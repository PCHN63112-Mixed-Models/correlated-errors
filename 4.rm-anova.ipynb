{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde1ccab-2d89-4ccf-aca6-dbea239a0625",
   "metadata": {},
   "source": [
    "# The Repeated Measures ANOVA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffadc85",
   "metadata": {},
   "source": [
    "## The Model of *Partitioned Errors*\n",
    "In the model above, we mentioned that performing the subtraction\n",
    "\n",
    "$$\n",
    "y_{ij} - \\alpha_{j} = \\mu + S_{i} + \\epsilon_{ij}.\n",
    "$$\n",
    "\n",
    "resulted in a model that was simply the grand mean *plus* pure error. In defining this \"error\", we split it into two parts, one associated with the subjects and one representing everything else. This process of splitting the error into different chunks is known as *partitioning* the error. In our original linear model, we only had a single error term and the model for two conditions was\n",
    "\n",
    "$$\n",
    "y_{ij} = \\mu + \\alpha_{j} + \\epsilon_{ij}.\n",
    "$$\n",
    "\n",
    "Although we implied that the term $S_{i}$ was *added* to the model, it is more correct to think of *splitting* the original error term. If we rename the error term to $\\eta_{ij}$, then this is more correctly expressed as\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}   &= \\mu + \\alpha_{j} + \\eta_{ij} \\\\\n",
    "    \\eta_{ij} &= S_{i} + \\epsilon_{ij}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Remembering that the errors represent the *random* part of our model, then the model with the single error term is given by\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}   &= \\mu + \\alpha_{j} + \\eta_{ij} \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}(0, \\sigma^{2})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "which should be familiar from last semester. If we were to then split $\\eta_{ij}$ into different chunks we end up with *multiple* random error terms\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}        &=    \\mu + \\alpha_{j} + (S_{i} + \\epsilon_{ij}) \\\\\n",
    "    S_{i}         &\\sim \\mathcal{N}(0, \\sigma^{2}_{b}) \\\\\n",
    "    \\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^{2}_{w})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So now we can see *explicitly* that there are two sources of error variance, one given by $\\sigma^{2}_{b}$ and one given by $\\sigma^{2}_{w}$. This means that the expected value of $y_{ij}$ stays exactly the same as any other model of two groups\n",
    "\n",
    "$$\n",
    "E\\left(y_{ij}\\right) = \\mu + \\alpha_{j} = \\mu_{j}.\n",
    "$$\n",
    "\n",
    "This connects directly with the idea that repeated measurements do not affect the mean function. However, what changes is the *variance* of $y_{ij}$, which is now given by\n",
    "\n",
    "$$\n",
    "\\text{Var}\\left(y_{ij}\\right) = \\sigma^{2}_{b} + \\sigma^{2}_{w}.\n",
    "$$\n",
    "\n",
    "These types of models are also known as *variance components* models, because they work precisely by splitting the variance into multiple components, as shown above. So, we can now express this model in terms of its mean and variance function like so\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    y_{ij}             &\\sim \\mathcal{N}(\\mu_{j}, \\sigma^{2})             &\\quad \\text{(Population distribution)} \\\\\n",
    "    E(y_{ij})          &=    \\mu_{j} = \\mu + \\alpha_{j}                   &\\quad \\text{(Mean function)}           \\\\\n",
    "    \\text{Var}(y_{ij}) &=    \\sigma^{2} = \\sigma^{2}_{b} + \\sigma^{2}_{w} &\\quad \\text{(Variance function)}.      \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So, we now have a model with a slightly more complex variance function that accommodates the fact that we have two sources of error whenever there are repeated measurements. This also connects directly with the idea that data from the same subject are *correlated*. The *covariance* between two measurements from the same subject is given by\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(\\mu + \\alpha_{1} + S_{i} + \\epsilon_{i1}, \\mu + \\alpha_{2} + S_{i} + \\epsilon_{i2}) \n",
    "$$\n",
    "\n",
    "Because $\\mu$, $\\alpha_{1}$ and $\\alpha_{2}$ are *population constants*, they have 0 variance and thus do not contribute to the definition of covariance, leading to\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i} + \\epsilon_{i1}, S_{i} + \\epsilon_{i2}) \n",
    "$$\n",
    "\n",
    "This can be expanded like so\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}) + \\text{Cov}(S_{i},\\epsilon_{i2}) + \\text{Cov}(\\epsilon_{i1},S_{i}) + \\text{Cov}(\\epsilon_{i1}, \\epsilon_{i2}). \n",
    "$$\n",
    "\n",
    "The subject effects and the errors are not correlated as these represent independent partitions of the overall error. As such, $\\text{Cov}(S_{i},\\epsilon_{i2}) = \\text{Cov}(\\epsilon_{i1},S_{i}) = 0$. Similarly, the final errors are uncorrelated because the correlation has been *removed* by partitioning-out the subject effects. So $\\text{Cov}(\\epsilon_{i1}, \\epsilon_{i2}) = 0$. This leaves\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}).\n",
    "$$\n",
    "\n",
    "A key result from the definition of covariance is that the covariance of a random variable with itself is simply its variance, meaning\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}) = \\text{Var}(S_{i}) = \\sigma^{2}_{b}.\n",
    "$$\n",
    "\n",
    "All of which is to say that the variance associated with the subject-specific deflections *is* the correlation induced by the repeated measurements.\n",
    "\n",
    "...\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\text{Var}\\left(y_{i1} - y_{i2}\\right) &= \\text{Var}(y_{i1}) + \\text{Var}(y_{i2}) - 2\\text{Cov}(y_{i1},y_{i2}) \\\\\n",
    "                                           &= \\left[\\sigma^{2}_{b} + \\sigma^{2}_{w}\\right] + \\left[\\sigma^{2}_{b} + \\sigma^{2}_{w}\\right] - 2\\sigma^{2}_{b} \\\\\n",
    "                                           &= \\sigma^{2}_{w} + \\sigma^{2}_{w}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So, we can see that the correlation *cancels-out*, which is exactly as expected from our exploration of the *model of paired differences* from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0223a13",
   "metadata": {},
   "source": [
    "### Partitioning the Error as a Decomposition of the Variance-covariance Matrix\n",
    "Now, we will connect what we have done above with the idea of modelling the variance-covariance matrix. Rather than doing this *explicitly*, the method above was an *implicit* modelling of the covariance structure...\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    y_{11} \\\\\n",
    "    y_{12} \\\\\n",
    "    y_{21} \\\\\n",
    "    y_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "\\sim\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "    \\sigma^{2}_{b} + \\sigma^{2}_{w}  & \\sigma^{2}_{b}                  & 0           & 0                     \\\\\n",
    "    \\sigma^{2}_{b}                   & \\sigma^{2}_{b} + \\sigma^{2}_{w} & 0           & 0                      \\\\\n",
    "    0                                & 0                               & \\sigma^{2}_{b} + \\sigma^{2}_{w}  & \\sigma^{2}_{b}            \\\\\n",
    "    0                                & 0           & \\sigma^{2}_{b} & \\sigma^{2}_{b} + \\sigma^{2}_{w}  \\\\\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe51b2",
   "metadata": {},
   "source": [
    "## The Concept of Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0025798-daa1-475d-b3f3-ed1ac8da1a0c",
   "metadata": {},
   "source": [
    "## Adding Between-subjects Factors\n",
    "\n",
    "... So what is the correct error here? The obvious, and correct, answer is that it is the *between-subjects* error. So how do we use this in our test statistics? At present, all we have done is *removed* the between-subjects error by including the `Subject` factor in our models. However, we somehow have to use this removed error as the denominator in tests that are based on between-subjects effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1c666-eb8c-43eb-9203-55d7fb758d15",
   "metadata": {},
   "source": [
    "### Partitioned Error Models\n",
    "\n",
    "... the difference is that, rather than including the `Subject` factor as something to be estimated and tested (like any other regression coefficients), we instead want to just use these effects for the purpose of estimating the *between-subjects* variance. We already saw from previous examples that the effects of `Subject` are not interesting, as we simply ignored them. Indeed, the $t$-tests and $p$-values and other automatic treatments of these coefficients were both *uninteresting* and *unnecessary*, which is a hint to the fact that we were not really using this factor correctly when adding it to the linear model in this way. This is because `Subject` was, in fact, something known as a *random-effect*.\n",
    "\n",
    "...This distinction between something we want to directly estimate and test and something that is used for calculating varirance is the difference between *fixed-effects* and *random-effects*. As such, in order to use the `Subject` factor in this way, it must be treated as a *random-effect*.\n",
    "\n",
    "...We have already seen models that contain random variables, as every single linear model so far has contained a *random error term*. As such, \n",
    "\n",
    "...The way the ANOVA calculated this error is through the usual decomposition of sums-of-squares...If we run an ANOVA on the paired model from earlier, we can see the *mean-squares* for the subejct effects. This *is* the estimate of the between-subejcts variance..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fdb21e",
   "metadata": {},
   "source": [
    "## RM ANOVA in `R`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599fab82",
   "metadata": {},
   "source": [
    "### Using the `aov()` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2732367d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(predvars, data, env): object 'y.long' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(predvars, data, env): object 'y.long' not found\nTraceback:\n",
      "1. summary(aov(y.long ~ cond + Error(subject)))",
      "2. aov(y.long ~ cond + Error(subject))",
      "3. eval(ecall, parent.frame())",
      "4. eval(ecall, parent.frame())",
      "5. stats::lm(formula = y.long ~ subject, singular.ok = TRUE, method = \"qr\", \n .     qr = TRUE)",
      "6. eval(mf, parent.frame())",
      "7. eval(mf, parent.frame())",
      "8. stats::model.frame(formula = y.long ~ subject, drop.unused.levels = TRUE)",
      "9. model.frame.default(formula = y.long ~ subject, drop.unused.levels = TRUE)",
      "10. eval(predvars, data, env)",
      "11. eval(predvars, data, env)"
     ]
    }
   ],
   "source": [
    "summary(aov(y.long ~ cond + Error(subject)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ce527",
   "metadata": {},
   "source": [
    "So this is now very explicitly saying that we want to add `subject` to the model, but that we want it to be treated as an *error term*. This tells `R` that we want the sums-of-squares and mean-square to be calculated for `subject`, but what we do not want is for there to be tests on this factor. Instead, we want it to be treated as the *denominator* of the $F$-statistic for certain tests. So, in the ANOVA table, we want `subject` to be an additional error term, rather than an actual effect we are interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1eb7ed",
   "metadata": {},
   "source": [
    "### Using the `ezANOVA()` Function\n",
    "As we can see above, using a partitioned error model with `aov()` is a tricky business and it would be very easy to get this wrong. As an alternative, we can use the `ezANOVA()` function from the `ez` package. As the name implies, this is designed to allow for an RM ANOVA without the usual difficulties associated with the `aov()` or `lm()` functions. Unfortuantely, the aim of this package is largely to make the `R` output the same as SPSS. So it does away with the linear model framework. This means, no residuals, no parameter estimates, no diagnostic plots or anything else we have made use of so far. If you *have* to use an RM ANOVA, this is the simplest way to get it *right*. However, as we will discuss below, we would disuade you from ever considering RM ANOVA as an option in the future. About the only utility of this is showing doubtful researchers that our better options of GLS and mixed-effects models are, in fact, giving them the same answer as an RM ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdee81e3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ezANOVA(): argument \"data\" is missing, with no default\n",
     "output_type": "error",
     "traceback": [
      "Error in ezANOVA(): argument \"data\" is missing, with no default\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "library(ez)\n",
    "ezANOVA()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdc59d",
   "metadata": {},
   "source": [
    "## Why We Should *Not* Use RM ANOVA\n",
    "Everything we have discussed above has really been an exercise in telling you why you really do not want to use RM ANOVA. All the unncessary fiddling with error terms and different tests requiring different errors is a complication that we could simply do without. Even if we do manage to successfully work out what needs to go where (or get a function like `ezANOVA()` to sort it for us), we are still left with a method that has a number of meaningful restrictions. ... Because of this, the RM ANOVA is both tricky to understand, tricky to use correctly and massively inflexible. It is no wonder that statisticians abandoned this method decades ago! And yet, this is the method that has persisted in psychology until releatively recently.\n",
    "\n",
    "This section has largely been motivational to understand why we want to use something more flexible and more modern, but it is important to recognise that you may well end up working with someone who knows nothing beyond the RM ANOVA. In those situations, it is useful to (a) motivate the need for something better and (b) understand how to get the RM ANOVA results in `R`, in case they require further convincing. So, we do not condone the use of the RM ANOVA, but we understand its place in psychology and also understand that there are times where you may want to see what the RM ANOVA says, even if you do not wish to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66d2d9-9c81-478c-a0d9-6b8ed9add05a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
