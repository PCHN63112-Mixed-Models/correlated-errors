
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Probability Models &#8212; Linear Models with Correlated Errors</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.probability';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The Paired t-test" href="3.paired-t.html" />
    <link rel="prev" title="Repeated Measurement Designs" href="1.designs.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models with Correlated Errors - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models with Correlated Errors - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.designs.html">Repeated Measurement Designs</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Probability Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.paired-t.html">The Paired <em>t</em>-test</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.rm-anova.html">The Repeated Measures ANOVA</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.gls.html">Generalised Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors/issues/new?title=Issue%20on%20page%20%2F2.probability.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.probability.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-normal-distribution">The Multivariate Normal Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mean-vector">The Mean Vector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-covariance-matrix">The Variance-Covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-draws-from-a-multivariate-normal">Taking Draws from a Multivariate Normal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-multivariate-normal">Visualising the Multivariate Normal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptualising-multiple-subjects">Conceptualising Multiple Subjects</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-wide-view">The Multivariate (<em>Wide</em>) View</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-univariate-long-view">The Univariate (<em>Long</em>) View</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-models">
<h1>Probability Models<a class="headerlink" href="#probability-models" title="Link to this heading">#</a></h1>
<p>…</p>
<section id="the-multivariate-normal-distribution">
<h2>The Multivariate Normal Distribution<a class="headerlink" href="#the-multivariate-normal-distribution" title="Link to this heading">#</a></h2>
<p>In order to place repeated measurements within a probabilistic framework, we need to introduce the concept of the <em>multivariate</em> normal distribution. As opposed to the <em>univariate</em> normal distribution we have seen previously, the <em>multivariate</em> normal distribution is not associated with a single <em>random variable</em>, it is associated with a <em>random vector</em>. This is written as follows</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right).
\]</div>
<p>We will spend a bit of time unpacking this, before we see how it applies to repeated measurements.</p>
<p>To start with, let us just define what we mean by a <em>vector</em>. Although there are different ways of conceptualising a vector, for our purpose we can simply think of it as a <em>list</em> of numbers. We can either have <em>row vectors</em> or <em>column vectors</em>, which we can simply think of like the <em>rows</em> or <em>columns</em> of a spreadsheet. There are much deeper and more precise mathematical definitions of vectors as mathematical objects, but for us this is all we really need to know. A <em>random vector</em> is then a vector that contains <em>random variables</em>, rather than numbers. So, if we have <em>two</em> repeated measurements take from subject <span class="math notranslate nohighlight">\(i\)</span> we can define our outcome variable as a <em>random row vector</em> called <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span>, which has the form</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} =
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}.
\]</div>
<p>So, notice that we have packaged these measurements together into a single object, which is important for what follows. Also notice that we use <strong>bold</strong> typeface to distinguish vectors and matrices from usual variables.</p>
<section id="the-mean-vector">
<h3>The Mean Vector<a class="headerlink" href="#the-mean-vector" title="Link to this heading">#</a></h3>
<p>Notice above that the mean of the multivariate normal is <em>also</em> a vector called <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>. This contains the <em>expected value</em> of <em>both</em> random variables in <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span>. So, if the expected value of column 1 was <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and the expected value of column 2 was <span class="math notranslate nohighlight">\(\mu_{2}\)</span>, we would have</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\mu} =
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}.
\]</div>
<p>Plugging the expanded definition of <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> into the expression for the multivariate normal, we currently have</p>
<div class="math notranslate nohighlight">
\[
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\boldsymbol{\Sigma}
\right).
\]</div>
<p>If there are more repeated measurements, we simply expand the number of columns. For instance, if we had 3 repeated measurements, we could specify</p>
<div class="math notranslate nohighlight">
\[
\begin{bmatrix}
    y_{i1} &amp; y_{i2} &amp; y_{i3}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2} &amp; \mu_{3}
\end{bmatrix}, 
\boldsymbol{\Sigma}
\right).
\]</div>
<p>Or, more compactly, as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right)
\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \mathbf{y}_{i} &amp;= 
    \begin{bmatrix}
        y_{i1} &amp; y_{i2} &amp; y_{i3}
    \end{bmatrix} \\
    \boldsymbol{\mu} &amp;= 
    \begin{bmatrix}
        \mu_{1} &amp; \mu_{2} &amp; \mu_{3}
    \end{bmatrix}.
\end{alignat*}
\end{split}\]</div>
</section>
<section id="the-variance-covariance-matrix">
<h3>The Variance-Covariance Matrix<a class="headerlink" href="#the-variance-covariance-matrix" title="Link to this heading">#</a></h3>
<p>Now, for the really crucial bit. First, recall that the univariate normal distribution is parameterised by a <em>mean</em> and a <em>variance</em>. These encode the <em>centre</em> of the distribution and its <em>width</em>. This should be familiar and is written</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim\mathcal{N}(\mu,\sigma^{2}).
\]</div>
<p>The multivariate normal is exactly the same in spirit. We have already seen how a single <em>mean</em> becomes a <em>mean vector</em>. So what about the <em>variance</em>? This is not coded by a <em>vector</em>, rather it is coded by a <em>matrix</em> symbolised by <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. This is called the <em>variance-covariance</em> matrix and it has the very important job of encoding the variance of each element of <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span> <em>but also encoding the correlation between those elements</em>. This is the <em>key</em> to understanding why the multivariate normal is a useful probability model for repeated measurements.</p>
<p>To start with, we will just define a <em>matrix</em>, before seeing how <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> fits into our conceptualisation. A <em>matrix</em> is simply a collection of <em>vectors</em>. These can either be multiple row vectors, or multiple column vectors. Either way, a matrix is more like a <em>spreadsheet</em> of values, rather than an individual column or row. In the example of <em>two</em> repeated measurements, the matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> will be <span class="math notranslate nohighlight">\(2 \times 2\)</span> and have the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\Sigma} = 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}.
\end{split}\]</div>
<p>The <em>diagonal</em> elements encode the variance of <span class="math notranslate nohighlight">\(y_{i1}\)</span> and the variance of <span class="math notranslate nohighlight">\(y_{i2}\)</span> respectively. These are denoted <span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span> and <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>. The <em>off-diagonal</em> elements encode the <em>correlation</em> between <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(y_{i2}\)</span>. This is parameterised in similar units to the variance and so is known as the <em>covariance</em>. This can be thought of as a <em>scaled</em> version of correlation. The relationship between correlation and covariance is as follows</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}\left(y_{i1},y_{i2}\right) = \sigma_{12} = \sigma_{21} = \rho\sigma_{1}\sigma_{2}, 
\]</div>
<p>where <span class="math notranslate nohighlight">\(\rho\)</span> is the correlation, <span class="math notranslate nohighlight">\(\sigma_{1}\)</span> is the <em>standard deviation</em> of <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{2}\)</span> is the <em>standard deviation</em> of <span class="math notranslate nohighlight">\(y_{i2}\)</span>. So this is really just different units encoding the same idea. Correlation re-scales covariance into the range <span class="math notranslate nohighlight">\([-1, 1]\)</span>. Because of this, we will use <em>correlation</em> and <em>covariance</em> somewhat interchangeably as, for our purpose, they capture the same concept. We can therefore think of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> as similar in spirit to a <em>correlation</em> matrix between the repeated measurements. As such, the degree to which the multivariate normal can form an accurate <em>data-generating</em> model will depend upon the values in <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>, the <em>diagonal</em> elements of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> and, most crucially for repeated measurements, the <em>off-diagonal</em> elements of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>.</p>
<p>We can put this all together to give our final probabilistic model for two repeated measurements</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\right)
\end{split}\]</div>
<p>Or, more compactly, as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right)
\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \mathbf{y}_{i} &amp;= 
    \begin{bmatrix}
        y_{i1} &amp; y_{i2}
    \end{bmatrix} \\
    \boldsymbol{\mu} &amp;= 
    \begin{bmatrix}
        \mu_{1} &amp; \mu_{2}
    \end{bmatrix} \\
    \boldsymbol{\Sigma} &amp;= 
    \begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\end{alignat*}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\sigma_{12} = \sigma_{21} = \rho\sigma_{1}\sigma_{2}.
\]</div>
</section>
<section id="taking-draws-from-a-multivariate-normal">
<h3>Taking Draws from a Multivariate Normal<a class="headerlink" href="#taking-draws-from-a-multivariate-normal" title="Link to this heading">#</a></h3>
<p>As we have see above, the multivariate normal distribution is able to describes the behaviour of <em>multiple</em> random variables by describing the data-generating process of a <em>random vector</em>. This includes both the expected value of each element of the vector <em>and</em>, most crucially, how <em>correlated</em> those values are. In the case of a 2-dimensional multivariate normal, every time we draw data from this distribution we get <em>two</em> values back. The first has a population mean of <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and a variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span>. The second has a population mean of <span class="math notranslate nohighlight">\(\mu_{2}\)</span> and a variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>. Most importantly, the two values will be <em>correlated</em> by a factor of <span class="math notranslate nohighlight">\(\sigma_{12}\)</span>. If <span class="math notranslate nohighlight">\(\sigma_{12} = 0\)</span> then this will be no different to drawing two values separately from a univariate normal distribution and there is little point in using the multivariate normal. However, if <span class="math notranslate nohighlight">\(|\sigma_{12}| &gt; 0\)</span>, then the two values will be related, where the strength of this relationship scales with the magnitude of the covariance.</p>
<p>To see how the multivariate normal works as a sampling model, we can simulate drawing data from a multivariate normal distribution in <code class="docutils literal notranslate"><span class="pre">R</span></code>. Base <code class="docutils literal notranslate"><span class="pre">R</span></code> does not have any multivariate distribution functions, but we can use the <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">MASS</span></code> package. To do so, we provide a <em>mean vector</em> and a <em>variance-covariance matrix</em>, alongside the number of independent draws we want to take. For instance, we can draw a single pair of values from the multivariate normal defined by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y}_{i} \sim\mathcal{N}\left(
\begin{bmatrix}
    2 &amp; 3
\end{bmatrix}, 
\begin{bmatrix}
    1   &amp; 1.6  \\
    1.6 &amp; 4
\end{bmatrix}
\right)
\end{split}\]</div>
<p>using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">666</span><span class="p">)</span>

<span class="n">var.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">                           </span><span class="c1"># Variance 1</span>
<span class="n">var.2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span><span class="w">                           </span><span class="c1"># Variance 2</span>
<span class="n">rho</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.8</span><span class="w">                         </span><span class="c1"># Correlation</span>
<span class="n">cov</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rho</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var.1</span><span class="p">)</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var.2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Covariance</span>

<span class="n">Mu</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">)</span><span class="w">                                  </span><span class="c1"># Mean vector</span>
<span class="n">Sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">var.1</span><span class="p">,</span><span class="w"> </span><span class="n">cov</span><span class="p">,</span>
<span class="w">                  </span><span class="n">cov</span><span class="p">,</span><span class="w">   </span><span class="n">var.2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Variance-covariance matrix</span>

<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 1.624908 4.941023
</pre></div>
</div>
</div>
</div>
<p>So, we can see that we get <em>two</em> values back whenever we sample from this distribution. These can be thought of as random draw from the same experimental unit. For instance, we can think of these as representing responses from subject <span class="math notranslate nohighlight">\(i\)</span> in experimental condition 1 and experimental condition 2. This is parameterised by the mean vector</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">Mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 2 3
</pre></div>
</div>
</div>
</div>
<p>and by the variance-covariance matrix</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     [,1] [,2]
[1,]  1.0  1.6
[2,]  1.6  4.0
</pre></div>
</div>
</div>
</div>
<p>Note that the correlation was set to <span class="math notranslate nohighlight">\(\rho = 0.8\)</span> in the code above and was converted into covariance based on the variances of <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>. As we can see, covariance is not constrained to <span class="math notranslate nohighlight">\(\left[-1, 1\right]\)</span> like correlation is and so does not have the same ease of interpretation. As such, whenever we want to <em>interpret</em> dependence, correlation is more useful. However, for calculations involving variance, covariance is needed so that the units are compatible.</p>
</section>
</section>
<section id="visualising-the-multivariate-normal">
<h2>Visualising the Multivariate Normal<a class="headerlink" href="#visualising-the-multivariate-normal" title="Link to this heading">#</a></h2>
<p>Although we have now discussed the mechanics of the multivariate normal, an easier way to conceptualise how the multivariate normal works is to <em>visualise</em> it. The most important element to recognise here is that the multivariate normal represents a probability density across <em>multiple</em> dimensions. As such, in order to visualise it, we have to restrict ourselves to only 2-dimensions. The multivariate normal can have many more dimensions than this, we just cannot visualise it. This is similar in spirit to multiple regression, where we can have as many predictor as we want, but can only visualise the regression plane when we have 2 of them.</p>
<p>A basic 2-dimensional normal distribution is shown below.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/2c4b2c39a7293d1547fe9740641de6eb6fb9e68b5fc029c13cef00f3ca30df0f.png" src="_images/2c4b2c39a7293d1547fe9740641de6eb6fb9e68b5fc029c13cef00f3ca30df0f.png" />
</div>
</div>
<p>Because this is 2-dimensional, it is defined as a probability distribution for the random vector</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} =
\begin{bmatrix}
    y_{1} &amp; y_{2}
\end{bmatrix}.
\]</div>
<p>Each of the random variables in this vector gets its own axis. So the first horizontal axis represents possible values of <span class="math notranslate nohighlight">\(y_{1}\)</span>, and the second horizontal axis represents possible values of <span class="math notranslate nohighlight">\(y_{2}\)</span>. The density of the distribution then gives the <em>joint-probability</em> of all possible pairs of values for <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>. Pick any point on the surface and it represents the probability of the points on the <span class="math notranslate nohighlight">\(y_{1}\)</span> axis and the <span class="math notranslate nohighlight">\(y_{2}\)</span> axis <em>occurring together</em>. From this we can see that the <em>most probable</em> joint values are when <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span> are equal to their expected value. In other words, the peak of the distribution occurs at the mean of <span class="math notranslate nohighlight">\(y_{1}\)</span> <em>and</em> the mean of <span class="math notranslate nohighlight">\(y_{2}\)</span>. For any other values, the joint-probability depends upon the variance within each dimension, as well as the covariance.</p>
<p>In the example above, the variance-covariance matrix was defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\Sigma} = 
\begin{bmatrix}
    \sigma^{2} &amp; 0 \\
    0 &amp; \sigma^{2}
\end{bmatrix}
\end{split}\]</div>
<p>In other words, the variance of each dimension was set to be the same and there was <em>no correlation</em>. This creates the perfect symmetry we see in the shape above. Now, let us see what happens when there <em>is</em> correlation. If we keep everything else the same but set <span class="math notranslate nohighlight">\(\rho = 0.8\)</span>, we get the distribution shown below.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/0a4f1e139aa68a91084920f167dfbe8131ae2008e487f03d75adc706f2d4dd97.png" src="_images/0a4f1e139aa68a91084920f167dfbe8131ae2008e487f03d75adc706f2d4dd97.png" />
</div>
</div>
<p>As we can see, correlation has created a “shark fin” shape in the probability density. To see how this connects with the idea of correlation, we will see how the probability distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> changes for a given value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. The plots below show a rotated view of the multivariate normal where we are focussing on the <span class="math notranslate nohighlight">\(y_{2}\)</span>-axis. The <em>left</em> column shows no correlation (<span class="math notranslate nohighlight">\(\rho=0\)</span>) and the <em>right</em> column shows a strong correlation (<span class="math notranslate nohighlight">\(\rho=0.8\)</span>). The distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> when <span class="math notranslate nohighlight">\(y_{1}\)</span> is fixed to a certain value is superimposed in blue. This is a <em>slice</em> through the multivariate normal. The <em>top</em> row shows <span class="math notranslate nohighlight">\(P(y_{2}|y_{1}=-1)\)</span> and the <em>bottom</em> row shows <span class="math notranslate nohighlight">\(P(y_{2}|y_{1}=1)\)</span>. Take a moment to study these so you are clear what they are showing.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/ef55936d1dd76bf7e1140ffd0f2b19206f933229e5f8c2ceb353b8e04ca4cd7f.png" src="_images/ef55936d1dd76bf7e1140ffd0f2b19206f933229e5f8c2ceb353b8e04ca4cd7f.png" />
</div>
</div>
<p>Notice that when there is <em>no correlation</em>, the distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> does not change with the value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. In other words, the value of <span class="math notranslate nohighlight">\(y_{1}\)</span> has no bearing on the probability of different values of <span class="math notranslate nohighlight">\(y_{2}\)</span>. This is the essence of <em>independence</em>. However, when there <em>is</em> correlation, the shape of the distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> <em>shifts</em> depending upon the value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. Notice in the <em>right</em> column that when <span class="math notranslate nohighlight">\(y_{1} = -1\)</span>, the distribution of <span class="math notranslate nohighlight">\(Y\)</span> is centred on a <em>different value</em> compared to when <span class="math notranslate nohighlight">\(y_{1} = 1\)</span>. This change in expectation is captured by the “shark fin” shape of the density. In essence, the most probable value of <span class="math notranslate nohighlight">\(y_{2}\)</span> changes based on the value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. The stronger the correlation, the closer the expected value of one random value tracks the value of the other. This is the essence of <em>dependence</em>.</p>
</section>
<section id="conceptualising-multiple-subjects">
<h2>Conceptualising Multiple Subjects<a class="headerlink" href="#conceptualising-multiple-subjects" title="Link to this heading">#</a></h2>
<p>We have now seen how we can think about correlated values of our outcome as draws from a multivariate normal distribution with a given variance-covariance matrix. However, we have only be thinking about <em>one</em> subject so far. To complete this picture, we need to think about how we conceptualise <em>multiple</em> subjects. This is important because there are two entirely equivalent ways to do this that map on to two different data structures that you may come across: <em>wide</em>-formatted data and <em>long</em>-formatted data.</p>
<section id="the-multivariate-wide-view">
<h3>The Multivariate (<em>Wide</em>) View<a class="headerlink" href="#the-multivariate-wide-view" title="Link to this heading">#</a></h3>
<p>Starting with out existing conceptualisation of a subject as a <em>row</em>-vector drawn from a multivariate normal, the natural extension is to add more rows for each additional subject. This corresponds to a <em>matrix</em> of values, where each row is an independent draw from a multivariate normal distribution. Indeed, this is exactly what is implied by the notation</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right), 
\]</div>
<p>because <span class="math notranslate nohighlight">\(i\)</span> indexes each <em>row</em> of the outcome variable. This therefore implies that <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> as a whole (with no subscript) is a <em>matrix</em>. To see this in <code class="docutils literal notranslate"><span class="pre">R</span></code>, we can set the value of <code class="docutils literal notranslate"><span class="pre">n=</span></code> in the call to <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> to our total sample size and we will get back a matrix of responses. Each row represents a subject and each column represents a separate repeated measurement. This may be familiar to you as <em>wide-formatted</em> data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">777</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>           [,1]     [,2]
 [1,] 2.1571710 3.772133
 [2,] 1.3168746 2.926946
 [3,] 2.6566917 3.312552
 [4,] 1.4093942 2.833913
 [5,] 3.3962213 4.712967
 [6,] 3.2315357 2.947249
 [7,] 2.1202807 3.264324
 [8,] 3.2996450 3.804416
 [9,] 1.4016128 3.207103
[10,] 1.1858382 3.095126
[11,] 1.5763201 2.846384
[12,] 2.6030285 2.499737
[13,] 0.2235982 1.207587
[14,] 2.4386245 2.497327
[15,] 4.3641379 5.021615
</pre></div>
</div>
</div>
</div>
<p>As expected, the two columns are <em>correlated</em>, which we can see using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">cor</span><span class="p">(</span><span class="n">y</span><span class="p">[,</span><span class="m">1</span><span class="p">],</span><span class="n">y</span><span class="p">[,</span><span class="m">2</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 0.7651892
</pre></div>
</div>
</div>
</div>
<p>which is not too far off the value of <span class="math notranslate nohighlight">\(\rho=0.8\)</span> that we used for the simulations. The more data we have the more precise this estimate of the correlation would be and the closer to the true value it would become.</p>
</section>
<section id="the-univariate-long-view">
<h3>The Univariate (<em>Long</em>) View<a class="headerlink" href="#the-univariate-long-view" title="Link to this heading">#</a></h3>
<p>As an alternative, we can also view our outcome as a <em>single column-vector</em> of measurements, rather than a matrix. This is important because all the linear models we have seen thus far are <em>univariate</em>, as they only have a single outcome variable. If we want to analyse repeated measurements within this framework, we need to organise our data in a univariate fashion<a class="footnote-reference brackets" href="#multivar-foot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. This means we have to stack subjects as <em>one column</em>. So, there is nothing in the structure of the outcome variable that indicates where the independent measurements are and where the dependent measurements are. This may seem a step backwards, and it does bring additional complication. However, there are advantages here. For instance, if there are <em>missing values</em> across repeats, they can simply be omitted in the univariate format. However, a matrix cannot have empty entries, which would force us to either impute some value or to abandon the data entirely<a class="footnote-reference brackets" href="#missing-foot" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<p>Importantly, the organisation of the data makes no difference to the <em>probability model</em>, only to the geometry and mechanics of the model we fit to the data. To see this, we need to recognise that it does not matter whether we conceptualise each subject as a <em>row</em> or <em>column</em> vector. Either way, the probability model remains the same. So, the following expression for a single subject</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}  &amp; \sigma_{12} \\
    \sigma_{21} &amp; \sigma^{2}
\end{bmatrix}
\right),
\end{split}\]</div>
<p>is entirely equivalent to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} \\
    y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} \\
    \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}  &amp; \sigma_{12}  \\
    \sigma_{21} &amp; \sigma^{2}
\end{bmatrix}
\right).
\end{split}\]</div>
<p>If we take the <em>second</em> perspective of each subject being a <em>column-vector</em>, we can now <em>stack</em> the subjects to produce a single outcome variable, suitable for use in our linear model framework. We can see an example of this below in <code class="docutils literal notranslate"><span class="pre">R</span></code>. This takes a little more work because the default output from <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> is <em>wide</em>-formatted data. Do not worry too much about the way this is converted, the point is that the numbers and their origin do not change between these approaches. The only difference is the way the data are organised. This may be familiar to you as <em>long-formatted</em> data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">777</span><span class="p">)</span>
<span class="n">y</span><span class="w">      </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="n">y.vec</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.vector</span><span class="p">(</span><span class="nf">t</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="n">y.long</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">y.vec</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">30</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y.long</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>           [,1]
 [1,] 2.1571710
 [2,] 3.7721330
 [3,] 1.3168746
 [4,] 2.9269463
 [5,] 2.6566917
 [6,] 3.3125521
 [7,] 1.4093942
 [8,] 2.8339131
 [9,] 3.3962213
[10,] 4.7129669
[11,] 3.2315357
[12,] 2.9472488
[13,] 2.1202807
[14,] 3.2643236
[15,] 3.2996450
[16,] 3.8044165
[17,] 1.4016128
[18,] 3.2071032
[19,] 1.1858382
[20,] 3.0951262
[21,] 1.5763201
[22,] 2.8463840
[23,] 2.6030285
[24,] 2.4997373
[25,] 0.2235982
[26,] 1.2075869
[27,] 2.4386245
[28,] 2.4973271
[29,] 4.3641379
[30,] 5.0216151
</pre></div>
</div>
</div>
</div>
<p>If we do this, we can then conceptualise the <em>whole</em> outcome variable across <em>all</em> subjects as a draw from a multivariate normal distribution. For instance, if we had 3 subjects each with 2 repeated measurements then the outcome vector would contain 6 values. The mean vector would contain 6 expected values and the variance-covariance matrix would be <span class="math notranslate nohighlight">\(6 \times 6\)</span>. Importantly, this covariance structure would model non-zero covariance <em>within</em> each subject, but would encode zero covariance between the subjects, given that they are treated as independent. This type of structure is known as a <em>block diagonal</em> matrix and would be written as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{11} \\
    y_{12} \\
    y_{21} \\
    y_{22} \\
    y_{31} \\
    y_{32} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}  &amp; \sigma_{12} &amp; 0           &amp; 0           &amp; 0           &amp; 0           \\
    \sigma_{21} &amp; \sigma^{2}  &amp; 0           &amp; 0           &amp; 0           &amp; 0           \\
    0           &amp; 0           &amp; \sigma^{2}  &amp; \sigma_{12} &amp; 0           &amp; 0           \\
    0           &amp; 0           &amp; \sigma_{21} &amp; \sigma^{2}  &amp; 0           &amp; 0           \\
    0           &amp; 0           &amp; 0           &amp; 0           &amp; \sigma^{2}  &amp; \sigma_{12} \\
    0           &amp; 0           &amp; 0           &amp; 0           &amp; \sigma_{21} &amp; \sigma^{2}  \\
\end{bmatrix}
\right)
\end{split}\]</div>
<p>This is a 6-dimensional normal distribution, so we would struggle to visualise this in any meaningful way. However, dimensions are just a mathematical tool for keeping track of information. We do not <em>have</em> to be able to visualise them in order for it to be meaningful. The more important element here is the <em>structure</em>. In particular, there is nothing about the structure of the outcome vector <em>or</em> the mean vector that encodes the organisation of the data within and between subjects. This could just be 6 independent measurements taken from two separate experimental conditions. The key is recognising that the structure of the data as repeated measurements is entirely encoded by the variance-covariance matrix.</p>
<p>Just to drive this point home, an equivalent dataset of <em>independent</em> measurements would have the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{11} \\
    y_{22} \\
    y_{31} \\
    y_{42} \\
    y_{51} \\
    y_{62} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}  &amp; 0           &amp; 0           &amp; 0           &amp; 0           &amp; 0           \\
    0           &amp; \sigma^{2}  &amp; 0           &amp; 0           &amp; 0           &amp; 0           \\
    0           &amp; 0           &amp; \sigma^{2}  &amp; 0           &amp; 0           &amp; 0           \\
    0           &amp; 0           &amp; 0           &amp; \sigma^{2}  &amp; 0           &amp; 0           \\
    0           &amp; 0           &amp; 0           &amp; 0           &amp; \sigma^{2}  &amp; 0           \\
    0           &amp; 0           &amp; 0           &amp; 0           &amp; 0           &amp; \sigma^{2}  \\
\end{bmatrix}
\right).
\end{split}\]</div>
<p>Because there is no dependency between these measurements, they can simply be treated as individual draws from a univariate distribution of the form</p>
<div class="math notranslate nohighlight">
\[
y_{ij} \sim \mathcal{N}\left(\mu_{j},\sigma^{2}\right),
\]</div>
<p>which is <em>exactly</em> the probability model we were working with last semester. The key focus of our statistical model for repeated measurements is therefore the structure of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. It has nothing to do with the parameter estimates that form the mean function. According to the models above, this will be <em>identical</em> whether we have repeated measurements or not. We already know this because our simulations from the previous part of the lesson showed that correlation directly impacted the <em>standard errors</em>, rather than the estimates themselves. As such, if the covariance structure does <em>not</em> include correlation, we will get the estimated standard errors <em>wrong</em>. This then has a direct impact on inference, both in terms of NHST but also in terms of assessing <em>uncertainty</em> using confidence intervals. As such, the fundamental difference between the models we discussed last semester and methods for repeated measurements is <em>precisely</em> the accommodation of correlation via a more complex covariance structure.</p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="multivar-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>There are multivariate versions of the linear model where the outcome is treated as a <em>matrix</em> rather than a <em>vector</em>. Indeed, these can be used for repeated measurements and do have some advantages. However, they are beyond the scope of this unit. <a class="reference external" href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781118391686">Methods of Multivariate Analysis</a> by Rencher and Christensen is an excellent exposition on this topic, if you want to know more.</p>
</aside>
<aside class="footnote brackets" id="missing-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>You might think we can just add a 0 wherever data is missing. However, 0 still carries meaning and will bias the parameter estimates towards it. If this value is unusual, it may cause high leverage or it could end up being an outlier. Rather than representing <em>nothing</em>, we are actually making a very <em>strong</em> claim about the real value of this data point. You might think the <em>mean</em> is a better choice, but this actually carries similar issues and makes the mean appear more certain than it is. Ultimately, every method of imputation is questionable on the grounds that you are claiming to know what that data would have been, had it been collected.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.designs.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Repeated Measurement Designs</p>
      </div>
    </a>
    <a class="right-next"
       href="3.paired-t.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Paired <em>t</em>-test</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-normal-distribution">The Multivariate Normal Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mean-vector">The Mean Vector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-covariance-matrix">The Variance-Covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-draws-from-a-multivariate-normal">Taking Draws from a Multivariate Normal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-multivariate-normal">Visualising the Multivariate Normal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptualising-multiple-subjects">Conceptualising Multiple Subjects</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-wide-view">The Multivariate (<em>Wide</em>) View</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-univariate-long-view">The Univariate (<em>Long</em>) View</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>