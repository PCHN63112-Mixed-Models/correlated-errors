
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>The Paired t-test &#8212; Linear Models with Correlated Errors</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3.paired-t';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The Repeated Measures ANOVA" href="4.rm-anova.html" />
    <link rel="prev" title="Probability Models" href="2.probability.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models with Correlated Errors - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models with Correlated Errors - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.designs.html">Repeated Measurement Designs</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.probability.html">Probability Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The Paired <em>t</em>-test</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.rm-anova.html">The Repeated Measures ANOVA</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.gls.html">Generalised Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors/issues/new?title=Issue%20on%20page%20%2F3.paired-t.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/3.paired-t.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Paired t-test</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-sample-vs-paired-t-tests">Two-sample vs Paired <em>t</em>-tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model-of-paired-differences">The Model of <em>Paired Differences</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paired-differences-in-r">Paired Differences in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#removing-the-effect-of-the-subjects">Removing the Effect of the Subjects</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model-of-partitioned-errors">The Model of <em>Partitioned Errors</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partitioning-the-error">Partitioning the Error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partitioning-the-error-as-a-decomposition-of-the-variance-covariance-matrix">Partitioning the Error as a Decomposition of the Variance-covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-does-the-standard-error-come-from">Where Does the Standard Error Come From?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recreating-the-paired-t-test-in-the-linear-model">Recreating the Paired <span class="math notranslate nohighlight">\(t\)</span>-test in the Linear Model</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-paired-t-test">
<h1>The Paired <em>t</em>-test<a class="headerlink" href="#the-paired-t-test" title="Link to this heading">#</a></h1>
<p>To begin our journey into the world of models for repeated measurements, we will start with the simplest possible example: the paired <span class="math notranslate nohighlight">\(t\)</span>-test. Last semester, we saw how the humble <span class="math notranslate nohighlight">\(t\)</span>-test can be subsumed into the linear model framework through the use of <em>dummy variables</em>. This same approach can be used with paired data[^paired-foot] because the difference between the <em>independent</em> and <em>paired</em> <span class="math notranslate nohighlight">\(t\)</span>-test does not lie with the <em>mean function</em>. We spent a lot of time last semester discussing different mean functions and, you will be glad to know, this all follows-over into the world of repeated measurements. The difference lies with the <em>variance function</em>. Specifically, how we can alter the variance function to accommodate non-zero correlation between the repeats? As we will see in this part of the lesson, there are <em>two</em> equivalent ways of doing this with paired data. One of them <em>side-steps</em> the issues of dependence whereas the other does not. However, it is useful to understand how both of these work because it provides some crucial insight into modelling repeated measurements that we will generalise as our models get more complex.</p>
<section id="two-sample-vs-paired-t-tests">
<h2>Two-sample vs Paired <em>t</em>-tests<a class="headerlink" href="#two-sample-vs-paired-t-tests" title="Link to this heading">#</a></h2>
<p>To begin with, it is useful to examine <em>how</em> the results differ between a <em>two-sample</em> and <em>paired</em> <span class="math notranslate nohighlight">\(t\)</span>-test. We can don this in <code class="docutils literal notranslate"><span class="pre">R</span></code> by comparing the results of the <code class="docutils literal notranslate"><span class="pre">t.test()</span></code> function with <code class="docutils literal notranslate"><span class="pre">paired=FALSE</span></code> and <code class="docutils literal notranslate"><span class="pre">paired=TRUE</span></code>. To do this, we use the <code class="docutils literal notranslate"><span class="pre">mice2</span></code> data set from the <code class="docutils literal notranslate"><span class="pre">datarium</span></code> package, that contains the weight of a sample of 10 mice both <em>before</em> and <em>after</em> some treatment. The experimental question concerns whether the treatment affects the weight of the mice. The data is shown below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="s">&#39;datarium&#39;</span><span class="p">)</span>
<span class="nf">data</span><span class="p">(</span><span class="s">&#39;mice2&#39;</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">mice2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   id before after
1   1  187.2 429.5
2   2  194.2 404.4
3   3  231.7 405.6
4   4  200.5 397.2
5   5  201.7 377.9
6   6  235.0 445.8
7   7  208.7 408.4
8   8  172.4 337.0
9   9  184.6 414.3
10 10  189.6 380.3
</pre></div>
</div>
</div>
</div>
<p>We can compare the output from a <em>two-sample</em> <span class="math notranslate nohighlight">\(t\)</span>-test and a <em>paired</em> <span class="math notranslate nohighlight">\(t\)</span>-test by changing the <code class="docutils literal notranslate"><span class="pre">paired=</span></code> argument of <code class="docutils literal notranslate"><span class="pre">t.test()</span></code>, as shown below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">t.test</span><span class="p">(</span><span class="n">mice2</span><span class="o">$</span><span class="n">before</span><span class="p">,</span><span class="w"> </span><span class="n">mice2</span><span class="o">$</span><span class="n">after</span><span class="p">,</span><span class="w"> </span><span class="n">var.equal</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">paired</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">))</span><span class="w">  </span><span class="c1"># paired t-test</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">t.test</span><span class="p">(</span><span class="n">mice2</span><span class="o">$</span><span class="n">before</span><span class="p">,</span><span class="w"> </span><span class="n">mice2</span><span class="o">$</span><span class="n">after</span><span class="p">,</span><span class="w"> </span><span class="n">var.equal</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">paired</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">))</span><span class="w"> </span><span class="c1"># two-sample t-test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>	Paired t-test

data:  mice2$before and mice2$after
t = -25.546, df = 9, p-value = 1.039e-09
alternative hypothesis: true mean difference is not equal to 0
95 percent confidence interval:
 -217.1442 -181.8158
sample estimates:
mean difference 
        -199.48 


	Two Sample t-test

data:  mice2$before and mice2$after
t = -17.453, df = 18, p-value = 9.974e-13
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -223.4926 -175.4674
sample estimates:
mean of x mean of y 
   200.56    400.04 
</pre></div>
</div>
</div>
</div>
<p>The output is a bit different between the two methods, so let us spend a little time unpacking what <em>is</em> and what <em>is not</em> different here. To begin with, the clearest differences between the two methods concern the <span class="math notranslate nohighlight">\(t\)</span>-statistic itself, the degrees of freedom, the <span class="math notranslate nohighlight">\(p\)</span>-value and the confidence interval. This is summarised in the table below</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Test</p></th>
<th class="head"><p><em>t</em>-statistic</p></th>
<th class="head"><p>DoF</p></th>
<th class="head"><p><em>p</em>-value</p></th>
<th class="head"><p>95% CI</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Paired</p></td>
<td><p>-25.546</p></td>
<td><p>9</p></td>
<td><p>1.039e-09</p></td>
<td><p>[-217.14 -181.82]</p></td>
</tr>
<tr class="row-odd"><td><p>Two-sample</p></td>
<td><p>-17.453</p></td>
<td><p>18</p></td>
<td><p>9.974e-13</p></td>
<td><p>[-223.49 -175.47]</p></td>
</tr>
</tbody>
</table>
</div>
<p>Although this may therefore seem like <em>everything</em> is different, there is actually one element that is <em>identical</em> here, though it is somewhat hidden. To see it, consider that the structure of a <span class="math notranslate nohighlight">\(t\)</span>-test is</p>
<div class="math notranslate nohighlight">
\[
t = \frac{\mu_{1} - \mu_{2}}{\text{SE}\{\mu_{1} - \mu_{2}\}},
\]</div>
<p>meaning that we think of the <span class="math notranslate nohighlight">\(t\)</span> as the ratio between the <em>mean difference</em> and the <em>standard error of the mean difference</em>. The <span class="math notranslate nohighlight">\(t\)</span>-statistic is different between the <em>two-sample</em> and the <em>paired</em> tests, but this does not necessarily mean that all elements of this ratio are also different. Indeed, if we look at the output above we can see that the <em>paired</em> test reports a mean difference of <code class="docutils literal notranslate"><span class="pre">-199.48</span></code> and the <em>two-sample</em> test reports the individual means as <code class="docutils literal notranslate"><span class="pre">200.56</span></code> and <code class="docutils literal notranslate"><span class="pre">400.04</span></code>. If we calculate the mean difference in the <em>two-sample</em> test we get</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="m">200.56</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">400.04</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] -199.48
</pre></div>
</div>
</div>
</div>
<p>So, this is <em>identical</em> between the <em>paired</em> and <em>two-sample</em> tests. This should not be surprising, as we already established that repeated measurements do not affect the mean function. So, in either case, the groups means are the same, the mean difference is the same and the <em>numerator</em> of the <span class="math notranslate nohighlight">\(t\)</span>-statistic is the same. From this, we can conclude that the <em>difference</em> between the two methods concerns the <em>denominator</em> of the <span class="math notranslate nohighlight">\(t\)</span>-statistic. In other words, <em>the standard error of the difference changes under repeated measurements</em>.</p>
<p>Given that we know the numerator for both tests, we can recover the denominators to see that this is the case</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mean.diff</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">-199.48</span>
<span class="n">paired.t</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">-25.546</span>
<span class="n">twosamp.t</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">-17.453</span>
<span class="n">paired.se</span><span class="w">  </span><span class="o">&lt;-</span><span class="w">  </span><span class="n">mean.diff</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">paired.t</span>
<span class="n">twosamp.se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="n">mean.diff</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">twosamp.t</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">paired.se</span><span class="p">,</span><span class="w"> </span><span class="n">twosamp.se</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1]  7.808659 11.429554
</pre></div>
</div>
</div>
</div>
<p>So, the <em>standard error</em> of the difference is much <em>smaller</em> in the <em>paired</em> test when compared to the <em>two-sample</em> test. This should not be a surprise. Thinking back to our discussion from the beginning of the lesson, we know that the variance of the difference between two random variables should get <em>smaller</em> when they are positively correlated. From this, we can conclude that, when applied to <em>paired</em> data, the <em>two-sample</em> <span class="math notranslate nohighlight">\(t\)</span>-test is using a standard error that is <em>too large</em>.</p>
<p>This tracks with everything we have discussed so far. However, the key question for us is <em>how</em> the <em>paired</em> <span class="math notranslate nohighlight">\(t\)</span>-test is able to do this. As mentioned at the start of this part of the lesson, there are two equivalent ways of thinking about this. We will discuss <em>both</em> below because their equivalence provides important information for conceptualising more complex methods.</p>
</section>
<section id="the-model-of-paired-differences">
<h2>The Model of <em>Paired Differences</em><a class="headerlink" href="#the-model-of-paired-differences" title="Link to this heading">#</a></h2>
<p>The first method we can use is actually a bit of a <em>cheat</em> in order to side-step the issue of dependence. Effectively, a paired <span class="math notranslate nohighlight">\(t\)</span>-test can be thought of as a <em>one-sample</em> <span class="math notranslate nohighlight">\(t\)</span>-test on the <em>difference</em> between the pairs. We will explore this in more detail below, however, it is useful to know that conceptually this is a really key step because it introduces the idea that we can correctly model repeated measurements by <em>removing</em> something from the data. If we can make the paired test correct via subtraction, there must be something that is cancelling-out. Whatever this “something” is, its removal allows us to treat the <em>differences</em> between the pairs as independent.</p>
<section id="paired-differences-in-r">
<h3>Paired Differences in <code class="docutils literal notranslate"><span class="pre">R</span></code><a class="headerlink" href="#paired-differences-in-r" title="Link to this heading">#</a></h3>
<p>As a first step, we can demonstrate that this idea of subtracting the pairs <em>does</em> work, before exploring <em>why</em>. We can use the <code class="docutils literal notranslate"><span class="pre">mice2</span></code> data again and create a new variable that represents the difference between <code class="docutils literal notranslate"><span class="pre">before</span></code> the treatment and <code class="docutils literal notranslate"><span class="pre">after</span></code> the treatment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mice2</span><span class="o">$</span><span class="n">treat.diff</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mice2</span><span class="o">$</span><span class="n">before</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mice2</span><span class="o">$</span><span class="n">after</span>
<span class="nf">print</span><span class="p">(</span><span class="n">mice2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   id before after treat.diff
1   1  187.2 429.5     -242.3
2   2  194.2 404.4     -210.2
3   3  231.7 405.6     -173.9
4   4  200.5 397.2     -196.7
5   5  201.7 377.9     -176.2
6   6  235.0 445.8     -210.8
7   7  208.7 408.4     -199.7
8   8  172.4 337.0     -164.6
9   9  184.6 414.3     -229.7
10 10  189.6 380.3     -190.7
</pre></div>
</div>
</div>
</div>
<p>Now, we can simply perform a one-sample <span class="math notranslate nohighlight">\(t\)</span>-test on the difference. To do this, we could use the <code class="docutils literal notranslate"><span class="pre">t.test()</span></code> function, but given that our focus is linear models, we will use <code class="docutils literal notranslate"><span class="pre">lm()</span></code> instead.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">onesamp.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">treat.diff</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mice2</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">onesamp.mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = treat.diff ~ 1, data = mice2)

Residuals:
   Min     1Q Median     3Q    Max 
-42.82 -11.17   1.28  19.66  34.88 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -199.480      7.809  -25.55 1.04e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 24.69 on 9 degrees of freedom
</pre></div>
</div>
</div>
</div>
<p>The test on the intercept parameter <span class="math notranslate nohighlight">\((\beta_{0})\)</span> is now <em>identical</em> to the paired <span class="math notranslate nohighlight">\(t\)</span>-test from earlier. We can also compare two different ways of using <code class="docutils literal notranslate"><span class="pre">t.test()</span></code>, one using a one-sample test of the differences and the other using the full paired test</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">t.test</span><span class="p">(</span><span class="n">mice2</span><span class="o">$</span><span class="n">treat.diff</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">t.test</span><span class="p">(</span><span class="n">mice2</span><span class="o">$</span><span class="n">before</span><span class="p">,</span><span class="w"> </span><span class="n">mice2</span><span class="o">$</span><span class="n">after</span><span class="p">,</span><span class="w"> </span><span class="n">var.equal</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">paired</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>	One Sample t-test

data:  mice2$treat.diff
t = -25.546, df = 9, p-value = 1.039e-09
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 -217.1442 -181.8158
sample estimates:
mean of x 
  -199.48 


	Paired t-test

data:  mice2$before and mice2$after
t = -25.546, df = 9, p-value = 1.039e-09
alternative hypothesis: true mean difference is not equal to 0
95 percent confidence interval:
 -217.1442 -181.8158
sample estimates:
mean difference 
        -199.48 
</pre></div>
</div>
</div>
</div>
<p>As we can see, these are identical. So, this provided some key insight that we will build on to understand <em>how</em> models of repeated measurements work.</p>
</section>
<section id="removing-the-effect-of-the-subjects">
<h3>Removing the Effect of the Subjects<a class="headerlink" href="#removing-the-effect-of-the-subjects" title="Link to this heading">#</a></h3>
<p>Given what we have demonstrated above, the key insight is that taking <span class="math notranslate nohighlight">\(y_{i\Delta} = y_{i1} - y_{i2}\)</span> allows us to treat the values of <span class="math notranslate nohighlight">\(y_{i\Delta}\)</span> as <em>independent</em>. Effectively, the element that makes repeated measurements difficult has been <em>removed</em> via this subtraction. Given that we know that <em>correlation</em> is the issue, taking <span class="math notranslate nohighlight">\(y_{i\Delta} = y_{i1} - y_{i2}\)</span> <em>must</em> be removing the correlation from the data. This is fairly intuitive because we have reduced correlated pairs of data down to only a single value per-subject. Given that the subjects are taken as independent, the values of <span class="math notranslate nohighlight">\(y_{i\Delta}\)</span> must also be independent. In effect, there are <em>no</em> repeated measurements anymore. However, expressing this formally is a useful stepping-stone to more general methods.</p>
<p>To see what is happening, let us return to our basic <span class="math notranslate nohighlight">\(t\)</span>-test model from last semester where we parameterise each group mean in terms of the grand mean plus a group-specific deflection. The mean for the first repeated measurement is therefore <span class="math notranslate nohighlight">\(\mu_{1} = \mu + \alpha_{1}\)</span> and the mean for the second repeated measurement is <span class="math notranslate nohighlight">\(\mu_{2} = \mu + \alpha_{2}\)</span>. To capture the concept of <em>dependence</em> between these repeats, we add a <em>shared component</em> called <span class="math notranslate nohighlight">\(S_{i}\)</span>. For the two repeated measurements, the model is therefore</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    y_{i1} &amp;= \mu + \alpha_{1} + S_{i} + \epsilon_{i1} \\
    y_{i2} &amp;= \mu + \alpha_{2} + S_{i} + \epsilon_{i2} 
\end{alignat*}.
\end{split}\]</div>
<p>So, the reason why <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(y_{i2}\)</span> are correlated is because they <em>share</em> the same component <span class="math notranslate nohighlight">\(S_{i}\)</span>. This captures the idea that these measurements come from the <em>same subject</em>. If we then <em>subtract</em> <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(y_{i2}\)</span>, the term <span class="math notranslate nohighlight">\(S_{i}\)</span> will cancel-out<a class="footnote-reference brackets" href="#intercept-foot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    y_{i\Delta} = y_{i1} - y_{i2} &amp;= (\mu - \mu) + (\alpha_{1} - \alpha_{2}) + (S_{i} - S_{i}) + (\epsilon_{i1} - \epsilon_{i2}) \\
                                  &amp;= (\mu_{1} - \mu_{2}) + (\epsilon_{i1} - \epsilon_{i2})
\end{alignat*}.
\end{split}\]</div>
<p>So, this tells us that <span class="math notranslate nohighlight">\(S_{i}\)</span> precisely captures the <em>correlation</em>, because removing it renders the data <em>independent</em>.</p>
<p>We can also visualise what is happening here, to gain further intuition. The plot below shows each mouse along the <span class="math notranslate nohighlight">\(x\)</span>-axis, with their weight along the <span class="math notranslate nohighlight">\(y\)</span>-axis. The two treatments are shown for each mouse as two different coloured points and the grand mean is shown as a solid black line</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/0494806ab5e0a22b25a4f73660817c78d68e0782bac6a59a3ab3f703385a2684.png" src="_images/0494806ab5e0a22b25a4f73660817c78d68e0782bac6a59a3ab3f703385a2684.png" />
</div>
</div>
<p>According to the model</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \mu + \alpha_{j} + S_{i} + \epsilon_{ij}
\]</div>
<p>there are <em>three</em> sources of variance that explain why the data deflects from the grand mean. The first is variation associated with the two treatments (the <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> terms), the second is variation associated with the different subjects (the <span class="math notranslate nohighlight">\(S_{i}\)</span> terms) and the third is random error unrelated to anything else (the <span class="math notranslate nohighlight">\(\epsilon_{ij}\)</span> terms).</p>
<p>In order to understand this in more detail, and how it relates to repeated measurements, we can <em>remove</em> each source of variance from the data and then see what the plot looks like. Starting with the two treatments, if we remove the treatment effects from the data (the <span class="math notranslate nohighlight">\(\alpha_{j}\)</span>) we get the following</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/3b3ef361e84f17bc82826cd514ee9f99d48b20404e8e5228bdf9622a9791e600.png" src="_images/3b3ef361e84f17bc82826cd514ee9f99d48b20404e8e5228bdf9622a9791e600.png" />
</div>
</div>
<p>Now, after removing the <em>predictable</em> element of the variance, we should be left with only the <em>unpredictable</em> element in terms of pure error. In other words, the plot above shows all the reasons, <em>other</em> than the two experimental conditions, why the data do not adhere to the grand mean. Going back to our model, this shows</p>
<div class="math notranslate nohighlight">
\[
y_{ij} - \alpha_{j} = \mu + S_{i} + \epsilon_{ij}.
\]</div>
<p>So, there are two sources to this error. One relates to the fact that the data come from different subjects and the other is just random noise. Of interest is that the <em>correlation</em> induced by the repeated measurements can be seen above. Notice how the data from each subject is closely linked. For instance, both measurements for mouse 6 are close together and are both <em>above</em> the grand mean. Similarly, both measurements for mouse 8 are close together and are both <em>below</em> the grand mean. This implies that each mouse has a unique <em>constant offset</em> that moves their measurements above or below the grand mean <em>as a pair</em>. The fact that this offset moves the measurements <em>together</em> explains why the repeated measurements are <em>correlated</em>. In principle, if we remove this offset we remove the correlation. So, let us see what happens if we remove the constant offset given by <span class="math notranslate nohighlight">\(S_{i}\)</span>. This gives</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/bd980ff3c7139dd7a6d8da67cdddfb582c2448e55e2c5371ffc0e65e331d887f.png" src="_images/bd980ff3c7139dd7a6d8da67cdddfb582c2448e55e2c5371ffc0e65e331d887f.png" />
</div>
</div>
<p>Now we can see that the constant offset that moves each subject in different directions from the grand mean has been removed. Each subject is now <em>on an equal footing</em>. Mouse 6 is no longer far above the grand mean, nor is Mouse 8 far below the grand mean. Going back to our model, this shows</p>
<div class="math notranslate nohighlight">
\[
y_{ij} - \alpha_{j} - S_{i} = \mu + \epsilon_{ij}.
\]</div>
<p>We have therefore removed the element that causes the data to be correlated and the only variation left is the random error term <span class="math notranslate nohighlight">\(\epsilon_{ij}\)</span>. Subtracting the <span class="math notranslate nohighlight">\(S_{i}\)</span> effectively <em>removes</em> the value that shifts each subject’s measurements <em>away</em> from the mean by some amount that is <em>unique</em> to each subject, but <em>constant</em> across their own measurements. This is like each subject having their <em>own intercept</em>. In the paired <span class="math notranslate nohighlight">\(t\)</span>-test, this intercept is <em>implicitly</em> removed in the subtraction. However, we do also have the option of making this removal <em>explicit</em> by including the subject constants in the model itself. This method is known as a <em>partitioned errors</em> model and is useful both as a next step towards more general methods for repeated measurements, but also as a means of highlighting exactly what the removal of the <span class="math notranslate nohighlight">\(S_{i}\)</span> achieves in terms of inference.</p>
</section>
</section>
<section id="the-model-of-partitioned-errors">
<h2>The Model of <em>Partitioned Errors</em><a class="headerlink" href="#the-model-of-partitioned-errors" title="Link to this heading">#</a></h2>
<p>In the model above, we mentioned that performing the subtraction</p>
<div class="math notranslate nohighlight">
\[
y_{ij} - \alpha_{j} = \mu + S_{i} + \epsilon_{ij}.
\]</div>
<p>resulted in a model that was simply the grand mean <em>plus</em> pure error. In defining this “error”, we split it into two parts, one associated with the subjects and one representing everything else. This process of splitting the error into different chunks is known as <em>partitioning</em> the error. In our original linear model, we only had a single error term and the model for two conditions was</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \mu + \alpha_{j} + \epsilon_{ij}.
\]</div>
<p>Although we implied that the term <span class="math notranslate nohighlight">\(S_{i}\)</span> was <em>added</em> to the model, it is more correct to think of <em>splitting</em> the original error term. If we rename the error term to <span class="math notranslate nohighlight">\(\eta_{ij}\)</span>, then this is more correctly expressed as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    y_{ij}   &amp;= \mu + \alpha_{j} + \eta_{ij} \\
    \eta_{ij} &amp;= S_{i} + \epsilon_{ij}
\end{alignat*}
\end{split}\]</div>
<p>Remembering that the errors represent the <em>random</em> part of our model, then the model with the single error term is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    y_{ij}   &amp;= \mu + \alpha_{j} + \eta_{ij} \\
    \eta_{ij} &amp;\sim \mathcal{N}(0, \sigma^{2})
\end{alignat*}
\end{split}\]</div>
<p>which should be familiar from last semester. If we were to then split <span class="math notranslate nohighlight">\(\eta_{ij}\)</span> into different chunks we end up with <em>multiple</em> random error terms</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    y_{ij}        &amp;=    \mu + \alpha_{j} + (S_{i} + \epsilon_{ij}) \\
    S_{i}         &amp;\sim \mathcal{N}(0, \sigma^{2}_{b}) \\
    \epsilon_{ij} &amp;\sim \mathcal{N}(0, \sigma^{2}_{w})
\end{alignat*}
\end{split}\]</div>
<p>So now we can see <em>explicitly</em> that there are two sources of error variance, one given by <span class="math notranslate nohighlight">\(\sigma^{2}_{b}\)</span> and one given by <span class="math notranslate nohighlight">\(\sigma^{2}_{w}\)</span>. This means that the expected value of <span class="math notranslate nohighlight">\(y_{ij}\)</span> stays exactly the same as any other model of two groups</p>
<div class="math notranslate nohighlight">
\[
E\left(y_{ij}\right) = \mu + \alpha_{j} = \mu_{j}.
\]</div>
<p>This connects directly with the idea that repeated measurements do not affect the mean function. However, what changes is the <em>variance</em> of <span class="math notranslate nohighlight">\(y_{ij}\)</span>, which is now given by</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y_{ij}\right) = \sigma^{2}_{b} + \sigma^{2}_{w}.
\]</div>
<p>These types of models are also known as <em>variance components</em> models, because they work precisely by splitting the variance into multiple components, as shown above. So, we can now express this model in terms of its mean and variance function like so</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
    y_{ij}             &amp;\sim \mathcal{N}(\mu_{j}, \sigma^{2})             &amp;\quad \text{(Population distribution)} \\
    E(y_{ij})          &amp;=    \mu_{j} = \mu + \alpha_{j}                   &amp;\quad \text{(Mean function)}           \\
    \text{Var}(y_{ij}) &amp;=    \sigma^{2} = \sigma^{2}_{b} + \sigma^{2}_{w} &amp;\quad \text{(Variance function)}.      \\
\end{alignat*}
\end{split}\]</div>
<p>So, we now have a model with a slightly more complex variance function that accommodates the fact that we have two sources of error whenever there are repeated measurements. This also connects directly with the idea that data from the same subject are <em>correlated</em>. The <em>covariance</em> between two measurements from the same subject is given by</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}(y_{i1},y_{i2}) = \text{Cov}(\mu + \alpha_{1} + S_{i} + \epsilon_{i1}, \mu + \alpha_{2} + S_{i} + \epsilon_{i2}) 
\]</div>
<p>Because <span class="math notranslate nohighlight">\(\mu\)</span>, <span class="math notranslate nohighlight">\(\alpha_{1}\)</span> and <span class="math notranslate nohighlight">\(\alpha_{2}\)</span> are <em>population constants</em>, they have 0 variance and thus do not contribute to the definition of covariance, leading to</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}(y_{i1},y_{i2}) = \text{Cov}(S_{i} + \epsilon_{i1}, S_{i} + \epsilon_{i2}) 
\]</div>
<p>This can be expanded like so</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}(y_{i1},y_{i2}) = \text{Cov}(S_{i},S_{i}) + \text{Cov}(S_{i},\epsilon_{i2}) + \text{Cov}(\epsilon_{i1},S_{i}) + \text{Cov}(\epsilon_{i1}, \epsilon_{i2}). 
\]</div>
<p>The subject effects and the errors are not correlated as these represent independent partitions of the overall error. As such, <span class="math notranslate nohighlight">\(\text{Cov}(S_{i},\epsilon_{i2}) = \text{Cov}(\epsilon_{i1},S_{i}) = 0\)</span>. Similarly, the final errors are uncorrelated because the correlation has been <em>removed</em> by partitioning-out the subject effects. So <span class="math notranslate nohighlight">\(\text{Cov}(\epsilon_{i1}, \epsilon_{i2}) = 0\)</span>. This leaves</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}(y_{i1},y_{i2}) = \text{Cov}(S_{i},S_{i}).
\]</div>
<p>A key result from the definition of covariance is that the covariance of a random variable with itself is simply its variance, meaning</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}(y_{i1},y_{i2}) = \text{Cov}(S_{i},S_{i}) = \text{Var}(S_{i}) = \sigma^{2}_{b}.
\]</div>
<p>All of which is to say that the variance associated with the subject-specific deflections <em>is</em> the correlation induced by the repeated measurements.</p>
<p>…</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \text{Var}\left(y_{i1} - y_{i2}\right) &amp;= \text{Var}(y_{i1}) + \text{Var}(y_{i2}) - 2\text{Cov}(y_{i1},y_{i2}) \\
                                           &amp;= \left[\sigma^{2}_{b} + \sigma^{2}_{w}\right] + \left[\sigma^{2}_{b} + \sigma^{2}_{w}\right] - 2\sigma^{2}_{b} \\
                                           &amp;= \sigma^{2}_{w} + \sigma^{2}_{w}
\end{alignat*}
\end{split}\]</div>
<p>So, we can see that the correlation <em>cancels-out</em>, which is exactly as expected from our exploration of the <em>model of paired differences</em> from earlier.</p>
<section id="partitioning-the-error">
<h3>Partitioning the Error<a class="headerlink" href="#partitioning-the-error" title="Link to this heading">#</a></h3>
<p>Notice that a huge amount of the variation in this data was attributable to the variation between different subjects. Now that this has been removed, we can effectively treat our data as <em>one big sample from a single subject</em>. As such, the variability we can see between all pairs of measurements provides us with an indication of how <em>internally consistent</em> a single subject is across the different conditions of the task. With the overall effect of the conditions removed, this remaining variability is not related to the conditions themseleves. Rather, it is related to other sources of random variation that cause an individual’s response to change across multiple repeats of an experiment. This is known as the  <em>within-subject variance</em>.</p>
<p>The variance associated with the two conditions is of direct interest because this captures our experimental effect of interest. Both the <em>between-subjects</em> and <em>within-subject</em> variance are effectively sources of <em>error</em> because they indicate different ways that the raw data may differ from the means of the conditions. One of these errors comes from the fact that different people may respond consistently higher or lower than the mean. The other comes from the fact that, even if an individual did not respond differently from the mean, natural variation across repeats will always be there.</p>
<p>This partitioning of variance can be formally stated as</p>
<div class="math notranslate nohighlight">
\[
\text{Var}(y) = \sigma^{2} = \sigma^{2}_{b} + \sigma^{2}_{w}.
\]</div>
<p>As such, we now have <em>three</em> choices when it comes to calculating standard errors. Do we use the pooled variance of <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>? The between-subjects variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{b}\)</span>, or the within-subject variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{w}\)</span>?</p>
<p>Key Point
In a regular paired t-test, the error variance consists of the differences between the means of the groups and the raw data. Howevever, when we have repeated measurements, this difference can be further divided into two sources … This is consistent with the idea of the <em>between-subjects variance</em> <span class="math notranslate nohighlight">\(\left(\sigma^{2}_{b}\right)\)</span> and the <em>within-subject variance</em> <span class="math notranslate nohighlight">\(\left(\sigma^{2}_{w}\right)\)</span> … As such, the difference with a <em>paired</em> test is that is uses the <em>within-subject variance</em> exclusively for determining the denominator of the <span class="math notranslate nohighlight">\(t\)</span>-statistic.</p>
</section>
<section id="partitioning-the-error-as-a-decomposition-of-the-variance-covariance-matrix">
<h3>Partitioning the Error as a Decomposition of the Variance-covariance Matrix<a class="headerlink" href="#partitioning-the-error-as-a-decomposition-of-the-variance-covariance-matrix" title="Link to this heading">#</a></h3>
<p>Now, we will connect what we have done above with the idea of modelling the variance-covariance matrix. Rather than doing this <em>explicitly</em>, the method above was an <em>implicit</em> modelling of the covariance structure…</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{11} \\
    y_{12} \\
    y_{21} \\
    y_{22} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu + \alpha_{1} \\
    \mu + \alpha_{2} \\
    \mu + \alpha_{1} \\
    \mu + \alpha_{2} \\
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{b} + \sigma^{2}_{w}  &amp; \sigma^{2}_{b}                  &amp; 0           &amp; 0                     \\
    \sigma^{2}_{b}                   &amp; \sigma^{2}_{b} + \sigma^{2}_{w} &amp; 0           &amp; 0                      \\
    0                                &amp; 0                               &amp; \sigma^{2}_{b} + \sigma^{2}_{w}  &amp; \sigma^{2}_{b}            \\
    0                                &amp; 0           &amp; \sigma^{2}_{b} &amp; \sigma^{2}_{b} + \sigma^{2}_{w}  \\
\end{bmatrix}
\right)
\end{split}\]</div>
</section>
<section id="where-does-the-standard-error-come-from">
<h3>Where Does the Standard Error Come From?<a class="headerlink" href="#where-does-the-standard-error-come-from" title="Link to this heading">#</a></h3>
<p>To begin understanding what is going on here, we need to review where the value for the standard error comes from. In the context of a linear model, the standard error of <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\text{SE}\left(\hat{\beta}_{1}\right) = \sqrt{\text{Var}\left(\hat{\beta}_{1}\right)} = \sqrt{\frac{\hat{\sigma}^{2}}{\sum_{i=1}^{n}\left(x_{i1} - \bar{x}_{1}\right)}}.
\]</div>
<p>So, the standard error is the square-root of the variance of an estimate, and the variance of an estimate is simply a scaled version of the error variance from the model. This scaling is not entirely clear when represented in the format above. However, when <span class="math notranslate nohighlight">\(x_{1}\)</span> is simply a dummy variable encoding a mean difference, this simplifies to the known formula for the denominator of a <span class="math notranslate nohighlight">\(t\)</span>-test assuming equal variance in the two samples</p>
<div class="math notranslate nohighlight">
\[
\text{SE}\left(\hat{\beta}_{1}\right) = \text{SE}\left(\hat{\mu}_{1} - \hat{\mu}_{2}\right) = \sqrt{\frac{\hat{\sigma}^{2}}{\frac{1}{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}} = \sqrt{\hat{\sigma}^{2}\left(\frac{1}{n_{1}} + \frac{1}{n_{2}}\right)}.
\]</div>
<p>Here, we can more easily see that the standard error depends only upon the sample sizes and the error variance.</p>
<div class="tip admonition">
<p class="admonition-title">Key Point!</p>
<p>Under multiple repeats of the same experimnent, the sample sizes of the groups will remain the same. As such, this element of the standard error is simply a <em>constant scaling</em>. Whether the data are independent or not will not change this element of the standard error because the formula is <em>always the same</em>. The only element that can change is the <em>error variance</em>. As such, this must be the source of the difference between the <em>two-sample</em> and <em>paired</em> approaches.</p>
</div>
<p>We can verify that this formula for the standard error is correct in the <em>two-sample</em> model by calculating</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">two.sample.mod</span><span class="p">)</span><span class="o">$</span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span>
<span class="nf">sqrt</span><span class="p">(</span><span class="n">sigma2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="m">50</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">50</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">Error</span>:

<span class="o">!</span><span class="w"> </span>object<span class="w"> </span><span class="s1">&#39;two.sample.mod&#39;</span><span class="w"> </span>not<span class="w"> </span>found

    <span class="err">▆</span>

<span class="g g-Whitespace"> </span><span class="mi">1</span><span class="o">.</span> <span class="err">└─</span><span class="n">base</span><span class="p">::</span><span class="n">summary</span><span class="p">(</span><span class="n">two</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>which agrees with out results so far. As the element of most interest here is the estimate of <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>, the next obvious question is where does this come from?</p>
<p>As a review, the error variance in a linear model is estimated using</p>
<div class="math notranslate nohighlight">
\[
\hat{\sigma}^{2} = \frac{\sum_{i=1}^{n}\epsilon_{i}^{2}}{n-p},
\]</div>
<p>which is also known as the <em>residual mean square</em> or <em>error mean square</em>. We can again verify this for our example by calculating</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma2</span>

<span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">two.sample.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">two.sample.mod</span><span class="o">$</span><span class="n">df.residual</span>
</pre></div>
</div>
</div>
</div>
<p>As such, if this is the element that differs between the <em>two-sample</em> and <em>paired</em> model, then our final suspect must be the <em>model residuals</em>. More specifically, the residuals must be <em>larger</em> in the <em>two-sample</em> case and <em>smaller</em> in the <em>paired</em> case. This is the only way the standard errors can differ. But this still does not explain <em>why</em> this is the case?</p>
</section>
<section id="recreating-the-paired-t-test-in-the-linear-model">
<h3>Recreating the Paired <span class="math notranslate nohighlight">\(t\)</span>-test in the Linear Model<a class="headerlink" href="#recreating-the-paired-t-test-in-the-linear-model" title="Link to this heading">#</a></h3>
<p>From all we discussed earlier, the aim is therefore to <em>remove</em> the between-subject variance from the residuals so that the error variance of the model only contains the <em>within-subject variance</em>. If we do not do this, then <span class="math notranslate nohighlight">\(\sigma^{2} = \sigma^{2}_{b} + \sigma^{2}_{w}\)</span>, which will be too large to accurately capture the standard error of the mean difference under repeated measurements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>

<span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">50</span><span class="p">),</span><span class="n">each</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>
<span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">subject</span><span class="p">)</span>

<span class="n">paired.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y.long</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">cond</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">subject</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">paired.mod</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">Anova</span><span class="p">(</span><span class="n">paired.mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Now, the output here is a bit of mess due to all the subject effects. However, if you look at the coefficient and test for <code class="docutils literal notranslate"><span class="pre">CondB</span></code>, notice that <span class="math notranslate nohighlight">\(t = 2.495\)</span> and <span class="math notranslate nohighlight">\(p = 0.016\)</span>, which is the same as the <em>paired</em> <span class="math notranslate nohighlight">\(t\)</span>-test from earlier. Furthermore, the degrees of freedom are now correct at <span class="math notranslate nohighlight">\(49\)</span>. As such, adding the subject effects to the model has allowed the <em>between-subjects</em> error to be partitioned out and thus the remaining variance calculated from the residuals is <em>only</em> the <em>within-subject</em> error. This is the error needed to correctly estimate the standard error of the paired difference and thus the model results are now correct.</p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="intercept-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>So too will the intercept term <span class="math notranslate nohighlight">\(\mu\)</span>, but this just means that the data will be <em>mean centred</em> with 0 representing no difference between the repeated measurements.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="2.probability.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Probability Models</p>
      </div>
    </a>
    <a class="right-next"
       href="4.rm-anova.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Repeated Measures ANOVA</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-sample-vs-paired-t-tests">Two-sample vs Paired <em>t</em>-tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model-of-paired-differences">The Model of <em>Paired Differences</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paired-differences-in-r">Paired Differences in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#removing-the-effect-of-the-subjects">Removing the Effect of the Subjects</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model-of-partitioned-errors">The Model of <em>Partitioned Errors</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partitioning-the-error">Partitioning the Error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partitioning-the-error-as-a-decomposition-of-the-variance-covariance-matrix">Partitioning the Error as a Decomposition of the Variance-covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-does-the-standard-error-come-from">Where Does the Standard Error Come From?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recreating-the-paired-t-test-in-the-linear-model">Recreating the Paired <span class="math notranslate nohighlight">\(t\)</span>-test in the Linear Model</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>