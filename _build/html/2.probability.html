
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Probability Models &#8212; Linear Models with Correlated Errors</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.probability';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The Paired t-test" href="3.paired-t.html" />
    <link rel="prev" title="Repeated Measurements" href="1.designs.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models with Correlated Errors - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Linear Models with Correlated Errors - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.designs.html">Repeated Measurements</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Probability Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.paired-t.html">The Paired <em>t</em>-test</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.rm-anova.html">The Repeated Measures ANOVA</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.gls.html">Generalised Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors/issues/new?title=Issue%20on%20page%20%2F2.probability.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.probability.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-normal-distribution">The Multivariate Normal Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mean-vector">The Mean Vector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-covariance-matrix">The Variance-Covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-draws-from-a-multivariate-normal">Taking Draws from a Multivariate Normal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-multivariate-normal">Visualising the Multivariate Normal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptualising-multiple-subjects">Conceptualising Multiple Subjects</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-wide-view">The Multivariate (<em>Wide</em>) View</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-univariate-long-view">The Univariate (<em>Long</em>) View</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-probability-model">Correlation and the Probability Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-linear-model-assumptions">Correlation and the Linear Model Assumptions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-standard-errors">Correlation and the Standard Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theory">Theory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">Simulation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-models">
<h1>Probability Models<a class="headerlink" href="#probability-models" title="Link to this heading">#</a></h1>
<p>…</p>
<section id="the-multivariate-normal-distribution">
<h2>The Multivariate Normal Distribution<a class="headerlink" href="#the-multivariate-normal-distribution" title="Link to this heading">#</a></h2>
<p>In order to place repeated measurements within a probabilistic framework, we need to introduce the concept of the <em>multivariate</em> normal distribution. As opposed to the <em>univariate</em> normal distribution we have seen previously, the <em>multivariate</em> normal distribution is not associated with a single <em>random variable</em>, it is associated with a <em>random vector</em>. This is written as follows</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right).
\]</div>
<p>We will spend a bit of time unpacking this, before we see how it applies to repeated measurements.</p>
<p>To start with, let us just define what we mean by a <em>vector</em>. Although there are different ways of conceptualising a vector, for our purpose we can simply think of it as a <em>list</em> of numbers. We can either have <em>row vectors</em> or <em>column vectors</em>, which we can simply think of like the <em>rows</em> or <em>columns</em> of a spreadsheet. There are much deeper and more precise mathematical definitions of vectors as mathematical objects, but for us this is all we really need to know. A <em>random vector</em> is then a vector that contains <em>random variables</em>, rather than numbers. So, if we have <em>two</em> repeated measurements take from subject <span class="math notranslate nohighlight">\(i\)</span> we can define our outcome variable as a <em>random row vector</em> called <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span>, which has the form</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} =
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}.
\]</div>
<p>So, notice that we have packaged these measurements together into a single object, which is important for what follows. Also notice that we use <strong>bold</strong> typeface to distinguish vectors and matrices from usual variables.</p>
<section id="the-mean-vector">
<h3>The Mean Vector<a class="headerlink" href="#the-mean-vector" title="Link to this heading">#</a></h3>
<p>Notice above that the mean of the multivariate normal is <em>also</em> a vector called <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>. This contains the <em>expected value</em> of <em>both</em> random variables in <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span>. So, if the expected value of column 1 was <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and the expected value of column 2 was <span class="math notranslate nohighlight">\(\mu_{2}\)</span>, we would have</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\mu} =
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}.
\]</div>
<p>Plugging the expanded definition of <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> into the expression for the multivariate normal, we currently have</p>
<div class="math notranslate nohighlight">
\[
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\boldsymbol{\Sigma}
\right).
\]</div>
<p>If there are more repeated measurements, we simply expand the number of columns. For instance, if we had 3 repeated measurements, we could specify</p>
<div class="math notranslate nohighlight">
\[
\begin{bmatrix}
    y_{i1} &amp; y_{i2} &amp; y_{i3}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2} &amp; \mu_{3}
\end{bmatrix}, 
\boldsymbol{\Sigma}
\right).
\]</div>
<p>Or, more compactly, as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right)
\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \mathbf{y}_{i} &amp;= 
    \begin{bmatrix}
        y_{i1} &amp; y_{i2} &amp; y_{i3}
    \end{bmatrix} \\
    \boldsymbol{\mu} &amp;= 
    \begin{bmatrix}
        \mu_{1} &amp; \mu_{2} &amp; \mu_{3}
    \end{bmatrix}.
\end{alignat*}
\end{split}\]</div>
</section>
<section id="the-variance-covariance-matrix">
<h3>The Variance-Covariance Matrix<a class="headerlink" href="#the-variance-covariance-matrix" title="Link to this heading">#</a></h3>
<p>Now, for the really crucial bit. First, recall that the univariate normal distribution is parameterised by a <em>mean</em> and a <em>variance</em>. These encode the <em>centre</em> of the distribution and its <em>width</em>. This should be familiar and is written</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim\mathcal{N}(\mu,\sigma^{2}).
\]</div>
<p>The multivariate normal is exactly the same in spirit. We have already seen how a single <em>mean</em> becomes a <em>mean vector</em>. So what about the <em>variance</em>? This is not coded by a <em>vector</em>, rather it is coded by a <em>matrix</em> symbolised by <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. This is called the <em>variance-covariance</em> matrix and it has the very important job of encoding the variance of each element of <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span> <em>but also encoding the correlation between those elements</em>. This is the <em>key</em> to understanding why the multivariate normal is a useful probability model for repeated measurements.</p>
<p>To start with, we will just define a <em>matrix</em>, before seeing how <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> fits into our conceptualisation. A <em>matrix</em> is simply a collection of <em>vectors</em>. These can either be multiple row vectors, or multiple column vectors. Either way, a matrix is more like a <em>spreadsheet</em> of values, rather than an individual column or row. In the example of <em>two</em> repeated measurements, the matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> will be <span class="math notranslate nohighlight">\(2 \times 2\)</span> and have the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\Sigma} = 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}.
\end{split}\]</div>
<p>The <em>diagonal</em> elements encode the variance of <span class="math notranslate nohighlight">\(y_{i1}\)</span> and the variance of <span class="math notranslate nohighlight">\(y_{i2}\)</span> respectively. These are denoted <span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span> and <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>. The <em>off-diagonal</em> elements encode the <em>correlation</em> between <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(y_{i2}\)</span>. This is parameterised in similar units to the variance and so is known as the <em>covariance</em>. This can be thought of as a <em>scaled</em> version of correlation. The relationship between correlation and covariance is as follows</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}\left(y_{i1},y_{i2}\right) = \sigma_{12} = \sigma_{21} = \rho\sigma_{1}\sigma_{2}, 
\]</div>
<p>where <span class="math notranslate nohighlight">\(\rho\)</span> is the correlation, <span class="math notranslate nohighlight">\(\sigma_{1}\)</span> is the <em>standard deviation</em> of <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{2}\)</span> is the <em>standard deviation</em> of <span class="math notranslate nohighlight">\(y_{i2}\)</span>. So this is really just different units encoding the same idea. Correlation re-scales covariance into the range <span class="math notranslate nohighlight">\([-1, 1]\)</span>. Because of this, we will use <em>correlation</em> and <em>covariance</em> somewhat interchangeably as, for our purpose, they capture the same concept. We can therefore think of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> as similar in spirit to a <em>correlation</em> matrix between the repeated measurements. As such, the degree to which the multivariate normal can form an accurate <em>data-generating</em> model will depend upon the values in <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>, the <em>diagonal</em> elements of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> and, most crucially for repeated measurements, the <em>off-diagonal</em> elements of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>.</p>
<p>We can put this all together to give our final probabilistic model for two repeated measurements</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\right)
\end{split}\]</div>
<p>Or, more compactly, as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right)
\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \mathbf{y}_{i} &amp;= 
    \begin{bmatrix}
        y_{i1} &amp; y_{i2}
    \end{bmatrix} \\
    \boldsymbol{\mu} &amp;= 
    \begin{bmatrix}
        \mu_{1} &amp; \mu_{2}
    \end{bmatrix} \\
    \boldsymbol{\Sigma} &amp;= 
    \begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\end{alignat*}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\sigma_{12} = \sigma_{21} = \rho\sigma_{1}\sigma_{2}.
\]</div>
</section>
<section id="taking-draws-from-a-multivariate-normal">
<h3>Taking Draws from a Multivariate Normal<a class="headerlink" href="#taking-draws-from-a-multivariate-normal" title="Link to this heading">#</a></h3>
<p>As we have see above, the multivariate normal distribution is able to describes the behaviour of <em>multiple</em> random variables by describing the data-generating process of a <em>random vector</em>. This includes both the expected value of each element of the vector <em>and</em>, most crucially, how <em>correlated</em> those values are. In the case of a 2-dimensional multivariate normal, every time we draw data from this distribution we get <em>two</em> values back. The first has a population mean of <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and a variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span>. The second has a population mean of <span class="math notranslate nohighlight">\(\mu_{2}\)</span> and a variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>. Most importantly, the two values will be <em>correlated</em> by a factor of <span class="math notranslate nohighlight">\(\sigma_{12}\)</span>. If <span class="math notranslate nohighlight">\(\sigma_{12} = 0\)</span> then this will be no different to drawing two values separately from a univariate normal distribution and there is little point in using the multivariate normal. However, if <span class="math notranslate nohighlight">\(|\sigma_{12}| &gt; 0\)</span>, then the two values will be related, where the strength of this relationship scales with the magnitude of the covariance.</p>
<p>To see how the multivariate normal works as a sampling model, we can simulate drawing data from a multivariate normal distribution in <code class="docutils literal notranslate"><span class="pre">R</span></code>. Base <code class="docutils literal notranslate"><span class="pre">R</span></code> does not have any multivariate distribution functions, but we can use the <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">MASS</span></code> package. To do so, we provide a <em>mean vector</em> and a <em>variance-covariance matrix</em>, alongside the number of independent draws we want to take. For instance, we can draw a single pair of values from the multivariate normal defined by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y}_{i} \sim\mathcal{N}\left(
\begin{bmatrix}
    2 &amp; 3
\end{bmatrix}, 
\begin{bmatrix}
    1   &amp; 1.6  \\
    1.6 &amp; 4
\end{bmatrix}
\right)
\end{split}\]</div>
<p>using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">666</span><span class="p">)</span>

<span class="n">var.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">                           </span><span class="c1"># Variance 1</span>
<span class="n">var.2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span><span class="w">                           </span><span class="c1"># Variance 2</span>
<span class="n">rho</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.8</span><span class="w">                         </span><span class="c1"># Correlation</span>
<span class="n">cov</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rho</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var.1</span><span class="p">)</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var.2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Covariance</span>

<span class="n">Mu</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">)</span><span class="w">                                  </span><span class="c1"># Mean vector</span>
<span class="n">Sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">var.1</span><span class="p">,</span><span class="w"> </span><span class="n">cov</span><span class="p">,</span>
<span class="w">                  </span><span class="n">cov</span><span class="p">,</span><span class="w">   </span><span class="n">var.2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Variance-covariance matrix</span>

<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 1.624908 4.941023
</pre></div>
</div>
</div>
</div>
<p>So, we can see that we get <em>two</em> values back whenever we sample from this distribution. These can be thought of as random draw from the same experimental unit. For instance, we can think of these as representing responses from subject <span class="math notranslate nohighlight">\(i\)</span> in experimental condition 1 and experimental condition 2. This is parameterised by the mean vector</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">Mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 2 3
</pre></div>
</div>
</div>
</div>
<p>and by the variance-covariance matrix</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     [,1] [,2]
[1,]  1.0  1.6
[2,]  1.6  4.0
</pre></div>
</div>
</div>
</div>
<p>Note that the correlation was set to <span class="math notranslate nohighlight">\(\rho = 0.8\)</span> in the code above and was converted into covariance based on the variances of <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>. As we can see, covariance is not constrained to <span class="math notranslate nohighlight">\(\left[-1, 1\right]\)</span> like correlation is and so does not have the same ease of interpretation. As such, whenever we want to <em>interpret</em> dependence, correlation is more useful. However, for calculations involving variance, covariance is needed so that the units are compatible.</p>
</section>
</section>
<section id="visualising-the-multivariate-normal">
<h2>Visualising the Multivariate Normal<a class="headerlink" href="#visualising-the-multivariate-normal" title="Link to this heading">#</a></h2>
<p>Although we have now discussed the mechanics of the multivariate normal, an easier way to conceptualise how the multivariate normal works is to <em>visualise</em> it. The most important element to recognise here is that the multivariate normal represents a probability density across <em>multiple</em> dimensions. As such, in order to visualise it, we have to restrict ourselves to only 2-dimensions. The multivariate normal can have many more dimensions than this, we just cannot visualise it. This is similar in spirit to multiple regression, where we can have as many predictor as we want, but can only visualise the regression plane when we have 2 of them.</p>
<p>A basic 2-dimensional normal distribution is shown below.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/99962a1f4c140a5589c428e0dd832bd28cd65e6dd855d77792bee742cdbe9ca1.png" src="_images/99962a1f4c140a5589c428e0dd832bd28cd65e6dd855d77792bee742cdbe9ca1.png" />
</div>
</div>
<p>Because this is 2-dimensional, it is defined as a probability distribution for the random vector</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} =
\begin{bmatrix}
    y_{1} &amp; y_{2}
\end{bmatrix}.
\]</div>
<p>Each of the random variables in this vector gets its own axis. So the first horizontal axis represents possible values of <span class="math notranslate nohighlight">\(y_{1}\)</span>, and the second horizontal axis represents possible values of <span class="math notranslate nohighlight">\(y_{2}\)</span>. The density of the distribution then gives the <em>joint-probability</em> of all possible pairs of values for <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>. Pick any point on the surface and it represents the probability of the associated points on the <span class="math notranslate nohighlight">\(y_{1}\)</span> axis and the <span class="math notranslate nohighlight">\(y_{2}\)</span> axis <em>occurring together</em>. From this we can see that the <em>most probable</em> joint values are when <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span> are equal to their expected value. In other words, the peak of the distribution occurs at the mean of <span class="math notranslate nohighlight">\(y_{1}\)</span> <em>and</em> the mean of <span class="math notranslate nohighlight">\(y_{2}\)</span>. For any other values, the joint-probability depends upon the variance within each dimension, as well as the covariance.</p>
<p>We can also view this distribution from the <em>top-down</em> as a heat map, where <em>brighter</em> colours correspond to <em>greater</em> density. This can be a useful perspective once we see how correlation influences the shape of the multivariate normal.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/4fcf4d708bd7373e0f65916525a46a50458796e29831fb5acd8b4362aff6fa95.png" src="_images/4fcf4d708bd7373e0f65916525a46a50458796e29831fb5acd8b4362aff6fa95.png" />
</div>
</div>
<p>In the example above, the variance-covariance matrix was defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\Sigma} = 
\begin{bmatrix}
    \sigma^{2} &amp; 0 \\
    0 &amp; \sigma^{2}
\end{bmatrix}
\end{split}\]</div>
<p>In other words, the variance of each dimension is the same and there is <em>no correlation</em>. This creates the perfect symmetry we see in the shape above. Now, let us see what happens when there <em>is</em> correlation. If we keep everything else the same but set <span class="math notranslate nohighlight">\(\rho = 0.8\)</span>, we get the distribution shown below.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/3cf618272d73eeac502cf3ab17267caf15089bbcfcc2a5188bc61df43d7c3e2e.png" src="_images/3cf618272d73eeac502cf3ab17267caf15089bbcfcc2a5188bc61df43d7c3e2e.png" />
</div>
</div>
<p>As we can see, correlation has created a “shark-fin” in the probability density. This is clearest when we see the top-down density plot of this distribution.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/202d01cc5d163e9b75e44e3e464a8ef33642a3b89e17eeef457b6f3554fc80cb.png" src="_images/202d01cc5d163e9b75e44e3e464a8ef33642a3b89e17eeef457b6f3554fc80cb.png" />
</div>
</div>
<p>To see more clearly how this shape connects with the idea of correlation, we will see how the probability distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> changes for a given value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. The plots below show a rotated view of the multivariate normal where we are focussing on the <span class="math notranslate nohighlight">\(y_{2}\)</span>-axis. The <em>left</em> column shows no correlation (<span class="math notranslate nohighlight">\(\rho=0\)</span>) and the <em>right</em> column shows a strong correlation (<span class="math notranslate nohighlight">\(\rho=0.8\)</span>). The distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> when <span class="math notranslate nohighlight">\(y_{1}\)</span> is fixed to a certain value is superimposed in blue. This is a <em>slice</em> through the multivariate normal. The <em>top</em> row shows <span class="math notranslate nohighlight">\(P(y_{2}|y_{1}=-1)\)</span> and the <em>bottom</em> row shows <span class="math notranslate nohighlight">\(P(y_{2}|y_{1}=1)\)</span>. Take a moment to study these so you are clear what they are showing.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/1e17249118bc5508f03f4359f180952c0fbf1f7adc84ad244eb0278a0982f584.png" src="_images/1e17249118bc5508f03f4359f180952c0fbf1f7adc84ad244eb0278a0982f584.png" />
</div>
</div>
<p>Notice that when there is <em>no correlation</em>, the distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> does not change with the value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. In other words, the value of <span class="math notranslate nohighlight">\(y_{1}\)</span> has no bearing on the probability of different values of <span class="math notranslate nohighlight">\(y_{2}\)</span>. This is the essence of <em>independence</em>. When there <em>is</em> correlation, the shape of the distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> <em>shifts</em> depending upon the value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. Notice in the <em>right</em> column that when <span class="math notranslate nohighlight">\(y_{1} = -1\)</span>, the distribution of <span class="math notranslate nohighlight">\(y_{2}\)</span> is centred on a different value compared to when <span class="math notranslate nohighlight">\(y_{1} = 1\)</span>. This change in expected value is because of the “shark-fin” shape to the density. In essence, the most probable value of <span class="math notranslate nohighlight">\(y_{2}\)</span> changes based on the value of <span class="math notranslate nohighlight">\(y_{1}\)</span>. The stronger the correlation, the sharper this “shark fin” becomes and the more the expected value of one random value tracks the value of the other. This is the essence of <em>dependence</em>.</p>
</section>
<section id="conceptualising-multiple-subjects">
<h2>Conceptualising Multiple Subjects<a class="headerlink" href="#conceptualising-multiple-subjects" title="Link to this heading">#</a></h2>
<section id="the-multivariate-wide-view">
<h3>The Multivariate (<em>Wide</em>) View<a class="headerlink" href="#the-multivariate-wide-view" title="Link to this heading">#</a></h3>
<p>… This is associated with <em>wide-formatted</em> data.</p>
<p>We can repeat this again for <em>multiple</em> subjects to see the full conceptualisation of this experiment. If we had <span class="math notranslate nohighlight">\(n=15\)</span> then we can simulate our simple repeated measurements experiment using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">777</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>           [,1]     [,2]
 [1,] 2.1571710 3.772133
 [2,] 1.3168746 2.926946
 [3,] 2.6566917 3.312552
 [4,] 1.4093942 2.833913
 [5,] 3.3962213 4.712967
 [6,] 3.2315357 2.947249
 [7,] 2.1202807 3.264324
 [8,] 3.2996450 3.804416
 [9,] 1.4016128 3.207103
[10,] 1.1858382 3.095126
[11,] 1.5763201 2.846384
[12,] 2.6030285 2.499737
[13,] 0.2235982 1.207587
[14,] 2.4386245 2.497327
[15,] 4.3641379 5.021615
</pre></div>
</div>
</div>
</div>
<p>So, now we have 15 measurements from condition 1 and 15 measurements from conditon 2. These are arranged per-subject, so the first row is the two measurements from subject 1, the second row is the two measurments from subject 2 and so on. Importantly, the two columns are <em>correlated</em>, which we can see using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">cor</span><span class="p">(</span><span class="n">y</span><span class="p">[,</span><span class="m">1</span><span class="p">],</span><span class="n">y</span><span class="p">[,</span><span class="m">2</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 0.7651892
</pre></div>
</div>
</div>
</div>
<p>which, as we can see, is not too far off the value of <span class="math notranslate nohighlight">\(\rho\)</span> we used for the simulations. Obviously, the more data we have the more precise this estimate of the correlation would be and the closer to the true value it would become.</p>
</section>
<section id="the-univariate-long-view">
<h3>The Univariate (<em>Long</em>) View<a class="headerlink" href="#the-univariate-long-view" title="Link to this heading">#</a></h3>
<p>… The way to see this is to recognise that it does not matter whether we conceptualise each subject as a <em>row</em> or <em>column</em> vector, the probability model remains the same. So, the following two expressions are entirely equivalent</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\right)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} \\
    y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} \\
    \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\right)
\end{split}\]</div>
<p>If we take the <em>second</em> perspective of each subject being a <em>column-vector</em>, we can now <em>stack</em> the subjects to produce a single outcome variable, suitable for use in our linear model framework.</p>
<p>… This is associated with <em>long-formatted</em> data.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{11} \\
    y_{12} \\
    y_{21} \\
    y_{22} \\
    y_{31} \\
    y_{32} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12} &amp; 0 &amp; 0 &amp; 0 &amp; 0  \\
    \sigma_{21}    &amp; \sigma^{2}_{2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; \sigma^{2}_{1} &amp; \sigma_{12} &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; \sigma_{21}    &amp; \sigma^{2}_{2} &amp; 0 &amp; 0  \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; \sigma^{2}_{1} &amp; \sigma_{12} \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; \sigma_{21}    &amp; \sigma^{2}_{2} \\
\end{bmatrix}
\right)
\end{split}\]</div>
<p>This is a 6-dimensional normal distribution, so we would struggly to visualise this in any meaningful way. However, as mentioned last semester, dimensions are just a mathematical tool for keeping track of information. We do not <em>have</em> to be able to visualise them in order for this to be useful or make sense. The more important element here is the <em>structure</em>.</p>
<p>As we can see, each subject is given by the <em>first</em> index of <span class="math notranslate nohighlight">\(y\)</span>. So, we have two measurements from subject 1, two measurements from subject 2 and two measurements from subject 3. We conceptualise this dataset as a single draw from a 6-dimensional normal distribution. The mean vector tells us that the population means for each condition are identical across subjects, so our interest is estimating <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and <span class="math notranslate nohighlight">\(\mu_{2}\)</span>. If the data came from 6 different subjects, this would be no different from assuming <span class="math notranslate nohighlight">\(y_{i1} \sim \mathcal{N}(\mu_{1}, \sigma^{2}_{1})\)</span> and <span class="math notranslate nohighlight">\(y_{i2} \sim \mathcal{N}(\mu_{2}, \sigma^{2}_{2})\)</span>. However, because these are <em>repeated measurements</em>, the important aspect here is the correlation structure embedded in the <em>variance-covariance</em> matrix. This has a <em>block-diagonal</em> structure, which implies that there is <em>no correlation</em> between measurements from <em>different</em> subjects. This seems fair, as it is usually unlikely that separate subjects would affect each other. However, <em>within</em> each subject we assume a separate variance for each condition (<span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span>, <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>) and some <em>non-zero</em> covariance (<span class="math notranslate nohighlight">\(\sigma_{12} = \sigma_{21}\)</span>) that captures how correlated the responses are from an individual subject.</p>
</section>
</section>
<section id="correlation-and-the-probability-model">
<h2>Correlation and the Probability Model<a class="headerlink" href="#correlation-and-the-probability-model" title="Link to this heading">#</a></h2>
<p>… We will now see how these issues solidify within the context of the probability model we have established.</p>
<section id="correlation-and-the-linear-model-assumptions">
<h3>Correlation and the Linear Model Assumptions<a class="headerlink" href="#correlation-and-the-linear-model-assumptions" title="Link to this heading">#</a></h3>
<p>… In order to work with the linear model machinery, we need our outcome to be a <em>single</em> variable, rather than <em>multiple</em> variables.</p>
<p>Although this dataset is in the <em>wide</em> format, it is important to realise that <code class="docutils literal notranslate"><span class="pre">t1</span></code>, <code class="docutils literal notranslate"><span class="pre">t2</span></code> and <code class="docutils literal notranslate"><span class="pre">t3</span></code> are <em>not</em> different variables. They are all measurements of <code class="docutils literal notranslate"><span class="pre">selfesteem</span></code> organised by subject. The reality is that these are all the <em>same</em> variable, as is made clearer by converting this dataset to <em>long</em> format</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">reshape2</span><span class="p">)</span>

<span class="c1"># reshape wide -&gt; long</span>
<span class="n">selfesteem.long</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">melt</span><span class="p">(</span><span class="n">selfesteem</span><span class="p">,</span><span class="w">               </span><span class="c1"># wide data frame</span>
<span class="w">                        </span><span class="n">id.vars</span><span class="o">=</span><span class="s">&#39;id&#39;</span><span class="p">,</span><span class="w">             </span><span class="c1"># what stays fixed?</span>
<span class="w">                        </span><span class="n">variable.name</span><span class="o">=</span><span class="s">&quot;time&quot;</span><span class="p">,</span><span class="w">     </span><span class="c1"># name for the new predictor</span>
<span class="w">                        </span><span class="n">value.name</span><span class="o">=</span><span class="s">&quot;selfesteem&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># name for the new outcome</span>

<span class="n">selfesteem.long</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">selfesteem.long</span><span class="p">[</span><span class="nf">order</span><span class="p">(</span><span class="n">selfesteem.long</span><span class="o">$</span><span class="n">id</span><span class="p">),]</span><span class="w"> </span><span class="c1"># order by ID</span>
<span class="nf">rownames</span><span class="p">(</span><span class="n">selfesteem.long</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">30</span><span class="p">)</span><span class="w">                         </span><span class="c1"># fix row names</span>

<span class="nf">print</span><span class="p">(</span><span class="n">selfesteem.long</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">Error</span>:

<span class="o">!</span><span class="w"> </span>object<span class="w"> </span><span class="s1">&#39;selfesteem&#39;</span><span class="w"> </span>not<span class="w"> </span>found

    <span class="err">▆</span>

<span class="g g-Whitespace"> </span><span class="mi">1</span><span class="o">.</span> <span class="err">└─</span><span class="n">reshape2</span><span class="p">::</span><span class="n">melt</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>So, now we have our single outcome variable <span class="math notranslate nohighlight">\(y\)</span>, suitable for use in a linear model. Except that we now have an outcome variable where <em>individual elements are not independent</em>. Rather than each row representing an independent draw from some probability distribution, we now have rows that are <em>correlated</em>, based on whether they come from the same subject.</p>
<div class="tip admonition">
<p class="admonition-title">Why Are Repeated Measurements Correlated?</p>
<p>This is, in effect, a principle of reality. There is an <em>internal consistency</em> to people that means that they will produce a similar pattern of results across repeats.</p>
</div>
<p>Why does the correlation matter? Recall that a core assumption of the normal linear model is that the data/errors are <span class="math notranslate nohighlight">\(i.i.d.\)</span> We previously wrote this as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    y &amp;= \mu + \epsilon \\
    \epsilon &amp;\sim^{i.i.d.}\mathcal{N}(0,\sigma^{2})
\end{alignat*}
\end{split}\]</div>
<p>Under repeated measurements, the <span class="math notranslate nohighlight">\(independent\)</span> criteria is clearly broken. Where this is most important is for <em>estimation</em>. Both OLS and MLE/REML assume independence when performing estimation. When the data are <em>dependent</em>, this causes bias to creep in, rendering some of the parameter estimates <em>larger</em> or <em>smaller</em> than they should be. We will discuss this in more detail further below, but this should be enough for the moment to see why this might be a problem for the approaches we discussed last semester.</p>
</section>
<section id="correlation-and-the-standard-errors">
<h3>Correlation and the Standard Errors<a class="headerlink" href="#correlation-and-the-standard-errors" title="Link to this heading">#</a></h3>
<p>Given everything above, what are the implications for our statistical model when there is correlation between measurements? As we have discussed, nothing about the <em>mean function</em> changes. So if we are only interested in estimating effects as defined within the mean function, nothing changes. This means that regression slopes, cell means and mean differences remain unchanged. However, what <em>does</em> change is the <em>variance function</em>. The biggest practical implication of this is that <em>correlation changes the standard errors</em>. This means that our <em>uncertainty</em> is different under correlation. If we get this wrong, the standard errors will be wrong, the test statistical will be wrong, the confidence intervals will be wrong and the <span class="math notranslate nohighlight">\(p\)</span>-values will be wrong. In short, neglecting to model the correlational structure will make our <em>inference wrong</em>. In a more general sense, neglecting the correlational structure will lead to a poor model of the data-generating process, because correlation is a <em>fundamental</em> element of how the data came to be. If we ignore it, we can never hope to have an accurate picture of where our data came from.</p>
</section>
<section id="theory">
<h3>Theory<a class="headerlink" href="#theory" title="Link to this heading">#</a></h3>
<p>The simplest demonstration of how correlation affects uncertainty comes directly from the properties of a random variable. It is a standard result in probability theory that the variance of the <em>difference</em> between two random variables (<span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>) is given by</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y_{1} - y_{2}\right) = \text{Var}\left(y_{1}\right) + \text{Var}\left(y_{2}\right) - 2\text{Cov}\left(y_{1},y_{2}\right).
\]</div>
<p>To understand this, consider the fact that subtracting two random variables produces a <em>new</em> random variable that captures their <em>difference</em>. This new random variable will also have a distribution. So what we are thinking above in the above equation is the <em>width</em> of the distribution of the <em>difference</em> between <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>. What this is saying is that the width of this distribution is a function of the variances from the two individual distributions <em>and</em> their degree of correlation. If the correlation is <em>positive</em> the variance will shrink, if the correlation is <em>negative</em> the variance will <em>grow</em>. Either way, our uncertainty around the difference between these two random variables <em>depends</em> upon their degree of correlation</p>
</section>
<section id="simulation">
<h3>Simulation<a class="headerlink" href="#simulation" title="Link to this heading">#</a></h3>
<p>To see this, we can run a simulation in <code class="docutils literal notranslate"><span class="pre">R</span></code>. First, we use the <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">MASS</span></code> package to simulate 1,000 realisations of two repeated measurements with a correlation of <span class="math notranslate nohighlight">\(\rho = 0.8\)</span>. To do this, we use the following sampling model:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} \\
    y_{i2} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    2 \\
    3 \\
\end{bmatrix},
\begin{bmatrix}
    1 &amp; 0.8 \\
    0.8 &amp; 1 \\
\end{bmatrix}
\right)
\end{split}\]</div>
<p>We can then compare this to 1,000 realisations of two independent measurements with a correlation of <span class="math notranslate nohighlight">\(\rho = 0\)</span>. To do this, we use the following sampling model</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} \\
    y_{i2} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    2 \\
    3 \\
\end{bmatrix},
\begin{bmatrix}
    1 &amp; 0 \\
    0 &amp; 1 \\
\end{bmatrix}
\right).
\end{split}\]</div>
<p>The <code class="docutils literal notranslate"><span class="pre">R</span></code> code is</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">Sigma.dep</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">var</span><span class="p">,</span><span class="n">cov</span><span class="p">,</span>
<span class="w">                      </span><span class="n">cov</span><span class="p">,</span><span class="n">var</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>

<span class="n">Sigma.ind</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">var</span><span class="p">,</span><span class="w">   </span><span class="m">0</span><span class="p">,</span>
<span class="w">                        </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">var</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>

<span class="n">y.dep</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma.dep</span><span class="p">)</span><span class="w"> </span><span class="c1"># dependence</span>
<span class="n">y.ind</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma.ind</span><span class="p">)</span><span class="w"> </span><span class="c1"># independence</span>
</pre></div>
</div>
</div>
</div>
<p>In both cases, we conceptualise the columns of <code class="docutils literal notranslate"><span class="pre">y.dep</span></code> and <code class="docutils literal notranslate"><span class="pre">y.ind</span></code> as two different conditions of an experiment. As such, our interest lies in the <em>difference</em> between the columns. As a final step, we subtract the columns and then compare the distributions of differences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">diff.dep</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">y.dep</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y.dep</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span>
<span class="n">diff.ind</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">y.ind</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y.ind</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span>

<span class="nf">hist</span><span class="p">(</span><span class="n">diff.dep</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-8</span><span class="p">,</span><span class="m">6</span><span class="p">),</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&#39;Mean Difference&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&#39;Correlated&#39;</span><span class="p">)</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">diff.ind</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-8</span><span class="p">,</span><span class="m">6</span><span class="p">),</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&#39;Mean Difference&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&#39;Uncorrelated&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that the distribution of repeated measurement differences is much <em>narrower</em> than the distribution of independent differences. This is the theory in action. … This is why there is a <em>power</em> advantage to repeated measurements. … The variability of the difference is much smaller because the conditions are going to be <em>more similar</em> when they are correlated. As such, we do not expect wild differences between them. The two conditions should generally be very similar and thus their difference should be consistently smaller than in the independent case, where much larger differences are possible.</p>
<p>We can see how this will affect the <span class="math notranslate nohighlight">\(t\)</span>-statistic by calculating</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.designs.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Repeated Measurements</p>
      </div>
    </a>
    <a class="right-next"
       href="3.paired-t.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Paired <em>t</em>-test</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-normal-distribution">The Multivariate Normal Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mean-vector">The Mean Vector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-covariance-matrix">The Variance-Covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-draws-from-a-multivariate-normal">Taking Draws from a Multivariate Normal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-multivariate-normal">Visualising the Multivariate Normal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptualising-multiple-subjects">Conceptualising Multiple Subjects</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-wide-view">The Multivariate (<em>Wide</em>) View</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-univariate-long-view">The Univariate (<em>Long</em>) View</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-probability-model">Correlation and the Probability Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-linear-model-assumptions">Correlation and the Linear Model Assumptions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-standard-errors">Correlation and the Standard Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theory">Theory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">Simulation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>