
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Probability Models for Repeated Measurements &#8212; Linear Models with Correlated Errors</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.probability';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The Paired t-test" href="3.paired-t.html" />
    <link rel="prev" title="Repeated Measurement Designs" href="1.designs.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models with Correlated Errors - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models with Correlated Errors - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.designs.html">Repeated Measurement Designs</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Probability Models for Repeated Measurements</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.paired-t.html">The Paired <em>t</em>-test</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.rm-anova.html">The Repeated Measures ANOVA</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.gls.html">Generalised Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/correlated-errors/issues/new?title=Issue%20on%20page%20%2F2.probability.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.probability.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability Models for Repeated Measurements</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-normal-distribution">The Multivariate Normal Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mean-vector">The Mean Vector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-covariance-matrix">The Variance-Covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-draws-from-a-multivariate-normal">Taking Draws from a Multivariate Normal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-multivariate-normal">Visualising the Multivariate Normal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptualising-multiple-subjects">Conceptualising Multiple Subjects</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-wide-view">The Multivariate (<em>Wide</em>) View</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-univariate-long-view">The Univariate (<em>Long</em>) View</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-probability-model">Correlation and the Probability Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-linear-model-assumptions">Correlation and the Linear Model Assumptions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-standard-errors">Correlation and the Standard Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theory">Theory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">Simulation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-models-for-repeated-measurements">
<h1>Probability Models for Repeated Measurements<a class="headerlink" href="#probability-models-for-repeated-measurements" title="Link to this heading">#</a></h1>
<p>…</p>
<section id="the-multivariate-normal-distribution">
<h2>The Multivariate Normal Distribution<a class="headerlink" href="#the-multivariate-normal-distribution" title="Link to this heading">#</a></h2>
<p>In order to place repeated measurements within a probabilistic framework, we need to introduce the concept of the <em>multivariate</em> normal distribution. As opposed to the <em>univariate</em> normal distribution we have seen previously, the <em>multivariate</em> normal distribution is not associated with a single <em>random variable</em>, it is associated with a <em>random vector</em>. This is written as follows</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} \sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right).
\]</div>
<p>We will spend a bit of time unpacking this, before we see how it applies to repeated measurements.</p>
<p>To start with, let us just define what we mean by a <em>vector</em>. Although there are different ways of conceptualising a vector, for our purpose we can simply think of it as a <em>list</em> of numbers. We can either have <em>row vectors</em> or <em>column vectors</em>, which we can simply think of like the <em>rows</em> or <em>columns</em> of a spreadsheet. There are much deeper and more precise mathematical definitions of vectors as mathematical objects, but for us this is all we really need to know. A <em>random vector</em> is then a vector that contains <em>random variables</em>, rather than numbers. So, if we have <em>two</em> repeated measurements take from subject <span class="math notranslate nohighlight">\(i\)</span> we can define our outcome variable as a <em>random row vector</em> called <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span>, which has the form</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} =
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}.
\]</div>
<p>So, notice that we have packaged these measurements together into a single object, which is important for what follows. Also notice that we use <strong>bold</strong> typeface to distinguish vectors and matrices from usual variables.</p>
<section id="the-mean-vector">
<h3>The Mean Vector<a class="headerlink" href="#the-mean-vector" title="Link to this heading">#</a></h3>
<p>Notice above that the mean of the multivariate normal is <em>also</em> a vector called <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>. This contains the <em>expected value</em> of <em>both</em> random variables in <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span>. So, if the expected value of column 1 was <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and the expected value of column 2 was <span class="math notranslate nohighlight">\(\mu_{2}\)</span>, we would have</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\mu} =
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}.
\]</div>
<p>Plugging the expanded definition of <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> into the expression for the multivariate normal, we currently have</p>
<div class="math notranslate nohighlight">
\[
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\boldsymbol{\Sigma}
\right).
\]</div>
<p>If there are more repeated measurements, we simply expand the number of columns. For instance, if we had 3 repeated measurements, we could specify</p>
<div class="math notranslate nohighlight">
\[
\begin{bmatrix}
    y_{i1} &amp; y_{i2} &amp; y_{i3}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2} &amp; \mu_{3}
\end{bmatrix}, 
\boldsymbol{\Sigma}
\right).
\]</div>
<p>Or, more compactly,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \mathbf{y}_{i} &amp;\sim\mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}\right) \\
    \mathbf{y}_{i} &amp;= 
    \begin{bmatrix}
        y_{i1} &amp; y_{i2} &amp; y_{i3}
    \end{bmatrix} \\
    \boldsymbol{\mu} &amp;= 
    \begin{bmatrix}
        \mu_{1} &amp; \mu_{2} &amp; \mu_{3}
    \end{bmatrix}.
\end{alignat*}
\end{split}\]</div>
</section>
<section id="the-variance-covariance-matrix">
<h3>The Variance-Covariance Matrix<a class="headerlink" href="#the-variance-covariance-matrix" title="Link to this heading">#</a></h3>
<p>Now, for the really crucial bit. First, recall that the univariate normal distribution is parameterised by a <em>mean</em> and a <em>variance</em>. These encode the <em>centre</em> of the distribution and its <em>width</em>. This should be familiar and is written</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim\mathcal{N}(\mu,\sigma^{2}).
\]</div>
<p>The multivariate normal is exactly the same in spirit. We have already seen how a single <em>mean</em> becomes a <em>mean vector</em>. So what about the <em>variance</em>? This is not coded by a <em>vector</em>, rather it is coded by a <em>matrix</em> symbolised by <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. This is called the <em>variance-covariance</em> matrix and it has the very important job of encoding the variance of each element of <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span> <em>but also encoding the correlation between those elements</em>. This is the <em>key</em> to understanding why the multivariate normal is a useful probability model for repeated measurements.</p>
<p>To start with, we will just define a <em>matrix</em>, before seeing how <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> fits into our conceptualisation. A <em>matrix</em> is simply a collection of <em>vectors</em>. These can either be multiple row vectors, or multiple column vectors. Either way, a matrix is more like a <em>spreadsheet</em> of values, rather than an individual column or row. In the example of <em>two</em> repeated measurements, the matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> will be <span class="math notranslate nohighlight">\(2 \times 2\)</span> and have the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\Sigma} = 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}.
\end{split}\]</div>
<p>The <em>diagonal</em> elements encode the variance of <span class="math notranslate nohighlight">\(y_{i1}\)</span> and the variance of <span class="math notranslate nohighlight">\(y_{i2}\)</span> respectively. These are denoted <span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span> and <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>. The <em>off-diagonal</em> elements encode the <em>correlation</em> between <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(y_{i2}\)</span>. This is parameterised in similar units to the variance and so is known as the <em>covariance</em>. This can be thought of as a <em>scaled</em> version of correlation. The relationship between correlation and covariance is as follows</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}\left(y_{i1},y_{i2}\right) = \sigma_{12} = \sigma_{21} = \rho\sigma_{1}\sigma_{2}, 
\]</div>
<p>where <span class="math notranslate nohighlight">\(\rho\)</span> is the correlation, <span class="math notranslate nohighlight">\(\sigma_{1}\)</span> is the <em>standard deviation</em> of <span class="math notranslate nohighlight">\(y_{i1}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{2}\)</span> is the <em>standard deviation</em> of <span class="math notranslate nohighlight">\(y_{i2}\)</span>. So this is really just different units encoding the same idea. Correlation re-scales covariance into the range <span class="math notranslate nohighlight">\([-1, 1]\)</span>. Because of this, we will use <em>correlation</em> and <em>covariance</em> somewhat interchangeably as, for our purpose, they capture the same concept. We can therefore think of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> as similar in spirit to a <em>correlation</em> matrix between the repeated measurements. As such, the degree to which the multivariate normal can form an accurate <em>data-generating</em> model will depend upon the values in <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>, the <em>diagonal</em> elements of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> and, most crucially for repeated measurements, the <em>off-diagonal</em> elements of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\right)
\end{split}\]</div>
</section>
<section id="taking-draws-from-a-multivariate-normal">
<h3>Taking Draws from a Multivariate Normal<a class="headerlink" href="#taking-draws-from-a-multivariate-normal" title="Link to this heading">#</a></h3>
<p>So, taking all the above into account, the multivariate normal distribution is able to describes the behaviour of the <em>vector as a whole</em>, rather than the individual random variables <em>in</em> the vector. This includes both the expected value of each column <em>and</em>, most crucially, how <em>correlated</em> those values are.</p>
<p>So, every time we draw data from this multivariate distribution, we actually get <em>two</em> values. The first has a population mean of <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and a variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span>. The second has a population mean of <span class="math notranslate nohighlight">\(\mu_{2}\)</span> and a variance of <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>. Most importantly, the two values will be <em>correlated</em> by a factor of <span class="math notranslate nohighlight">\(\sigma_{12}\)</span>. If <span class="math notranslate nohighlight">\(\sigma_{12} = 0\)</span> then this will be no different to drawing two values from a univariate normal distribution, as the values will be uncorrelated. The value of the first draw will not influence the value of the second draw in any way. However, if <span class="math notranslate nohighlight">\(|\sigma_{12}| &gt; 0\)</span> then the two draws will be related, with their values becoming more and more similar the larger the correlation becomes.</p>
<p>We can simulate drawing data from a multivariate normal disribution in <code class="docutils literal notranslate"><span class="pre">R</span></code> by using the <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">MASS</span></code> package. To do so, we provide a <em>vector</em> of means and a variance-covariance matrix. For instance, drawing a single-subject from an experiment with 2 repeated measurement conditions can be simulated using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">666</span><span class="p">)</span>

<span class="n">var</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">                                  </span><span class="c1"># Variance of condition 1 &amp; 2</span>
<span class="n">rho</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.8</span><span class="w">                                </span><span class="c1"># Correlation between conditions 1 &amp; 2</span>
<span class="n">cov</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rho</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span><span class="w">            </span><span class="c1"># Covariance between conditions 1 &amp; 2</span>

<span class="n">Mu</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">)</span><span class="w">                             </span><span class="c1"># Mean vector</span>
<span class="n">Sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">var</span><span class="p">,</span><span class="n">cov</span><span class="p">,</span>
<span class="w">                  </span><span class="n">cov</span><span class="p">,</span><span class="n">var</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Variance-covariance matrix</span>

<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 2.077659 4.351648
</pre></div>
</div>
</div>
</div>
<p>So we can see that we get <em>two</em> values back whenever we sample from this distribution. These represent a random draw from condition 1 and a random draw from condition 2, with some degree of correlation. Notice that <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> returns the random draws as a <em>row</em> of values, rather than a column (as we showed earlier). This will only make a difference to way the values are arranged, but the interpretation remains the same. The mean vector is given by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">Mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 2 3
</pre></div>
</div>
</div>
</div>
<p>and the variance-covariance matrix is given by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     [,1] [,2]
[1,]  1.0  0.8
[2,]  0.8  1.0
</pre></div>
</div>
</div>
</div>
<p>We can repeat this again for <em>multiple</em> subjects to see the full conceptualisation of this experiment. If we had <span class="math notranslate nohighlight">\(n=15\)</span> then we can simulate our simple repeated measurements experiment using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>            [,1]     [,2]
 [1,]  1.5540228 2.772157
 [2,]  4.1082767 4.739901
 [3,] -0.3517207 1.145497
 [4,]  2.9383388 3.500617
 [5,]  1.1349551 1.386733
 [6,]  0.8374173 2.639909
 [7,]  0.3985685 1.200894
 [8,]  1.9504570 2.969792
 [9,]  4.5084460 4.570973
[10,]  0.6768891 0.964334
[11,]  3.3780586 3.262506
[12,]  0.7041465 1.032087
[13,]  2.5519364 2.702549
[14,]  1.6893139 3.166815
[15,]  3.0171120 3.611399
</pre></div>
</div>
</div>
</div>
<p>So, now we have 15 measurements from condition 1 and 15 measurements from conditon 2. These are arranged per-subject, so the first row is the two measurements from subject 1, the second row is the two measurments from subject 2 and so on. Importantly, the two columns are <em>correlated</em>, which we can see using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">cor</span><span class="p">(</span><span class="n">y</span><span class="p">[,</span><span class="m">1</span><span class="p">],</span><span class="n">y</span><span class="p">[,</span><span class="m">2</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 0.9144557
</pre></div>
</div>
</div>
</div>
<p>or by plotting the columns against each other</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[,</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[,</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Condition 1&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Condition 2&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/545379d935af2d73d467e12fa40a298d086ed712662291bb9054a2c4475937a6.png" src="_images/545379d935af2d73d467e12fa40a298d086ed712662291bb9054a2c4475937a6.png" />
</div>
</div>
<p>We can now see how the multivariate normal distribution serves as a <em>model</em> of repeated measurements. To put this into our more general framework, this is a more complex <em>variance function</em> that allows for correlation between the measurements.</p>
</section>
</section>
<section id="visualising-the-multivariate-normal">
<h2>Visualising the Multivariate Normal<a class="headerlink" href="#visualising-the-multivariate-normal" title="Link to this heading">#</a></h2>
<p>One of the easiest ways to conceptualise how the multivariate normal works is to <em>visualise</em> it.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/41997f52dc405ea4ff373755abbc1fb6efa3c0166d57491d35664f3bcc14360c.png" src="_images/41997f52dc405ea4ff373755abbc1fb6efa3c0166d57491d35664f3bcc14360c.png" />
</div>
</div>
<p>To see more clearly how this shark-fin shape connects with the idea of correlation, we will see how the probability distribution of <span class="math notranslate nohighlight">\(Y\)</span> changes for a given value of <span class="math notranslate nohighlight">\(X\)</span>. The plots below show a rotated view of the multivariate normal where we are focussing on the <span class="math notranslate nohighlight">\(y\)</span>-axis. The <em>left</em> column shows no correlation (<span class="math notranslate nohighlight">\(\rho=0\)</span>) and the <em>right</em> column shows a strong correlation (<span class="math notranslate nohighlight">\(\rho=0.8\)</span>). The distribution of <span class="math notranslate nohighlight">\(Y\)</span> when <span class="math notranslate nohighlight">\(X\)</span> is fixed to a certain value is superimposed in blue. This is a <em>slice</em> through the multivariate normal distribution. The <em>top</em> row shows <span class="math notranslate nohighlight">\(P(Y|X=-1)\)</span> and the <em>bottom</em> row shows <span class="math notranslate nohighlight">\(P(Y|X=1)\)</span>. Take a moment to study these so you are clear what they are showing.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/ef55936d1dd76bf7e1140ffd0f2b19206f933229e5f8c2ceb353b8e04ca4cd7f.png" src="_images/ef55936d1dd76bf7e1140ffd0f2b19206f933229e5f8c2ceb353b8e04ca4cd7f.png" />
</div>
</div>
<p>Notice that when there is <em>no correlation</em>, the shape of the distribution of <span class="math notranslate nohighlight">\(Y\)</span> does not change with the value of <span class="math notranslate nohighlight">\(X\)</span>. In other words, the value of <span class="math notranslate nohighlight">\(X\)</span> has no bearing on the probability of different values of <span class="math notranslate nohighlight">\(Y\)</span>. This is the essence of <em>independence</em>. However, when there <em>is</em> correlation, the shape of the distribution of <span class="math notranslate nohighlight">\(Y\)</span> <em>shifts</em> depending upon the value of <span class="math notranslate nohighlight">\(X\)</span>. Notice in the <em>right</em> column that when <span class="math notranslate nohighlight">\(X = -1\)</span>, the distribution of <span class="math notranslate nohighlight">\(Y\)</span> is centred close to <span class="math notranslate nohighlight">\(E(Y) = -1\)</span>. Similarly, when <span class="math notranslate nohighlight">\(X = 1\)</span>, the distribution of <span class="math notranslate nohighlight">\(Y\)</span> is centred close to <span class="math notranslate nohighlight">\(E(Y) = 1\)</span>. This change in expected value is seen as the “shark-fin” shape to the density. In essence, the most probable value of <span class="math notranslate nohighlight">\(Y\)</span> changes based on the value of <span class="math notranslate nohighlight">\(X\)</span>. The stronger the correlation, the closer the expected value of one random value approaches the sampled value of the other. This is the essence of <em>dependence</em>.</p>
</section>
<section id="conceptualising-multiple-subjects">
<h2>Conceptualising Multiple Subjects<a class="headerlink" href="#conceptualising-multiple-subjects" title="Link to this heading">#</a></h2>
<section id="the-multivariate-wide-view">
<h3>The Multivariate (<em>Wide</em>) View<a class="headerlink" href="#the-multivariate-wide-view" title="Link to this heading">#</a></h3>
<p>… This is associated with <em>wide-formatted</em> data.</p>
</section>
<section id="the-univariate-long-view">
<h3>The Univariate (<em>Long</em>) View<a class="headerlink" href="#the-univariate-long-view" title="Link to this heading">#</a></h3>
<p>… The way to see this is to recognise that it does not matter whether we conceptualise each subject as a <em>row</em> or <em>column</em> vector, the probability model remains the same. So, the following two expressions are entirely equivalent</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} &amp; y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} &amp; \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\right)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} \\
    y_{i2}
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} \\
    \mu_{2}
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12}  \\
    \sigma_{21}    &amp; \sigma^{2}_{2}
\end{bmatrix}
\right)
\end{split}\]</div>
<p>If we take the <em>second</em> perspective of each subject being a <em>column-vector</em>, we can now <em>stack</em> the subjects to produce a single outcome variable, suitable for use in our linear model framework.</p>
<p>… This is associated with <em>long-formatted</em> data.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{11} \\
    y_{12} \\
    y_{21} \\
    y_{22} \\
    y_{31} \\
    y_{32} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
    \mu_{1} \\
    \mu_{2} \\
\end{bmatrix}, 
\begin{bmatrix}
    \sigma^{2}_{1} &amp; \sigma_{12} &amp; 0 &amp; 0 &amp; 0 &amp; 0  \\
    \sigma_{21}    &amp; \sigma^{2}_{2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; \sigma^{2}_{1} &amp; \sigma_{12} &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; \sigma_{21}    &amp; \sigma^{2}_{2} &amp; 0 &amp; 0  \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; \sigma^{2}_{1} &amp; \sigma_{12} \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; \sigma_{21}    &amp; \sigma^{2}_{2} \\
\end{bmatrix}
\right)
\end{split}\]</div>
<p>This is a 6-dimensional normal distribution, so we would struggly to visualise this in any meaningful way. However, as mentioned last semester, dimensions are just a mathematical tool for keeping track of information. We do not <em>have</em> to be able to visualise them in order for this to be useful or make sense. The more important element here is the <em>structure</em>.</p>
<p>As we can see, each subject is given by the <em>first</em> index of <span class="math notranslate nohighlight">\(y\)</span>. So, we have two measurements from subject 1, two measurements from subject 2 and two measurements from subject 3. We conceptualise this dataset as a single draw from a 6-dimensional normal distribution. The mean vector tells us that the population means for each condition are identical across subjects, so our interest is estimating <span class="math notranslate nohighlight">\(\mu_{1}\)</span> and <span class="math notranslate nohighlight">\(\mu_{2}\)</span>. If the data came from 6 different subjects, this would be no different from assuming <span class="math notranslate nohighlight">\(y_{i1} \sim \mathcal{N}(\mu_{1}, \sigma^{2}_{1})\)</span> and <span class="math notranslate nohighlight">\(y_{i2} \sim \mathcal{N}(\mu_{2}, \sigma^{2}_{2})\)</span>. However, because these are <em>repeated measurements</em>, the important aspect here is the correlation structure embedded in the <em>variance-covariance</em> matrix. This has a <em>block-diagonal</em> structure, which implies that there is <em>no correlation</em> between measurements from <em>different</em> subjects. This seems fair, as it is usually unlikely that separate subjects would affect each other. However, <em>within</em> each subject we assume a separate variance for each condition (<span class="math notranslate nohighlight">\(\sigma^{2}_{1}\)</span>, <span class="math notranslate nohighlight">\(\sigma^{2}_{2}\)</span>) and some <em>non-zero</em> covariance (<span class="math notranslate nohighlight">\(\sigma_{12} = \sigma_{21}\)</span>) that captures how correlated the responses are from an individual subject.</p>
</section>
</section>
<section id="correlation-and-the-probability-model">
<h2>Correlation and the Probability Model<a class="headerlink" href="#correlation-and-the-probability-model" title="Link to this heading">#</a></h2>
<p>… We will now see how these issues solidify within the context of the probability model we have established.</p>
<section id="correlation-and-the-linear-model-assumptions">
<h3>Correlation and the Linear Model Assumptions<a class="headerlink" href="#correlation-and-the-linear-model-assumptions" title="Link to this heading">#</a></h3>
<p>… In order to work with the linear model machinery, we need our outcome to be a <em>single</em> variable, rather than <em>multiple</em> variables.</p>
<p>Although this dataset is in the <em>wide</em> format, it is important to realise that <code class="docutils literal notranslate"><span class="pre">t1</span></code>, <code class="docutils literal notranslate"><span class="pre">t2</span></code> and <code class="docutils literal notranslate"><span class="pre">t3</span></code> are <em>not</em> different variables. They are all measurements of <code class="docutils literal notranslate"><span class="pre">selfesteem</span></code> organised by subject. The reality is that these are all the <em>same</em> variable, as is made clearer by converting this dataset to <em>long</em> format</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">reshape2</span><span class="p">)</span>

<span class="c1"># reshape wide -&gt; long</span>
<span class="n">selfesteem.long</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">melt</span><span class="p">(</span><span class="n">selfesteem</span><span class="p">,</span><span class="w">               </span><span class="c1"># wide data frame</span>
<span class="w">                        </span><span class="n">id.vars</span><span class="o">=</span><span class="s">&#39;id&#39;</span><span class="p">,</span><span class="w">             </span><span class="c1"># what stays fixed?</span>
<span class="w">                        </span><span class="n">variable.name</span><span class="o">=</span><span class="s">&quot;time&quot;</span><span class="p">,</span><span class="w">     </span><span class="c1"># name for the new predictor</span>
<span class="w">                        </span><span class="n">value.name</span><span class="o">=</span><span class="s">&quot;selfesteem&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># name for the new outcome</span>

<span class="n">selfesteem.long</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">selfesteem.long</span><span class="p">[</span><span class="nf">order</span><span class="p">(</span><span class="n">selfesteem.long</span><span class="o">$</span><span class="n">id</span><span class="p">),]</span><span class="w"> </span><span class="c1"># order by ID</span>
<span class="nf">rownames</span><span class="p">(</span><span class="n">selfesteem.long</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">30</span><span class="p">)</span><span class="w">                         </span><span class="c1"># fix row names</span>

<span class="nf">print</span><span class="p">(</span><span class="n">selfesteem.long</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   id time selfesteem
1   1   t1   4.005027
2   1   t2   5.182286
3   1   t3   7.107831
4   2   t1   2.558124
5   2   t2   6.912915
6   2   t3   6.308434
7   3   t1   3.244241
8   3   t2   4.443434
9   3   t3   9.778410
10  4   t1   3.419538
11  4   t2   4.711696
12  4   t3   8.347124
13  5   t1   2.871243
14  5   t2   3.908429
15  5   t3   6.457287
16  6   t1   2.045868
17  6   t2   5.340549
18  6   t3   6.653224
19  7   t1   3.525992
20  7   t2   5.580695
21  7   t3   6.840157
22  8   t1   3.179425
23  8   t2   4.370234
24  8   t3   7.818623
25  9   t1   3.507964
26  9   t2   4.399808
27  9   t3   8.471229
28 10   t1   3.043798
29 10   t2   4.489376
30 10   t3   8.581100
</pre></div>
</div>
</div>
</div>
<p>So, now we have our single outcome variable <span class="math notranslate nohighlight">\(y\)</span>, suitable for use in a linear model. Except that we now have an outcome variable where <em>individual elements are not independent</em>. Rather than each row representing an independent draw from some probability distribution, we now have rows that are <em>correlated</em>, based on whether they come from the same subject.</p>
<div class="tip admonition">
<p class="admonition-title">Why Are Repeated Measurements Correlated?</p>
<p>This is, in effect, a principle of reality. There is an <em>internal consistency</em> to people that means that they will produce a similar pattern of results across repeats.</p>
</div>
<p>Why does the correlation matter? Recall that a core assumption of the normal linear model is that the data/errors are <span class="math notranslate nohighlight">\(i.i.d.\)</span> We previously wrote this as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    y &amp;= \mu + \epsilon \\
    \epsilon &amp;\sim^{i.i.d.}\mathcal{N}(0,\sigma^{2})
\end{alignat*}
\end{split}\]</div>
<p>Under repeated measurements, the <span class="math notranslate nohighlight">\(independent\)</span> criteria is clearly broken. Where this is most important is for <em>estimation</em>. Both OLS and MLE/REML assume independence when performing estimation. When the data are <em>dependent</em>, this causes bias to creep in, rendering some of the parameter estimates <em>larger</em> or <em>smaller</em> than they should be. We will discuss this in more detail further below, but this should be enough for the moment to see why this might be a problem for the approaches we discussed last semester.</p>
</section>
<section id="correlation-and-the-standard-errors">
<h3>Correlation and the Standard Errors<a class="headerlink" href="#correlation-and-the-standard-errors" title="Link to this heading">#</a></h3>
<p>Given everything above, what are the implications for our statistical model when there is correlation between measurements? As we have discussed, nothing about the <em>mean function</em> changes. So if we are only interested in estimating effects as defined within the mean function, nothing changes. This means that regression slopes, cell means and mean differences remain unchanged. However, what <em>does</em> change is the <em>variance function</em>. The biggest practical implication of this is that <em>correlation changes the standard errors</em>. This means that our <em>uncertainty</em> is different under correlation. If we get this wrong, the standard errors will be wrong, the test statistical will be wrong, the confidence intervals will be wrong and the <span class="math notranslate nohighlight">\(p\)</span>-values will be wrong. In short, neglecting to model the correlational structure will make our <em>inference wrong</em>. In a more general sense, neglecting the correlational structure will lead to a poor model of the data-generating process, because correlation is a <em>fundamental</em> element of how the data came to be. If we ignore it, we can never hope to have an accurate picture of where our data came from.</p>
</section>
<section id="theory">
<h3>Theory<a class="headerlink" href="#theory" title="Link to this heading">#</a></h3>
<p>The simplest demonstration of how correlation affects uncertainty comes directly from the properties of a random variable. It is a standard result in probability theory that the variance of the <em>difference</em> between two random variables (<span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>) is given by</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y_{1} - y_{2}\right) = \text{Var}\left(y_{1}\right) + \text{Var}\left(y_{2}\right) - 2\text{Cov}\left(y_{1},y_{2}\right).
\]</div>
<p>To understand this, consider the fact that subtracting two random variables produces a <em>new</em> random variable that captures their <em>difference</em>. This new random variable will also have a distribution. So what we are thinking above in the above equation is the <em>width</em> of the distribution of the <em>difference</em> between <span class="math notranslate nohighlight">\(y_{1}\)</span> and <span class="math notranslate nohighlight">\(y_{2}\)</span>. What this is saying is that the width of this distribution is a function of the variances from the two individual distributions <em>and</em> their degree of correlation. If the correlation is <em>positive</em> the variance will shrink, if the correlation is <em>negative</em> the variance will <em>grow</em>. Either way, our uncertainty around the difference between these two random variables <em>depends</em> upon their degree of correlation</p>
</section>
<section id="simulation">
<h3>Simulation<a class="headerlink" href="#simulation" title="Link to this heading">#</a></h3>
<p>To see this, we can run a simulation in <code class="docutils literal notranslate"><span class="pre">R</span></code>. First, we use the <code class="docutils literal notranslate"><span class="pre">mvrnorm()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">MASS</span></code> package to simulate 1,000 realisations of two repeated measurements with a correlation of <span class="math notranslate nohighlight">\(\rho = 0.8\)</span>. To do this, we use the following sampling model:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} \\
    y_{i2} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    2 \\
    3 \\
\end{bmatrix},
\begin{bmatrix}
    1 &amp; 0.8 \\
    0.8 &amp; 1 \\
\end{bmatrix}
\right)
\end{split}\]</div>
<p>We can then compare this to 1,000 realisations of two independent measurements with a correlation of <span class="math notranslate nohighlight">\(\rho = 0\)</span>. To do this, we use the following sampling model</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
    y_{i1} \\
    y_{i2} \\
\end{bmatrix}
\sim\mathcal{N}\left(
\begin{bmatrix}
    2 \\
    3 \\
\end{bmatrix},
\begin{bmatrix}
    1 &amp; 0 \\
    0 &amp; 1 \\
\end{bmatrix}
\right).
\end{split}\]</div>
<p>The <code class="docutils literal notranslate"><span class="pre">R</span></code> code is</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">Sigma.dep</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">var</span><span class="p">,</span><span class="n">cov</span><span class="p">,</span>
<span class="w">                      </span><span class="n">cov</span><span class="p">,</span><span class="n">var</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>

<span class="n">Sigma.ind</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">var</span><span class="p">,</span><span class="w">   </span><span class="m">0</span><span class="p">,</span>
<span class="w">                        </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">var</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>

<span class="n">y.dep</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma.dep</span><span class="p">)</span><span class="w"> </span><span class="c1"># dependence</span>
<span class="n">y.ind</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="n">Mu</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma.ind</span><span class="p">)</span><span class="w"> </span><span class="c1"># independence</span>
</pre></div>
</div>
</div>
</div>
<p>In both cases, we conceptualise the columns of <code class="docutils literal notranslate"><span class="pre">y.dep</span></code> and <code class="docutils literal notranslate"><span class="pre">y.ind</span></code> as two different conditions of an experiment. As such, our interest lies in the <em>difference</em> between the columns. As a final step, we subtract the columns and then compare the distributions of differences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">diff.dep</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">y.dep</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y.dep</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span>
<span class="n">diff.ind</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">y.ind</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y.ind</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span>

<span class="nf">hist</span><span class="p">(</span><span class="n">diff.dep</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-8</span><span class="p">,</span><span class="m">6</span><span class="p">),</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&#39;Mean Difference&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&#39;Correlated&#39;</span><span class="p">)</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">diff.ind</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-8</span><span class="p">,</span><span class="m">6</span><span class="p">),</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&#39;Mean Difference&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&#39;Uncorrelated&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a7b6b0b2c72a070da05b2d62d5b454485746d14ea900c74610145744ccb92403.png" src="_images/a7b6b0b2c72a070da05b2d62d5b454485746d14ea900c74610145744ccb92403.png" />
<img alt="_images/01621cb2dfa975f83ca9f7f88e406791a181fd78c406f2a75729bc239ed36f03.png" src="_images/01621cb2dfa975f83ca9f7f88e406791a181fd78c406f2a75729bc239ed36f03.png" />
</div>
</div>
<p>Notice that the distribution of repeated measurement differences is much <em>narrower</em> than the distribution of independent differences. This is the theory in action. … This is why there is a <em>power</em> advantage to repeated measurements. … The variability of the difference is much smaller because the conditions are going to be <em>more similar</em> when they are correlated. As such, we do not expect wild differences between them. The two conditions should generally be very similar and thus their difference should be consistently smaller than in the independent case, where much larger differences are possible.</p>
<p>We can see how this will affect the <span class="math notranslate nohighlight">\(t\)</span>-statistic by calculating</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.designs.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Repeated Measurement Designs</p>
      </div>
    </a>
    <a class="right-next"
       href="3.paired-t.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Paired <em>t</em>-test</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-normal-distribution">The Multivariate Normal Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mean-vector">The Mean Vector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-covariance-matrix">The Variance-Covariance Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-draws-from-a-multivariate-normal">Taking Draws from a Multivariate Normal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-multivariate-normal">Visualising the Multivariate Normal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptualising-multiple-subjects">Conceptualising Multiple Subjects</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-wide-view">The Multivariate (<em>Wide</em>) View</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-univariate-long-view">The Univariate (<em>Long</em>) View</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-probability-model">Correlation and the Probability Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-linear-model-assumptions">Correlation and the Linear Model Assumptions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-and-the-standard-errors">Correlation and the Standard Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theory">Theory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">Simulation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>