{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde1ccab-2d89-4ccf-aca6-dbea239a0625",
   "metadata": {},
   "source": [
    "# The Paired *t*-test\n",
    "At this point in the lesson, we have established what repeated measures designs are, why they cause problems and how we can use the multivariate normal distribution as a general probabilistic framework for accommodating correlation. We will now move on to discussing models that are suitable for repeated measurements. The most basic repeated measures scenario is when we have *two* measurements from each subject. In this situation, it is typical to use a *paired* $t$-test. Given what we have now established, our interest lies in *how* the paired $t$-test is able to accommodate correlation. As we will discuss below, rather than modelling the correlation directly, the paired $t$-test is structured such that the correlation is effectively *removed* from the data. Although this *side-steps* many of the issues around repeated measurements, understanding *why* this works is key for for developing more complex and general-purpose approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc8b1f-545c-4f4b-abf6-505f93433003",
   "metadata": {},
   "source": [
    "## Two-sample vs Paired *t*-tests\n",
    "To begin with, it is useful to examine *how* the results differ between a *two-sample* and *paired* $t$-test. We can don this in `R` by comparing the results of the `t.test()` function with `paired=FALSE` and `paired=TRUE`. To do this, we use the `mice2` data set from the `datarium` package. This contains the weight of a sample of 10 mice both *before* and *after* some treatment. The experimental question concerns whether the treatment affects the weight of the mice. The data is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc5306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id before after\n",
      "1   1  187.2 429.5\n",
      "2   2  194.2 404.4\n",
      "3   3  231.7 405.6\n",
      "4   4  200.5 397.2\n",
      "5   5  201.7 377.9\n",
      "6   6  235.0 445.8\n",
      "7   7  208.7 408.4\n",
      "8   8  172.4 337.0\n",
      "9   9  184.6 414.3\n",
      "10 10  189.6 380.3\n"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "data('mice2')\n",
    "print(mice2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f81866",
   "metadata": {},
   "source": [
    "We can compare the output from a *two-sample* $t$-test and a *paired* $t$-test by changing the `paired=` argument of `t.test()`, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29a1f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPaired t-test\n",
      "\n",
      "data:  mice2$before and mice2$after\n",
      "t = -25.546, df = 9, p-value = 1.039e-09\n",
      "alternative hypothesis: true mean difference is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -217.1442 -181.8158\n",
      "sample estimates:\n",
      "mean difference \n",
      "        -199.48 \n",
      "\n",
      "\n",
      "\tTwo Sample t-test\n",
      "\n",
      "data:  mice2$before and mice2$after\n",
      "t = -17.453, df = 18, p-value = 9.974e-13\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -223.4926 -175.4674\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "   200.56    400.04 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(t.test(mice2$before, mice2$after, var.equal=TRUE, paired=TRUE))  # paired t-test\n",
    "print(t.test(mice2$before, mice2$after, var.equal=TRUE, paired=FALSE)) # two-sample t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fdd680",
   "metadata": {},
   "source": [
    "The output is a bit different between the two methods, so let us spend a little time unpacking this. To begin with, the clearest differences concern the $t$-statistic itself, the degrees of freedom, the $p$-value and the confidence interval. These are summarised in the table below \n",
    "\n",
    "| Test       | *t*-statistic | DoF | *p*-value | 95% CI            | \n",
    "| ---------- | ------------- | --- | --------- | ----------------- |\n",
    "| Paired     | -25.546       | 9   | 1.039e-09 | [-217.14 -181.82] |\n",
    "| Two-sample | -17.453       | 18  | 9.974e-13 | [-223.49 -175.47] |\n",
    "\n",
    "Although it may seem like *everything* is different, there is actually one element that is *identical*, though it is somewhat hidden. To see it, consider that the structure of a $t$-test is\n",
    "\n",
    "$$\n",
    "t = \\frac{\\mu_{1} - \\mu_{2}}{\\text{SE}\\{\\mu_{1} - \\mu_{2}\\}},\n",
    "$$\n",
    "\n",
    "meaning that we think of the $t$ as the ratio between the *mean difference* and the *standard error of the mean difference*. The $t$-statistic itself is different between the *two-sample* and the *paired* tests, but this does not necessarily mean that all elements of this ratio are also different. Indeed, if we look at the output above we can see that the *paired* test reports a mean difference of `-199.48` and the *two-sample* test reports the individual means as `200.56` and `400.04`. If we calculate the mean difference from the values reported by the *two-sample* test we get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e3c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -199.48\n"
     ]
    }
   ],
   "source": [
    "print(200.56 - 400.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dba2cb",
   "metadata": {},
   "source": [
    "So, this is *identical* between the *paired* and *two-sample* tests. This should not be surprising, as we already established that repeated measurements do not affect the mean function. However, this does make it clear that it is not the *numerator* that differs between the paired and two-sample tests. As such, it must be the *denominator* of the $t$-statistic that leads to the differences above. In other words, *the standard error of the difference changes under repeated measurements*.\n",
    "\n",
    "Given that we know the numerator for both tests, we can recover the denominators and see that this is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf77d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  7.808659 11.429554\n"
     ]
    }
   ],
   "source": [
    "mean.diff  <- -199.48\n",
    "paired.t   <- -25.546\n",
    "twosamp.t  <- -17.453\n",
    "paired.se  <-  mean.diff / paired.t\n",
    "twosamp.se <-  mean.diff / twosamp.t\n",
    "\n",
    "print(c(paired.se, twosamp.se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0806ec6",
   "metadata": {},
   "source": [
    "The *standard error* of the difference is much *smaller* in the *paired* test (`7.81`), compared to the *two-sample* test (`11.43`). This should not be a surprise as we know that the variance of the difference between two random variables should get *smaller* when they are positively correlated. From this, we can conclude that the standard error in the two-sample test is *too large* for this particular dataset, which has led to a $t$-statistic that is *smaller* than it should be. Application of the wrong method here has led to a *loss* of statistical power.\n",
    "\n",
    "This tracks with everything we have discussed so far. However, the key question remains *how* the paired $t$-test is able to do this? There are two equivalent ways of conceptualising this, but the simplest is to think of a paired $t$-test as a model of *differences* between the repeated measurements. This is the perspective we will discuss below. The alternative perspective will be presented when we start discussing the *repeated measures ANOVA* as a generalisation of the paired $t$-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95572e43",
   "metadata": {},
   "source": [
    "## The Model of *Paired Differences*\n",
    "The key idea behind the *paired differences* approach is that a paired $t$-test is identical to a *one-sample* $t$-test on the *differences* between the pairs. This is a really key conceptual step because it introduces the idea that we can correctly model repeated measurements by *removing* something from the data. If we can make the paired test correct via subtraction it means that we are able to *remove* correlation and make the data *independent*. As we will see further below, formalising this idea allows us to conceptualise models of repeated measures in a more general fashion that will be useful going forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4268ea5",
   "metadata": {},
   "source": [
    "\n",
    "### Paired Differences in `R`\n",
    "As a first step, we can demonstrate that the idea of subtracting pairs *does* work. We can use the `mice2` data again and create a new variable that represents the *difference* between `before` and `after` the treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376f968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id before after treat.diff\n",
      "1   1  187.2 429.5     -242.3\n",
      "2   2  194.2 404.4     -210.2\n",
      "3   3  231.7 405.6     -173.9\n",
      "4   4  200.5 397.2     -196.7\n",
      "5   5  201.7 377.9     -176.2\n",
      "6   6  235.0 445.8     -210.8\n",
      "7   7  208.7 408.4     -199.7\n",
      "8   8  172.4 337.0     -164.6\n",
      "9   9  184.6 414.3     -229.7\n",
      "10 10  189.6 380.3     -190.7\n"
     ]
    }
   ],
   "source": [
    "mice2$treat.diff <- mice2$before - mice2$after\n",
    "print(mice2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c258b9",
   "metadata": {},
   "source": [
    "Now, we can simply perform a one-sample $t$-test on the difference. To do this, we could use the `t.test()` function, but given that our general focus is linear models, we will use `lm()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65622a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = treat.diff ~ 1, data = mice2)\n",
       "\n",
       "Residuals:\n",
       "   Min     1Q Median     3Q    Max \n",
       "-42.82 -11.17   1.28  19.66  34.88 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -199.480      7.809  -25.55 1.04e-09 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 24.69 on 9 degrees of freedom\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onesamp.mod <- lm(treat.diff ~ 1, data=mice2)\n",
    "summary(onesamp.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0c743",
   "metadata": {},
   "source": [
    "The test on the intercept parameter $(\\beta_{0})$ is now *identical* to the paired $t$-test from earlier. Importantly, we have done *nothing* to explicitly model the covariance structure. Indeed, remember that `lm()` assumes that there is *no* correlation in the data. So, we have now managed to analyse repeated measurements using a model that assumes that there are no repeated measurements. In effect, we have *created* independent data via subtraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f574f9ec",
   "metadata": {},
   "source": [
    "### Removing the Effect of the Subjects\n",
    "Given the demonstration above, the key insight is that taking $d_{i} = y_{i1} - y_{i2}$ allows us to treat the values of $d_{i}$ as *independent*. This means that this subtraction *must* be removing the correlation from the data. This is fairly intuitive because we have reduced correlated pairs of data down to only a single value per-subject. Given that the subjects are *independent*, the values of $d_{i}$ must also be independent. In effect, there are *no* repeated measurements anymore. However, expressing this formally is a useful stepping-stone to more general approaches.\n",
    "\n",
    "To see what is happening, let us return to our basic $t$-test model from last semester, where we parameterised each group mean in terms of the grand mean plus a group-specific deflection. The model is given by\n",
    "\n",
    "$$\n",
    "y_{ij} = \\mu + \\alpha_{j} + \\epsilon_{ij},\n",
    "$$\n",
    "\n",
    "so the means of the two repeated measurements are given by \n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    E(y_{i1}) &= \\mu_{1} = \\mu + \\alpha_{1} \\\\\n",
    "    E(y_{i2}) &= \\mu_{2} = \\mu + \\alpha_{2}.\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "To capture the concept of *dependence* between these repeats, we will now *split* the error into *two* components. This may seem an odd step, but stick with it because this simple maneuver is key to understanding why the paired $t$-test works. So, we take our error term and define $\\epsilon_{ij} = S_{i} + \\eta_{ij}$. This now consists of a *shared component* for each subject, called $S_{i}$, as well as a *unique component* for each observation, called $\\eta_{ij}$. For the two repeated measurements, the model is now\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{i1} &= \\mu + \\alpha_{1} + \\overbrace{S_{i} + \\eta_{i1}}^{\\epsilon_{ij}} \\\\\n",
    "    y_{i2} &= \\mu + \\alpha_{2} + S_{i} + \\eta_{i2} \n",
    "\\end{alignat*}.\n",
    "$$\n",
    "\n",
    "So, the reason why $y_{i1}$ and $y_{i2}$ are correlated is because they *share* the same component $S_{i}$. This captures the idea that these measurements come from the *same subject*. If we then *subtract* $y_{i1}$ and $y_{i2}$, the term $S_{i}$ will cancel-out\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    d_{i} = y_{i1} - y_{i2} &= (\\mu_{1} + S_{i} + \\eta_{i1}) - (\\mu_{2} + S_{i} + \\eta_{i2}) \\\\\n",
    "                            &= (\\mu_{1} + \\eta_{i1}) - (\\mu_{2} + \\eta_{i2})\n",
    "\\end{alignat*}.\n",
    "$$\n",
    "\n",
    "Because we end up with a single value of $d_{i}$ per-subject, these values must be *independent* because the subjects are *independent*. So, because the subtraction removes $S_{i}$, this tells us that $S_{i}$ *must* capture the *correlation*. As such, the simple act of splitting the error term into *two parts* directly explains exactly *how* and *why* the paired $t$-test works. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29c72a",
   "metadata": {},
   "source": [
    "`````{admonition} A Poetic Explanation\n",
    ":class: tip\n",
    "In their book \"Analysis of Repeated Measures\", Crowder and Hand (1990) refer to the elements of the model\n",
    "\n",
    "$$\n",
    "y_{ij} = \\mu + \\alpha_{j} + S_{i} + \\eta_{ij}\n",
    "$$\n",
    "\n",
    "in a more poetic way that may help get a sense of what the model terms are capturing. They refer to $\\mu_{j} = \\mu + \\alpha_{j}$ as an \"immutable constant of the universe\", $S_{i}$ as a \"lasting characteristic of the individual\" and $\\eta_{ij}$ as a \"fleeting aberration of the moment\". So, $\\mu_{j} = \\mu + \\alpha_{j}$ represents something fundamental and universal about the effect of the different treatments that is true across all measurements of those treatments. $S_{i}$ captures something that is specific and unique to subject $i$ that is true across all their repeated measurements, and $\\eta_{ij}$ represents random noise that occurred at the point of measurement that is unrelated to the experimental condition or the individual.\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc7745-7055-4e16-83fa-4ce2d215b1ab",
   "metadata": {},
   "source": [
    "## Inference in the Model of *Paired Differences*\n",
    "Earlier, we indicated that a key difference between a *paired* $t$-test and a *two-sample* $t$-test was the standard error used for the test statistic. We will now see how this aligns with the model of *paired differences* and the idea of *splitting* the error term into $\\epsilon_{ij} = S_{i} + \\eta_{ij}$ and then *removing* the $S_{i}$ terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c139a0f",
   "metadata": {},
   "source": [
    "### A Model with *Two* Error Terms\n",
    "To understand the consequences of splitting the error in two, recall that in the normal linear model the errors are a random variable of the form \n",
    "\n",
    "$$\n",
    "\\epsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^{2}).\n",
    "$$\n",
    "\n",
    "As such, when we split the errors, we get *two* random variables of the form\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    S_{i}     &\\sim \\mathcal{N}(0,\\sigma^{2}_{1}) \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}(0,\\sigma^{2}_{2}).\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "We do not assume these have the same variance and thus we now have *two* variances as well. So, not only have we *partitioned* the errors, we have also *partitioned* the variance into two separate chunks\n",
    "\n",
    "$$\n",
    "\\text{Var}\\left(y_{ij}\\right) = \\sigma^{2} = \\sigma^{2}_{1} + \\sigma^{2}_{2}.\n",
    "$$\n",
    "\n",
    "This says that the variation in our data is the sum of two separate chunks that come from two different sources. Within the context of a basic repeated measures model, these variance components are often called the *between-subjects* variance and the *within-subject* variance. So we can equivalently write the distribution of the errors as\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    S_{i}     &\\sim \\mathcal{N}(0,\\sigma^{2}_{b}) \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}(0,\\sigma^{2}_{w}).\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "In this scheme, $\\sigma^{2}_{b}$ captures variation due to the fact that we have measured *different subjects*, and $\\sigma^{2}_{w}$ captures variation of measurement *within each subject*. We therefore think of variation in these data as attributable to two different sources of error. One concerns the fact that we have different people in the data and the other concerns the fact that we have multiple measurements from each person in the data. We can therefore specify this model more generally as\n",
    "\n",
    "$$\n",
    "y_{ij} \\sim\\mathcal{N}(\\mu + \\alpha_{j}, \\sigma^{2}_{b} + \\sigma^{2}_{w})\n",
    "$$\n",
    "\n",
    "We will discuss this model specification in more detail in the next part of this lesson, as it is a key result that leads us both to the repeated measures ANOVA and the mixed-effects models that are the focus of this section of the unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2c5bc",
   "metadata": {},
   "source": [
    "### Error Variance in the Model of *Paired Differences*\n",
    "Now, let us circle back to the paired $t$-test and the idea of subtracting the pairs to remove the correlation. So, sticking with the concept of a model with *two* error variances, what happens when we take the *difference* $d_{i} = y_{i1} - y_{i2}$? Remember from the beginning of this lesson that the variance of the difference between two random variables is given by\n",
    "\n",
    "$$\n",
    "\\text{Var}(y_{1} - y_{2}) = \\text{Var}(y_{1}) + \\text{Var}(y_{2}) - 2\\text{Cov}(y_{1},y_{2}).\n",
    "$$\n",
    "\n",
    "As such, the variance of $d_{i}$ is\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{3}\n",
    "    \\text{Var}(d_{i}) &= \\text{Var}(y_{i1}) &&+ \\text{Var}(y_{i2}) &&- 2\\text{Cov}(y_{i1},y_{i2}) \\\\\n",
    "                      &= \\left(\\sigma^{2}_{b} + \\sigma^{2}_{w}\\right) &&+ \\left(\\sigma^{2}_{b} + \\sigma^{2}_{w}\\right) &&- 2\\text{Cov}(y_{i1},y_{i2})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "For reasons we will give in the next part of the lesson, the covariance between the repeated measurements is\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\sigma^{2}_{b}.\n",
    "$$\n",
    "\n",
    "Although this might seem an unintuitive result, stick with it for the moment. We will provide more intuition about this later in the unit. For now, let us see what happens when we put all this together \n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\text{Var}(d_{i}) &= \\left(\\sigma^{2}_{b} + \\sigma^{2}_{w}\\right) + \\left(\\sigma^{2}_{b} + \\sigma^{2}_{w}\\right) - 2\\sigma^{2}_{b} \\\\\n",
    "                      &= 2\\sigma^{2}_{w} + 2\\sigma^{2}_{b} - 2\\sigma^{2}_{b}  \\\\\n",
    "                      &= 2\\sigma^{2}_{w}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So, when we subtract the repeated measurements, $\\sigma^{2}_{b}$ *disappears* and we are only left with $\\sigma^{2}_{w}$. This is exactly the same idea as $S_{i}$ disappearing in the subtraction, as well as the idea of the correlation disappearing in the subtraction. The only variance left in $d_{i}$ is $\\sigma^{2}_{w}$. This means that the standard errors can only be based on $\\sigma^{2}_{w}$, which is always going to be smaller than $\\sigma^{2}_{w} + \\sigma^{2}_{b}$, which is what the *two-sample* $t$-test is using.\n",
    "\n",
    "Putting this all together, the paired $t$-test works because subtracting the repeated measurements cancels the term $S_{i}$. This both removes the correlation *and* removes a portion of the overall error variance. What is left represents only the *within-subject* variance. Because this is always *smaller* than the total variance, the standard error of the difference is *also* smaller. This makes the associated $t$-statistic *bigger* in the paired case, even though the mean difference never changes. In effect, this scheme allows correlation to be incorporated and the standard error adjusted in an entirely mechanistic way, simply by calculating the *difference* between the pairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af500a",
   "metadata": {},
   "source": [
    "`````{topic} What do you now know?\n",
    "In this section, we have explored the paired $t$-test as the most basic model of repeated measurements. After reading this section, you should have a good sense of :\n",
    "\n",
    "- The core differences when we apply a paired $t$-test vs a two-sample $t$-test to the same data in terms of the test statistic, degrees of freedom and confidence interval.\n",
    "- The concept that the *numerator* of the $t$-statistic does not change under repeated measurements, but the *denominator* (the *standard error of the differences*) does.\n",
    "- The idea that a paired $t$-test can be conceptualised as a *one-sample* $t$-test on the *differences* between the pairs.\n",
    "- The idea that subtracting the pairs renders the data *independent* because this *removes the correlation*.\n",
    "- The idea that we can conceptualise *why* this happens by: \n",
    "    - Splitting the model error into two parts, one that captures a *shared component* for each subject and one that captures *independent error*.\n",
    "    - Seeing how this *shared component* is the element that *cancels* under subtraction and thus *must* be the element that explains the correlation between the repeated measurements.\n",
    "    - Seeing that the only remaining variance reflects *within-subject* deviations that are *smaller* than the total variance.\n",
    "    - Seeing that this *within-subject* variance is the only element that can feeds into the standard errors and thus explaining why the standard errors are *smaller* for the paired test compared to the two-sample test.\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a091fc2-fa8d-4da2-b4af-83c5c5c7089f",
   "metadata": {},
   "source": [
    "[^intercept-foot]: So too will the intercept term $\\mu$, but this just means that the data will be *mean centred* with 0 representing no difference between the repeated measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e42c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
