{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde1ccab-2d89-4ccf-aca6-dbea239a0625",
   "metadata": {},
   "source": [
    "# One-way Repeated Measures ANOVA\n",
    "In the previous part of this lesson, we examined the paired $t$-test as the most basic method for dealing with repeated measurements. In doing do, we established that taking the *difference* between the pairs was enough to remove correlation and render the data independent, allowing us to specify a simple one-sample test on the mean difference. In order to understand this, we split our usual single error term into two components, one associated with each subject and one associated with any other deviations. We then saw how the term associated with each subject *cancelled* when the pairs were subtracted, implying that this component captured the correlation between the repeated measurements. Furthermore, by viewing these terms in relation to a partition of the error variance, we established that it is the *between-subjects* variance that is removed by subtraction, leaving only the *within-subject* variance. Because this is smaller than the total variance, and smaller than the between-subjects variance, this rendered the standard error of the estimated mean difference smaller, thus making the test statistic larger. This not only established *why* the paired $t$-test is different to the independent measures $t$-test, but also why the paired $t$-test is typically *more powerful* and thus desirable, from an inferential perspective. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061c103",
   "metadata": {},
   "source": [
    "## Limitations of the Model of *Paired Differences*\n",
    "Although this *paired differences* framework works well when the data consists of only *two* repeated measurements, we hit a problem if we have *more than two* repeated measurements, *more than one* repeated measures factor or even when we have a mixture of repeated measurements and independent measurements. In many of these cases, we cannot take a simple subtraction and then analyse the resultant differences. So, while the paired $t$-test is fine in simple cases, it does not generalise very easily. \n",
    "\n",
    "In order to allow the analysis of more complex experimental situations, we need to abandon the idea of making the data independent through subtraction. Instead, we need to accommodate the correlation *directly* within the model. The general theme of this section of the unit is *mixed-effects models*, which represent the most modern solution to this problem. However, in this part of the lesson we will discuss an older solution in the form of the *repeated measures ANOVA*. This is really a stepping-stone towards mixed-effects models, rather than a recommendation, as the repeated measures ANOVA is rather limited in practice. Nevertheless, this method is still used widely in psychological research and so is still worth understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffadc85",
   "metadata": {},
   "source": [
    "## The Model of *Partitioned Errors*\n",
    "As mentioned above, because *subtraction* only works in a number of limited cases, we need to abandon it as our general solution to dealing with dependent data. Instead, we need to work with data that we *know* is correlated. Unfortunately, as we have already established, the linear model framework assumes that the errors of the model are $i.i.d.$, which will not be true under repeated measurements. However, we have already seen a possible solution to this problem, as the removal of the subject terms $S_{i}$ theoretically *removes* the correlation and renders the errors independent. Thus, if we were to *include* the term $S_{i}$ in the model, the errors would meet the $i.i.d.$ criteria. Furthermore, the single error variance assumed by the linear model would be the *within-subject* variance and thus would be suitable for inference on the repeated measurements. Putting all this together gives us the model\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}    &=                      \\mu + \\alpha_{j} + S_{i} + \\eta_{ij} \\\\\n",
    "    \\eta_{ij} &\\overset{i.i.d.}{\\sim} \\mathcal{N}(0,\\sigma^{2}_{w})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "which is the basis for the repeated measures ANOVA.\n",
    "\n",
    "Now, in the specification above, we have treated $S_{i}$ like any other factor in an ANOVA model. However, this is not really correct. As discussed in the previous part of this lesson, $S_{i}$ comes from *splitting* the overall error term $\\epsilon_{ij}$. So, in theory, rather than representing population constants (like $\\mu$ and $\\alpha_{j}$), the $S_{i}$ are a *random variable*. This makes sense because the subjects represent a *random sample*, rather than a fixed quantity. If we were to run the experiment again, $\\mu$ and $\\alpha_{j}$ would be the *same*, but the $S_{i}$ would be *different*. Rather than $S_{i}$ representing the $i$th level of an $n$-dimensional experimental factor, it is the $i$th *random deviation*. From this perspective, $S_{i}$ is clearly an *additional error term*. Unfortunately, the linear model only has *one* error term. Thus, what we *want* to use is the model\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}    &=    \\mu + \\alpha_{j} + S_{i} + \\eta_{ij} \\\\\n",
    "    S_{i}     &\\sim \\mathcal{N}(0,\\sigma^{2}_{b})        \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}(0,\\sigma^{2}_{w})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "but we cannot, because this would require a method that could flexibly accommodate multiple error terms (which is exactly what *mixed-effects* model do). Instead, the repeated measures ANOVA aims to *replicate* this situation within the confines of a modelling framework that *does not allow it*. As you might imagine, this involves jumping through a number of hoops and places a number of restrictions on what is possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8847e",
   "metadata": {},
   "source": [
    "### Partitioned Errors in `R`\n",
    "Before discussing this in more detail, we will demonstrate the general idea in `R` in two ways, one using `lm()` and one using the `aov()` function. To begin with, let us specify the same model given above that contains the $S_{i}$ term. We will do this using the `mice2` data again, so we can show agreement with the paired $t$-test. \n",
    "\n",
    "First, we need to first convert this data into *long* format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c75534",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   time weight\n",
      "1   1 before  187.2\n",
      "2   1  after  429.5\n",
      "3   2 before  194.2\n",
      "4   2  after  404.4\n",
      "5   3 before  231.7\n",
      "6   3  after  405.6\n",
      "7   4 before  200.5\n",
      "8   4  after  397.2\n",
      "9   5 before  201.7\n",
      "10  5  after  377.9\n",
      "11  6 before  235.0\n",
      "12  6  after  445.8\n",
      "13  7 before  208.7\n",
      "14  7  after  408.4\n",
      "15  8 before  172.4\n",
      "16  8  after  337.0\n",
      "17  9 before  184.6\n",
      "18  9  after  414.3\n",
      "19 10 before  189.6\n",
      "20 10  after  380.3\n"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "library('reshape2')\n",
    "data('mice2')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 2\n",
    "n <- dim(mice2)[1]\n",
    "\n",
    "# reshape wide -> long\n",
    "mice2.long <- melt(mice2,                       # wide data frame\n",
    "                   id.vars='id',                # what stays fixed?\n",
    "                   variable.name=\"time\",        # name for the new predictor\n",
    "                   value.name=\"weight\")         # name for the new outcome\n",
    "\n",
    "mice2.long <- mice2.long[order(mice2.long$id),] # order by ID\n",
    "rownames(mice2.long) <- seq(1,n*t)              # fix row names\n",
    "\n",
    "print(mice2.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f792d9b",
   "metadata": {},
   "source": [
    "Next, we need to turn `id` into a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54fce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice2.long$id <- as.factor(mice2.long$id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76d9adf",
   "metadata": {},
   "source": [
    "Finally, we can specify the partitioned error model using `lm()` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6da669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = weight ~ time + id, data = mice2.long)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-21.410  -7.155   0.000   7.155  21.410 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  208.610     12.949  16.110 6.06e-08 ***\n",
       "timeafter    199.480      7.809  25.546 1.04e-09 ***\n",
       "id2           -9.050     17.460  -0.518   0.6167    \n",
       "id3           10.300     17.460   0.590   0.5698    \n",
       "id4           -9.500     17.460  -0.544   0.5996    \n",
       "id5          -18.550     17.460  -1.062   0.3157    \n",
       "id6           32.050     17.460   1.836   0.0996 .  \n",
       "id7            0.200     17.460   0.011   0.9911    \n",
       "id8          -53.650     17.460  -3.073   0.0133 *  \n",
       "id9           -8.900     17.460  -0.510   0.6225    \n",
       "id10         -23.400     17.460  -1.340   0.2130    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 17.46 on 9 degrees of freedom\n",
       "Multiple R-squared:  0.987,\tAdjusted R-squared:  0.9725 \n",
       "F-statistic: 68.22 on 10 and 9 DF,  p-value: 2.985e-07\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.mod <- lm(weight ~ time + id, data=mice2.long)\n",
    "summary(rm.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9381e",
   "metadata": {},
   "source": [
    "Ignoring the `id` effects, if we look at the test on `timeafter`, we can see that this agrees with the paired $t$-test from earlier. We can also tidy this output up a bit by calling `Anova()` on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2d62d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n",
      "Anova Table (Type II tests)\n",
      "\n",
      "Response: weight\n",
      "          Sum Sq Df F value    Pr(>F)    \n",
      "time      198961  1 652.613 1.039e-09 ***\n",
      "id          9013  9   3.285   0.04559 *  \n",
      "Residuals   2744  9                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "library('car')\n",
    "print(Anova(rm.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e8071",
   "metadata": {},
   "source": [
    "Where, again, we would ignore the test on `id` and just focus on the effect of `time`. \n",
    "\n",
    "Now, we have managed to produce correct tests for our factor of interest, so our model specification must be correct in that respect. However, the *way* we have done this needs some thought. After all, the fact that tests on `id` has been produced suggests that this model term is not being treated correctly. Do we really want a hypothesis test based on the null that all the subject means are the same? Given that this is a random sample of subjects, how meaningful would this be unless these were the only subjects in the world that we were interested in? As indicated earlier, the `id` effect is not really an effect of interest in the same way as `time`. In fact, `id` is considered part of the *error* rather than part of the *mean*. The way we have included `id` above is as part of the *mean function*, but really `id` should be part of the *variance function*. It would be like trying to specify a hypothesis test on the model residuals. We are not interested in some universal truth here because what we have are *random deviations* reflective of *error variance*. As such, in much the same way that the residuals are used to estimate the *within-subject* variance, we want the values of `id` to be used to estimate the *between-subjects* variance. Clearly, all we have done above is *remove* the variance of `id` from the residuals by moving it into the model equation. But we have done nothing to suggest that `id` should be treated differently from `time`. \n",
    "\n",
    "In order to tell `R` that `id` is an *additional error term*, we can use the `aov()` function. This is a wrapper for `lm()` designed to produce an ANOVA table where some of the model terms represent *error* rather than a traditional ANOVA effect. From an *estimation* perspective, this distinction does not make any difference because ANOVA mean squares are *already* estimates of variance. However, what *does* matter, is whether these mean squares form the *numerator* of an $F$-ratio (variance associated with *mean differences*) or the *denominator* of an $F$-ratio (variance associated with *error*). So, what we are really doing is telling `R` where to place the different mean squares in the ANOVA table. In other words, we have to tell `R` how we want the arithmetic to be organised.\n",
    "\n",
    "An example of using `aov()` for the `mice2` data is shown below. Here we use the `Error()` syntax within the model formula to indicate that `id` is an *error term*. This results in *two* ANOVA tables. One where $S_{i}$ forms the error term and one where $\\eta_{ij}$ forms the error term. Based on the model structure, `aov()` can work out that `time` should be in the table with $\\sigma^{2}_{w}$ as the error term. As there are no other terms in the model, the ANOVA table with $id$ as the error is empty, but we will see examples where this is not the case further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24416f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error: id\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\n",
      "Residuals  9   9013    1002               \n",
      "\n",
      "Error: Within\n",
      "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
      "time       1 198961  198961   652.6 1.04e-09 ***\n",
      "Residuals  9   2744     305                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "rm.aov.mod <- aov(weight ~ time + Error(id), data=mice2.long)\n",
    "print(summary(rm.aov.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e94ab",
   "metadata": {},
   "source": [
    "The main conclusion to draw at present is that the repeated measures ANOVA is based on a *partitioned error* model, where we separate the variance into $\\sigma^{2} = \\sigma^{2}_{b} + \\sigma^{2}_{w}$. However, because the normal linear model only has a *single* error term, we cannot do this automatically. Instead, we have to *remove* additional sources of variance from the errors by placing them within the *mean function*. We then have to manually construct different ANOVA tables for the different sources, using the mean square of some terms as *denominators* rather than *numerators*. This means that our *estimated model* is based only on a single error term, but the ANOVA table is based on treating some of the terms in the mean function as *additional error terms*. Hopefully it is clear that this is effectively an *ad hoc bolt-on* to a procedure that was never designed to support it[^submodel-foot]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f030e1",
   "metadata": {},
   "source": [
    "## The Implied Covariance Structure\n",
    "Another important element of the repeated measures ANOVA is the implied covariance structure. Although a variance-covariance matrix is never actually estimated or constructed as part of this procedure, it is *implied* by the model assumptions. As we will see further below, this implied structured is actually very restrictive and makes some strong claims about the nature of the repeated measurements. To see this, first consider the partitioned error model that the ANOVA table is assuming\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    y_{ij}             &\\sim \\mathcal{N}(\\mu_{j}, \\sigma^{2})             &\\quad \\text{(Population distribution)} \\\\\n",
    "    E(y_{ij})          &=    \\mu_{j} = \\mu + \\alpha_{j}                   &\\quad \\text{(Mean function)}           \\\\\n",
    "    \\text{Var}(y_{ij}) &=    \\sigma^{2} = \\sigma^{2}_{b} + \\sigma^{2}_{w} &\\quad \\text{(Variance function)}.      \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So, we can see that each observation is assumed to have the same variance, formed from $\\sigma^{2}_{b} + \\sigma^{2}_{w}$. This gives us the implied *diagonal* elements of the variance-covariance matrix. What about the *off-diagonal* elements? In a normal linear model these would be 0 to indicate no correlation. However, because we have repeated measurements, this will not be true. As established earlier, the fact that some observations share the error term $S_{i}$ creates correlation. The way this works is by examining the implied *covariance* between two measurements from the same subject\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(\\mu + \\alpha_{1} + S_{i} + \\epsilon_{i1}, \\mu + \\alpha_{2} + S_{i} + \\epsilon_{i2}) \n",
    "$$\n",
    "\n",
    "Because $\\mu$, $\\alpha_{1}$ and $\\alpha_{2}$ are *population constants*, they have 0 variance and thus do not contribute to the definition of covariance. These terms therefore drop-out, leaving\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i} + \\epsilon_{i1}, S_{i} + \\epsilon_{i2}) \n",
    "$$\n",
    "\n",
    "This can be expanded like so\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}) + \\text{Cov}(S_{i},\\epsilon_{i2}) + \\text{Cov}(\\epsilon_{i1},S_{i}) + \\text{Cov}(\\epsilon_{i1}, \\epsilon_{i2}). \n",
    "$$\n",
    "\n",
    "The subject effects and the errors are not correlated as these represent independent partitions of the overall error. As such, $\\text{Cov}(S_{i},\\epsilon_{i2}) = \\text{Cov}(\\epsilon_{i1},S_{i}) = 0$. Similarly, the final errors are uncorrelated because the correlation has been *removed* by partitioning-out the subject effects. So $\\text{Cov}(\\epsilon_{i1}, \\epsilon_{i2}) = 0$. This leaves\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}).\n",
    "$$\n",
    "\n",
    "A key result from the definition of covariance is that the [covariance of a random variable with itself is simply its variance](https://en.wikipedia.org/wiki/Covariance#Covariance_with_itself), meaning\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}) = \\text{Var}(S_{i}) = \\sigma^{2}_{b}.\n",
    "$$\n",
    "\n",
    "All of which is to say that the variance associated with the subject-specific deflections *is* the covariance induced by the repeated measurements. This means that the repeated measures ANOVA is implying the following covariance structure (as shown for two repeated measurements from two subjects)\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    y_{11} \\\\\n",
    "    y_{12} \\\\\n",
    "    y_{21} \\\\\n",
    "    y_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "\\sim\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "    \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  & 0                               & 0                               \\\\\n",
    "    \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} & 0                               & 0                               \\\\\n",
    "    0                               & 0                               & \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  \\\\\n",
    "    0                               & 0                               & \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} \\\\\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "This type of structure is known as *compound symmetry*, because all variances and covariances are the *same* across the repeated measurements. This is not really a problem when we have two repeats, because there is only one covariance term. However, consider what happens if we were to have *three* repeated measurements per-subject\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    y_{11} \\\\\n",
    "    y_{12} \\\\\n",
    "    y_{13} \\\\\n",
    "    y_{21} \\\\\n",
    "    y_{22} \\\\\n",
    "    y_{23} \\\\\n",
    "\\end{bmatrix}\n",
    "\\sim\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "    \\mu + \\alpha_{3} \\\\\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "    \\mu + \\alpha_{3} \\\\\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "    \\sigma^{2}_{b} + \\sigma^{2}_{w}  & \\sigma^{2}_{b}                  & \\sigma^{2}_{b}                  & 0                                & 0                               & 0                               \\\\\n",
    "    \\sigma^{2}_{b}                   & \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  & 0                                & 0                               & 0                               \\\\\n",
    "    \\sigma^{2}_{b}                   & \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} & 0                                & 0                               & 0                               \\\\\n",
    "    0                                & 0                               & 0                               & \\sigma^{2}_{b} + \\sigma^{2}_{w}  & \\sigma^{2}_{b}                  & \\sigma^{2}_{b}                  \\\\\n",
    "    0                                & 0                               & 0                               & \\sigma^{2}_{b}                   & \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  \\\\\n",
    "    0                                & 0                               & 0                               & \\sigma^{2}_{b}                   & \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} \\\\\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "This looks messy, but notice that the correlation between each of the repeated measurements is *exactly* the same value. Irrespective of what the experimental conditions are, the repeated measures ANOVA implies that they are correlated in exactly the same way. This is a *big* assumption. What if two conditions are positively correlated, but the others are negatively correlated? What is one of the experimental conditions works by making the correlation *weaker* compared to the other conditions? Any of these more complex situations are effectively *ignore* in the repeated measures ANOVA. Indeed, look back at the correlation structure we saw earlier in the lesson for the `selfesteem` data. This is clearly not compound symmetric. Remember that the importance of covariance relates to when we want to look at the *difference* between any of these conditions. If the covariance structure is *wrong* then the assumed standard error will be *wrong*. If we are using NHST, this means the calculated test statistic will not follow the assumed null distribution and $p$-value will either be *too liberal* or *too conservative*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdde13",
   "metadata": {},
   "source": [
    "### The Sphericity Condition\n",
    "Although we have suggested that the repeated measures ANOVA assumes a *compound symmetric* covariance structure, the reality is bit more nuanced. As indicated above, the assumption of compound symmetry is tied directly to the calculation of the standard errors, which then impact the denominator of the test statistic and inform the shape of the null distribution used to derive the $p$-values. If the actual covariance structure is *not* compound symmetric, then the formula used for the standard errors will be wrong, as will the formula used for the denominator of the test statistic. This will mean that the null distribution of the statistic is not what we think it is and the $p$-values will be inaccurate. This is a core limitation of the repeated measures ANOVA which is tied directly to the fact that the covariance structure is never explicitly *estimated*, it is only *assumed*.\n",
    "\n",
    "However, this assumption can actually be *weakened* slightly. Rather than assuming compound symmetry, a related condition known as *sphericity* is all that is required for the calculated $F$-statistic to follow the assumed null distribution. In brief, this condition is that the variance of all *pairwise differences* between the repeated measurements have equal variance. For instance, in the case of 3 repeated measures, this would be\n",
    "\n",
    "$$\n",
    "\\text{Var}(y_{i1} - y _{i2}) = \\text{Var}(y_{i1} - y _{i3}) = \\text{Var}(y_{i2} - y _{i3}) = \\sigma^{2}.\n",
    "$$\n",
    "\n",
    "We can *visualise* why this is known as *sphericity*. In the plots below, we transform the 3 repeated measures from each subject into the 3 subtractions from the formula above. We then plot these against each other in a 3D scatterplot. When sphericity is met (the *left* plot), this creates a *sphere* of points, because the variance is equal in all directions. When sphericity is *not* met (the *right* plot), this creates an *ellipsis*, because the variance is larger for some of these differences compared to others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7a7a22",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "library(rgl)\n",
    "library(htmlwidgets)\n",
    "\n",
    "set.seed(123)\n",
    "n_subj <- 800\n",
    "\n",
    "# --- Covariances in contrast space ---\n",
    "Sigma_spherical <- diag(3)\n",
    "\n",
    "A <- matrix(c(1,   0,   0,\n",
    "              0.8, 0.5, 0,\n",
    "              0.4, 0.3, 0.2),\n",
    "            nrow = 3, byrow = TRUE)\n",
    "Sigma_elliptical <- A %*% t(A)\n",
    "\n",
    "C_sph <- mvrnorm(n = n_subj, mu = c(0, 0, 0), Sigma = Sigma_spherical)\n",
    "C_ell <- mvrnorm(n = n_subj, mu = c(0, 0, 0), Sigma = Sigma_elliptical)\n",
    "\n",
    "colnames(C_sph) <- c(\"C1\", \"C2\", \"C3\")\n",
    "colnames(C_ell) <- c(\"C1\", \"C2\", \"C3\")\n",
    "\n",
    "# --- Build the rgl scene in an offscreen device ---\n",
    "open3d(useNULL = TRUE)\n",
    "bg3d(\"white\")\n",
    "\n",
    "layout3d(matrix(1:2, nrow = 1))\n",
    "\n",
    "# Left: spherical\n",
    "next3d()\n",
    "plot3d(\n",
    "  C_sph[, 1], C_sph[, 2], C_sph[, 3],\n",
    "  xlab = \"yi1 - yi2\",\n",
    "  ylab = \"yi1 - yi3\",\n",
    "  zlab = \"yi2 - yi3\",\n",
    "  col  = \"dodgerblue\",\n",
    "  size = 4,\n",
    "  alpha = 0.5,\n",
    "  box = TRUE,\n",
    "  type = \"s\"\n",
    ")\n",
    "lines3d(c(-4, 4), c(0, 0), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(-4, 4), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(0, 0), c(-4, 4), lwd = 3)\n",
    "\n",
    "aspect3d(\"iso\") \n",
    "\n",
    "# Right: elliptical\n",
    "next3d()\n",
    "plot3d(\n",
    "  C_ell[, 1], C_ell[, 2], C_ell[, 3],\n",
    "  xlab = \"yi1 - yi2\",\n",
    "  ylab = \"yi1 - yi3\",\n",
    "  zlab = \"yi2 - yi3\",\n",
    "  col  = \"firebrick\",\n",
    "  size = 4,\n",
    "  alpha = 0.5,\n",
    "  box = TRUE,\n",
    "  type = \"s\"\n",
    ")\n",
    "lines3d(c(-4, 4), c(0, 0), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(-4, 4), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(0, 0), c(-4, 4), lwd = 3)\n",
    "\n",
    "aspect3d(\"iso\") \n",
    "\n",
    "# Turn scene into widget\n",
    "w <- rglwidget()\n",
    "\n",
    "# Save as standalone HTML\n",
    "saveWidget(w, \"_static/sphericity_3d.html\", selfcontained = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0afd9d6",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">\n",
    "  <iframe\n",
    "    src=\"_static/sphericity_3d.html\"\n",
    "    class=\"sphericity-frame\"\n",
    "    width=\"800\"\n",
    "    height=\"600\"\n",
    "    style=\"border:none;\"\n",
    "  >\n",
    "  </iframe>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96675ccf",
   "metadata": {},
   "source": [
    "Now, this condition is really something of a *mathematical trick*. As pointed out by [Davis (2010)](), many authors have suggested that any realistic covariance matrix you may come across in practice that meets the criteria of *sphericity* will also be *compound symmetric*. Indeed, [Wallenstein (1982)]() went as far as to indicate that, for all practical purposes, the assumption of the repeated measures ANOVA *is* compound symmetry. However, the utility of expressing this assumption in terms of sphericity is that it allows for a *correction* to be applied. Rather than defining sphericity as above, it can be expressed in a mathematically equivalent way using a value known as $\\epsilon$[^noterr-foot]. When sphericity is met $\\epsilon = 1$, and when it is not met $\\epsilon \\neq 1$. This is useful because $\\epsilon$ can be used to adjust the degrees of freedom of the null $F$-distribution to make it correct when sphericity is violated. Thus, a null $F$-distribution of $F(\\epsilon \\times df_{1}, \\epsilon \\times df_{2})$ can be used, so long as we know $\\epsilon$. Several different methods of estimating $\\epsilon$ from the sample covariance matrix have been proposed by authors such as [Greenhouse & Geisser (1959)]() and [Huynh & Feldt (1976)](). \n",
    "\n",
    "If you have used statistical software such as SPSS in the past, these corrections should be familiar to you. Within `R`, these are available through the `ezANOVA()` function which, as we will see, is generally the most straight-forward way of generating a repeated measures ANOVA with the correct error partition. For simple models, this will make limited difference. However, as we will see below, more complex models because tricky to specify using `aov()`. This is partly a limitation in the structure of `aov()`, but also points to the general complexity of the repeated measures ANOVA framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d03371",
   "metadata": {},
   "source": [
    "In the code below, we show fitting a repeated measures ANOVA to the `selfesteem` data, first using `aov()` to correctly partition the error and then using `ezANOVA()` to get the same results with the sphericity corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f43d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "library('datarium')\n",
    "library('ez')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1eb7ed",
   "metadata": {},
   "source": [
    "## Repeated Measures ANOVA with Corrections in `R`\n",
    "As we can see above, using a partitioned error model with `aov()` is a tricky business and it would be very easy to get this wrong. As an alternative, we can use the `ezANOVA()` function from the `ez` package. As the name implies, this is designed to allow for an RM ANOVA without the usual difficulties associated with the `aov()` or `lm()` functions. Unfortuantely, the aim of this package is largely to make the `R` output the same as SPSS. So it does away with the linear model framework. This means, no residuals, no parameter estimates, no diagnostic plots or anything else we have made use of so far. If you *have* to use an RM ANOVA, this is the simplest way to get it *right*. However, as we will discuss below, we would disuade you from ever considering RM ANOVA as an option in the future. About the only utility of this is showing doubtful researchers that our better options of GLS and mixed-effects models are, in fact, giving them the same answer as an RM ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdee81e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id time    score\n",
      "1  1   t1 4.005027\n",
      "2  1   t2 5.182286\n",
      "3  1   t3 7.107831\n",
      "4  2   t1 2.558124\n",
      "5  2   t2 6.912915\n",
      "6  2   t3 6.308434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Error: id\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)\n",
       "Residuals  9   4.57  0.5078               \n",
       "\n",
       "Error: Within\n",
       "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "time       2 102.46   51.23   55.47 2.01e-08 ***\n",
       "Residuals 18  16.62    0.92                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library(ez)\n",
    "library('datarium')\n",
    "data('selfesteem')\n",
    "\n",
    "#=============================================================================#\n",
    "# Convert to LONG format\n",
    "#=============================================================================#\n",
    "t <- 3\n",
    "n <- dim(selfesteem)[1]\n",
    "\n",
    "# reshape wide -> long\n",
    "selfesteem.long <- melt(selfesteem, id.vars='id',variable.name=\"time\", value.name=\"score\")\n",
    "\n",
    "selfesteem.long           <- selfesteem.long[order(selfesteem.long$id),] # order by ID\n",
    "rownames(selfesteem.long) <- seq(1,n*t)                                  # fix row names\n",
    "selfesteem.long$id        <- as.factor(selfesteem.long$id)               # make id a factor\n",
    "\n",
    "print(head(selfesteem.long))\n",
    "\n",
    "#=============================================================================#\n",
    "# One-way RM ANOVA using aov()\n",
    "#=============================================================================#\n",
    "oneway.rm.aov <- aov(score ~ time + Error(id), data=selfesteem.long)\n",
    "summary(oneway.rm.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8648e",
   "metadata": {},
   "source": [
    "So, we can see that the error has been correctly partitioned and we have a suitable test of `time`. However, this is only valid so far as the assumption of sphericity is met. To generate this test as corrected for any violations of sphericity, the easiest approach is to use `ezANOVA()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7caac0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ANOVA\n",
      "  Effect DFn DFd        F            p p<.05       ges\n",
      "2   time   2  18 55.46903 2.013829e-08     * 0.8285954\n",
      "\n",
      "$`Mauchly's Test for Sphericity`\n",
      "  Effect         W          p p<.05\n",
      "2   time 0.5508534 0.09207551      \n",
      "\n",
      "$`Sphericity Corrections`\n",
      "  Effect       GGe        p[GG] p[GG]<.05       HFe        p[HF] p[HF]<.05\n",
      "2   time 0.6900613 2.161433e-06         * 0.7743711 6.032582e-07         *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneway.rm.ez <- ezANOVA(data=selfesteem.long, dv=score, wid=id, within=time)\n",
    "print(oneway.rm.ez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af23a9ca",
   "metadata": {},
   "source": [
    "Where `GGe` means `Greenhouse-Geiser epsilon` and `HFe` means `Huynh-Feldt epsilon`. These are the estimates of $\\epsilon$ using the methods mentioned earlier. As these are both $\\hat{\\epsilon} \\neq 1$, sphericity has been violated. The values `p[GG]` and `p[HF]` give the $p$-values for the omnibus test of `time`, after correcting the degrees of freedom using the two different estimates for $\\epsilon$. In both cases this remains significant, irrespective of the sphericity violation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e045e9",
   "metadata": {},
   "source": [
    "However, we still have all the limitations of `ezANOVA()` mentioned briefly last semester. Because this function does not aim to use the linear models framework, we cannot generate assumptions plots nor any of the other useful output we would normally get from `lm()`. Similarly, we cannot run follow-up tests using `emmeans`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6312",
   "metadata": {},
   "source": [
    "[^submodel-foot]: An alternative perspective here is that each error term represents a different *sub-model*. So, we can think of specifying *multiple* models, some of which require us to *average-over* certain factors. For instance, if we were to average-over the repeated measurements and then fit a model on the resultant outcome variable, this model would automatically have $\\sigma^{2}_{b}$ as its error term. This does make the whole procedure feel a little bit less of a hack, however, it is very impractical to do this, especially when the number of factors and interactions gets larger. You can read more about this approach in [McFarquhar (2019)](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2019.00352/full).\n",
    "\n",
    "[^noterr-foot]: Note that this is *not* the errors from the linear model, even though the Greek letter is the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}