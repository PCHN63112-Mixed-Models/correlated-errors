{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde1ccab-2d89-4ccf-aca6-dbea239a0625",
   "metadata": {},
   "source": [
    "# Higher-order Repeated Measures ANOVA\n",
    "In the previous part of this lesson, we examined the most simple case of the repeated measures ANOVA. Despite the simplicity of the design, we saw how this analysis had several complications around the correct partition of the error, as well as the assumptions made about the covariance structure. These alone were enough to suggest that the repeated measures ANOVA framework was problematic to apply in practice. Yet, there are even more complex situations where this framework can be applied. In this final part of the lesson, we will see how the repeated measures ANOVA is used in situations where there are additional *between-subjects* factors, as well as multiple *within-subject* factors. This is not to condone the use of the repeated measures ANOVA in these situations, rather it is to help you understand (a) how this method should be used correctly and (b) why an approach method such as mixed-effects will provide a much better alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0025798-daa1-475d-b3f3-ed1ac8da1a0c",
   "metadata": {},
   "source": [
    "## Adding Between-subjects Factors\n",
    "The first additional complexity we may come across is when we have *between-subjects* factor alongside the repeated measurements. For example, the `datarium` package contains the dataset `anxiety`. Here, 3 repeated measurements of anxiety have been taken at 3 different time points. Each subject comes from one of 3 groups practising different exercise regimes. So, `time` is the repeated measurement and `group` is the between-subjects factor. This is effectively a $3 \\times 3$ ANOVA, where our interest falls on the main effect of `group`, main effect of `time` and the `group:time` interaction. We can see this dataset below in its original form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b17c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;246m# A tibble: 6 × 5\u001b[39m\n",
      "  id    group    t1    t2    t3\n",
      "  \u001b[3m\u001b[38;5;246m<fct>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<fct>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[38;5;250m1\u001b[39m 1     grp1   14.1  14.4  14.1\n",
      "\u001b[38;5;250m2\u001b[39m 2     grp1   14.5  14.6  14.3\n",
      "\u001b[38;5;250m3\u001b[39m 3     grp1   15.7  15.2  14.9\n",
      "\u001b[38;5;250m4\u001b[39m 4     grp1   16    15.5  15.3\n",
      "\u001b[38;5;250m5\u001b[39m 5     grp1   16.5  15.8  15.7\n",
      "\u001b[38;5;250m6\u001b[39m 6     grp1   16.9  16.5  16.2\n"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "data('anxiety')\n",
    "print(head(anxiety))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3008832",
   "metadata": {},
   "source": [
    "and then reworked into long-format for univariate modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d85e554",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "library('reshape2')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 3\n",
    "n <- 45\n",
    "\n",
    "# reshape wide -> long\n",
    "anxiety.long <- melt(anxiety,                 # wide data frame\n",
    "                     id.vars=c('id','group'), # what stays fixed?\n",
    "                     variable.name='time',    # name for the new predictor\n",
    "                     value.name='anxiety')    # name for the new outcome\n",
    "\n",
    "anxiety.long           <- anxiety.long [order(anxiety.long$id),] # order by ID\n",
    "rownames(anxiety.long) <- seq(1,n*t)                             # fix row names\n",
    "anxiety.long$id        <- as.factor(anxiety.long$id)             # id as factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97baa3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id group time anxiety\n",
      "1  1  grp1   t1    14.1\n",
      "2  1  grp1   t2    14.4\n",
      "3  1  grp1   t3    14.1\n",
      "4  2  grp1   t1    14.5\n",
      "5  2  grp1   t2    14.6\n",
      "6  2  grp1   t3    14.3\n"
     ]
    }
   ],
   "source": [
    "print(head(anxiety.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476106c6",
   "metadata": {},
   "source": [
    "### The Between-subjects Error Term\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a74e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analysis of Variance Table\n",
       "\n",
       "Response: anxiety\n",
       "           Df  Sum Sq Mean Sq F value    Pr(>F)    \n",
       "group       2  61.992  30.996 367.701 < 2.2e-16 ***\n",
       "time        2  66.579  33.289 394.909 < 2.2e-16 ***\n",
       "id         42 299.146   7.123  84.494 < 2.2e-16 ***\n",
       "group:time  4  37.154   9.288 110.188 < 2.2e-16 ***\n",
       "Residuals  84   7.081   0.084                      \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety.lm <- lm(anxiety ~ group*time + id, data=anxiety.long)\n",
    "anova(anxiety.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb69965",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "... Getting this wrong could actually be disastrous for our inference, because we might falsely claim that the between-subjects factor has an effect because the error term is too small. Considering that these factors could correspond to something like treatment effects in patients and controls, concluding a false difference could have serious implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f31391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Error: id\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)  \n",
       "group      2  61.99  30.996   4.352 0.0192 *\n",
       "Residuals 42 299.15   7.123                 \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: Within\n",
       "           Df Sum Sq Mean Sq F value Pr(>F)    \n",
       "time        2  66.58   33.29   394.9 <2e-16 ***\n",
       "group:time  4  37.15    9.29   110.2 <2e-16 ***\n",
       "Residuals  84   7.08    0.08                   \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety.aov <- aov(anxiety ~ group*time + Error(id), data=anxiety.long)\n",
    "summary(anxiety.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98adc933",
   "metadata": {},
   "source": [
    "So now, even though the effect of `group` is still significant, we can see that this is much weaker when we use the correct error term ($F = 367.70$ vs $F = 4.35$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee845f",
   "metadata": {},
   "source": [
    "## Adding More Within-subject Factors\n",
    "This is where things start to get *really* tricky. Remember, as we go through this, that this is *not* something you would ever need to do in practice because we are not condoning the use of the repeated measures ANOVA. However, this complexity is shown to help you understand why you really do *not* want to do this. This is one of clearest cases where the automation provided by software such as SPSS actively *hides* so much of the complexity that researchers do not think twice about designing studies that require these approaches. As we will see below, we can also do this using `ezANOVA()`, but using `aov()` forces us to directly address how complex these methods become and why we really want a much more flexible and less cumbersome approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7178a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id diet exercises time weight\n",
      "1  1   no        no   t1  10.43\n",
      "2  1   no       yes   t1  11.12\n",
      "3  1  yes        no   t1  10.20\n",
      "4  1  yes       yes   t1  10.43\n",
      "5  1   no        no   t2  13.21\n",
      "6  1   no       yes   t2  12.51\n"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "library('reshape2')\n",
    "data('weightloss')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 12\n",
    "n <- 12\n",
    "\n",
    "# reshape wide -> long\n",
    "weightloss.long <- melt(weightloss,                         # wide data frame\n",
    "                        id.vars=c('id','diet','exercises'), # what stays fixed?\n",
    "                        variable.name=\"time\",               # name for the new predictor\n",
    "                        value.name=\"weight\")                # name for the new outcome\n",
    "\n",
    "weightloss.long <- weightloss.long[order(weightloss.long$id),] # order by ID\n",
    "rownames(weightloss.long) <- seq(1,n*t)              # fix row names\n",
    "\n",
    "print(head(weightloss.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c39d9c",
   "metadata": {},
   "source": [
    "### Multiple Within-subject Error Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9955ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ANOVA\n",
      "               Effect DFn DFd          F            p p<.05        ges\n",
      "2                diet   1  11   6.021440 3.202562e-02     * 0.02774675\n",
      "3           exercises   1  11  58.928078 9.650954e-06     * 0.28434954\n",
      "4                time   2  22 110.941583 3.218470e-12     * 0.54133853\n",
      "5      diet:exercises   1  11  75.356051 2.980284e-06     * 0.15716889\n",
      "6           diet:time   2  22   0.602562 5.561945e-01       0.01332945\n",
      "7      exercises:time   2  22  20.825889 8.408790e-06     * 0.27352201\n",
      "8 diet:exercises:time   2  22  14.246076 1.074451e-04     * 0.14663048\n",
      "\n",
      "$`Mauchly's Test for Sphericity`\n",
      "               Effect         W          p p<.05\n",
      "4                time 0.9833425 0.91944157      \n",
      "6           diet:time 0.5493166 0.05001654      \n",
      "7      exercises:time 0.6835227 0.14919857      \n",
      "8 diet:exercises:time 0.9589434 0.81089547      \n",
      "\n",
      "$`Sphericity Corrections`\n",
      "               Effect       GGe        p[GG] p[GG]<.05       HFe        p[HF]\n",
      "4                time 0.9836155 4.732515e-12         * 1.1960214 3.218470e-12\n",
      "6           diet:time 0.6893303 5.008306e-01           0.7558161 5.144265e-01\n",
      "7      exercises:time 0.7596029 7.470601e-05         * 0.8559657 3.105108e-05\n",
      "8 diet:exercises:time 0.9605626 1.395812e-04         * 1.1594775 1.074451e-04\n",
      "  p[HF]<.05\n",
      "4         *\n",
      "6          \n",
      "7         *\n",
      "8         *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library('ez')\n",
    "weightloss.ez <- ezANOVA(data=weightloss.long, dv=weight, wid=id, within=.(diet,exercises,time))\n",
    "print(weightloss.ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cedec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Error: id\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)\n",
       "Residuals 11   27.1   2.463               \n",
       "\n",
       "Error: id:diet\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)  \n",
       "diet       1  5.111   5.111   6.021  0.032 *\n",
       "Residuals 11  9.337   0.849                 \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:exercises\n",
       "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "exercises  1  71.16   71.16   58.93 9.65e-06 ***\n",
       "Residuals 11  13.28    1.21                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:time\n",
       "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "time       2 211.39  105.69   110.9 3.22e-12 ***\n",
       "Residuals 22  20.96    0.95                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:exercises:time\n",
       "               Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "exercises:time  2  67.43   33.72   20.83 8.41e-06 ***\n",
       "Residuals      22  35.62    1.62                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:diet:exercises\n",
       "               Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "diet:exercises  1  33.40   33.40   75.36 2.98e-06 ***\n",
       "Residuals      11   4.88    0.44                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:diet:time\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)\n",
       "diet:time  2   2.42   1.210   0.603  0.556\n",
       "Residuals 22  44.17   2.008               \n",
       "\n",
       "Error: id:diet:exercises:time\n",
       "                    Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "diet:exercises:time  2  30.77   15.39   14.25 0.000107 ***\n",
       "Residuals           22  23.76    1.08                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightloss.aov <- aov(weight ~ diet*exercises*time + \n",
    "                               Error(id                + \n",
    "                                     id:diet           +\n",
    "                                     id:exercises      +\n",
    "                                     id:time           +\n",
    "                                     id:exercises:time +\n",
    "                                     id:exercises:diet +\n",
    "                                     id:time:diet      +\n",
    "                                     id:time:exercises:diet), \n",
    "                        data=weightloss.long)\n",
    "summary(weightloss.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23525ebc",
   "metadata": {},
   "source": [
    "So now we have 8 ANOVA tables to deal with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af52161",
   "metadata": {},
   "source": [
    "There is an easier way to write this, using a special character inside the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f0e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightloss.aov <- aov(weight ~ diet*exercises*time + Error(id/(diet*exercises*time)), data=weightloss.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1eb7ed",
   "metadata": {},
   "source": [
    "### Using the `ezANOVA()` Function\n",
    "As we can see above, using a partitioned error model with `aov()` is a tricky business and it would be very easy to get this wrong. As an alternative, we can use the `ezANOVA()` function from the `ez` package. As the name implies, this is designed to allow for an RM ANOVA without the usual difficulties associated with the `aov()` or `lm()` functions. Unfortuantely, the aim of this package is largely to make the `R` output the same as SPSS. So it does away with the linear model framework. This means, no residuals, no parameter estimates, no diagnostic plots or anything else we have made use of so far. If you *have* to use an RM ANOVA, this is the simplest way to get it *right*. However, as we will discuss below, we would disuade you from ever considering RM ANOVA as an option in the future. About the only utility of this is showing doubtful researchers that our better options of GLS and mixed-effects models are, in fact, giving them the same answer as an RM ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdee81e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "\u001b[1m\u001b[33mError\u001b[39m in `ezANOVA()`:\u001b[22m\n\u001b[33m!\u001b[39m argument \"data\" is missing, with no default",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[33mError\u001b[39m in `ezANOVA()`:\u001b[22m\n",
      "\u001b[33m!\u001b[39m argument \"data\" is missing, with no default\n",
      "\u001b[90m    \u001b[39m▆\n",
      "\u001b[90m 1. \u001b[39m└─\u001b[1mez\u001b[22m::ezANOVA()"
     ]
    }
   ],
   "source": [
    "library(ez)\n",
    "ezANOVA()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdc59d",
   "metadata": {},
   "source": [
    "## Why We Should *Not* Use RM ANOVA\n",
    "Everything we have discussed above has really been an exercise in telling you why you really do not want to use RM ANOVA. All the unncessary fiddling with error terms and different tests requiring different errors is a complication that we could simply do without. Even if we do manage to successfully work out what needs to go where (or get a function like `ezANOVA()` to sort it for us), we are still left with a method that has a number of meaningful restrictions. ... Because of this, the RM ANOVA is both tricky to understand, tricky to use correctly and massively inflexible. It is no wonder that statisticians abandoned this method decades ago! And yet, this is the method that has persisted in psychology until releatively recently.\n",
    "\n",
    "... testing assumptions and follow-up tests...\n",
    "\n",
    "This section has largely been motivational to understand why we want to use something more flexible and more modern, but it is important to recognise that you may well end up working with someone who knows nothing beyond the RM ANOVA. In those situations, it is useful to (a) motivate the need for something better and (b) understand how to get the RM ANOVA results in `R`, in case they require further convincing. So, we do not condone the use of the RM ANOVA, but we understand its place in psychology and also understand that there are times where you may want to see what the RM ANOVA says, even if you do not wish to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66d2d9-9c81-478c-a0d9-6b8ed9add05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6312",
   "metadata": {},
   "source": [
    "[^submodel-foot]: An alternative perspective here is that each error term represents a different *sub-model*. So, we can think of specifying *multiple* models, some of which require us to *average-over* certain factors. For instance, if we were to average-over the repeated measurements and then fit a model on the resultant outcome variable, this model would automatically have $\\sigma^{2}_{b}$ as its error term. This does make the whole procedure feel a little bit less of a hack, however, it is very impractical to do this, especially when the number of factors and interactions gets larger. You can read more about this approach in [McFarquhar (2019)](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2019.00352/full).\n",
    "\n",
    "[^noterr-foot]: Note that this is *not* the errors from the linear model, even though the Greek letter is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e895875",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}