{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde1ccab-2d89-4ccf-aca6-dbea239a0625",
   "metadata": {},
   "source": [
    "# The Paired $t$-test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc8b1f-545c-4f4b-abf6-505f93433003",
   "metadata": {},
   "source": [
    "To begin, let us examine the difference in results between a *two-sample* $t$-test and a *paired* $t$-test. To do this, we can simulate data as we did before and then use the `t.test()` function with the `paired` option set to either `TRUE` or `FALSE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fcb5660-d167-4ee2-ac04-5578e778e1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tTwo Sample t-test\n",
       "\n",
       "data:  y[, 1] and y[, 2]\n",
       "t = -0.92759, df = 98, p-value = 0.3559\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -0.6487683  0.2354578\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "0.9601951 1.1668504 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tPaired t-test\n",
       "\n",
       "data:  y[, 1] and y[, 2]\n",
       "t = -2.4952, df = 49, p-value = 0.01601\n",
       "alternative hypothesis: true mean difference is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -0.3730884 -0.0402221\n",
       "sample estimates:\n",
       "mean difference \n",
       "     -0.2066553 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MASS)\n",
    "set.seed(666)\n",
    "\n",
    "var1  <- 1\n",
    "var2  <- 1\n",
    "rho   <- 0.8\n",
    "covar <- rho*var1*var2\n",
    "\n",
    "Sigma <- matrix(data=c(var1,covar,covar,var2), nrow=2, ncol=2)\n",
    "y     <- mvrnorm(n=50, mu=c(1,1.25), Sigma=Sigma)\n",
    "\n",
    "t.test(x=y[,1], y=y[,2], paired=FALSE, var.equal=TRUE)\n",
    "t.test(x=y[,1], y=y[,2], paired=TRUE,  var.equal=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc994a9-065b-417d-aaa1-ca269a2762ea",
   "metadata": {},
   "source": [
    "Perhaps the first thing you will notice is that the two-sample $t$-test is *non-significant*, whereas the paired $t$-test is *significant*. However, there is more to unpack here. \n",
    "\n",
    "Firstly, the output from the *two-sample* test reports the estimated group means as $\\hat{\\mu}_{1} = 0.9601951$ and $\\hat{\\mu}_{2} = 1.1668504$, meaning that the estimated mean difference is $\\hat{\\mu}_{1} - \\hat{\\mu}_{2} = 1.090923 - 1.303266 = -0.2066553$. This is the same as reported by the *paired* test. As such, the difference between these methods has nothing to do with the estimated mean difference, as this is *identical*.\n",
    "\n",
    "Where the two tests differ can be seen in terms of the $t$-statistic itself, the degrees of freedom and the confidence interval. Remembering that the structure of a $t$-statistic is\n",
    "\n",
    "$$\n",
    "t = \\frac{\\mu_{1} - \\mu_{2}}{\\text{SE}\\{\\mu_{1} - \\mu_{2}\\}}\n",
    "$$\n",
    "\n",
    "we think of the test statistic as dividing the mean difference by the standard error of the difference. If the numerator of the test statistic is the same under both the *two-sample* and *paired* tests, then the difference in results *must* be coming from a difference in the denominator. In other words, the standard error of the difference changes between the two-sample and paired cases.\n",
    "\n",
    "This should not be a surprise, given the discussion earlier in this lesson. If the correlation is *positive*, then we expect the standard error of the difference to be *smaller* when the data are correlated. Indeed, this is what we see here. In both cases, we can recover the standard error by dividing the mean difference by the $t$-statistic. This gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4880d54e-659b-46f1-b44e-ce50ecfe9729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.223</li><li>0.083</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.223\n",
       "\\item 0.083\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.223\n",
       "2. 0.083\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.223 0.083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(c(-0.2066553/-0.92759, -0.2066553/-2.4952), digits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27b9f1-f62c-4d53-8006-53c4d468a38a",
   "metadata": {},
   "source": [
    "So, in the *two-sample* case the standard error is $0.223$, which is larger than the standard error in the *paired* case, which is $0.083$. Again, this should not be a surprise and the conclusion here would be that the estimate in the *two-sample* case is *too large*, given the correlation in the data. However, the question for us here is really about *how* the *paired* $t$-test is able to take this into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73163370-ee1f-4d73-8093-0ef1241a6ee2",
   "metadata": {},
   "source": [
    "## The Paired $t$-test as a Linear Model\n",
    "\n",
    "To begin understanding how this works, it is useful to reframe the $t$-test in terms of a linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273663a2-a58c-4565-a204-6a2ea79feb0b",
   "metadata": {},
   "source": [
    "### Two-sample $t$-test as an LM\n",
    "To see this, we first start with the familiar case of the *two-sample* model. We can fit this as an LM within `R` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffbcad42-10d4-4d69-9d34-5ad829b7dca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = y.long ~ cond)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-2.52090 -0.85738  0.01796  0.70661  2.41932 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   0.9602     0.1575   6.095 2.16e-08 ***\n",
       "condB         0.2067     0.2228   0.928    0.356    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.114 on 98 degrees of freedom\n",
       "Multiple R-squared:  0.008703,\tAdjusted R-squared:  -0.001412 \n",
       "F-statistic: 0.8604 on 1 and 98 DF,  p-value: 0.3559\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(matrixcalc)\n",
    "\n",
    "y.long <- vec(t(y))          # Turn y into a column\n",
    "cond   <- rep(c(\"A\",\"B\"),50) # Create a predictor for the two conditions\n",
    "\n",
    "two.sample.mod <- lm(y.long ~ cond)\n",
    "summary(two.sample.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54d7ae-2f80-4162-b1ad-ed66b71bbe90",
   "metadata": {},
   "source": [
    "Focussing on the coefficient and tests associated with `CondB` in the table, we can see $t = 0.928$ and $p = 0.356$, which is the same[^foot1] as we saw for the two-sample test earlier. We can also see that the degrees of freedom agree at $98$. So we have managed to successfully implement the *two-sample* $t$-test as a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3b644-71c1-4640-b0b3-28023e256ab2",
   "metadata": {},
   "source": [
    "Now, we know that this is *incorrect* for correlated data. However, specifying the model in this form allows us to dig deeper into *why* this is wrong, which will then provide us with the insight needed to correct this and thus tell us how the *paired* method is able to accommodate correlation. This will also provide us with the grounding needed to understand the traditional repeated measured ANOVA, as well as mixed-effect model a little later in the unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc7745-7055-4e16-83fa-4ce2d215b1ab",
   "metadata": {},
   "source": [
    "### Variance Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f925e67-aa9b-409f-a3c0-d3ef395d262a",
   "metadata": {},
   "source": [
    "### Recreating the Paired $t$-test in the Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e32e1c6a-3b01-4277-a7d9-23be4ac7754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = y.long ~ cond + subject)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-0.9091 -0.1826  0.0000  0.1826  0.9091 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  1.736326   0.295727   5.871 3.69e-07 ***\n",
       "condB        0.206655   0.082820   2.495 0.016005 *  \n",
       "subject2     1.196331   0.414100   2.889 0.005741 ** \n",
       "subject3    -1.051564   0.414100  -2.539 0.014328 *  \n",
       "subject4     1.209435   0.414100   2.921 0.005268 ** \n",
       "subject5    -2.817765   0.414100  -6.805 1.33e-08 ***\n",
       "subject6     0.004824   0.414100   0.012 0.990752    \n",
       "subject7    -1.953810   0.414100  -4.718 2.02e-05 ***\n",
       "subject8    -1.475991   0.414100  -3.564 0.000825 ***\n",
       "subject9    -2.414923   0.414100  -5.832 4.25e-07 ***\n",
       "subject10   -0.754529   0.414100  -1.822 0.074547 .  \n",
       "subject11    1.325056   0.414100   3.200 0.002413 ** \n",
       "subject12   -2.394042   0.414100  -5.781 5.08e-07 ***\n",
       "subject13    0.105629   0.414100   0.255 0.799729    \n",
       "subject14   -2.346537   0.414100  -5.667 7.61e-07 ***\n",
       "subject15   -0.587411   0.414100  -1.419 0.162367    \n",
       "subject16   -0.786589   0.414100  -1.900 0.063391 .  \n",
       "subject17    0.099602   0.414100   0.241 0.810926    \n",
       "subject18   -0.387452   0.414100  -0.936 0.354043    \n",
       "subject19   -1.267217   0.414100  -3.060 0.003583 ** \n",
       "subject20    0.031173   0.414100   0.075 0.940299    \n",
       "subject21   -1.371237   0.414100  -3.311 0.001748 ** \n",
       "subject22   -1.836987   0.414100  -4.436 5.18e-05 ***\n",
       "subject23    0.489084   0.414100   1.181 0.243274    \n",
       "subject24   -1.011166   0.414100  -2.442 0.018269 *  \n",
       "subject25   -0.685651   0.414100  -1.656 0.104162    \n",
       "subject26   -2.120863   0.414100  -5.122 5.09e-06 ***\n",
       "subject27   -1.783486   0.414100  -4.307 7.93e-05 ***\n",
       "subject28   -2.387982   0.414100  -5.767 5.34e-07 ***\n",
       "subject29   -1.722743   0.414100  -4.160 0.000128 ***\n",
       "subject30   -1.988735   0.414100  -4.803 1.52e-05 ***\n",
       "subject31    0.001599   0.414100   0.004 0.996935    \n",
       "subject32   -1.323223   0.414100  -3.195 0.002444 ** \n",
       "subject33    0.643038   0.414100   1.553 0.126893    \n",
       "subject34   -1.307154   0.414100  -3.157 0.002730 ** \n",
       "subject35   -0.497410   0.414100  -1.201 0.235455    \n",
       "subject36   -0.464979   0.414100  -1.123 0.266967    \n",
       "subject37   -0.307461   0.414100  -0.742 0.461341    \n",
       "subject38   -2.122708   0.414100  -5.126 5.01e-06 ***\n",
       "subject39   -0.543883   0.414100  -1.313 0.195163    \n",
       "subject40    1.240640   0.414100   2.996 0.004283 ** \n",
       "subject41   -0.026287   0.414100  -0.063 0.949642    \n",
       "subject42   -1.178307   0.414100  -2.845 0.006457 ** \n",
       "subject43   -1.173931   0.414100  -2.835 0.006642 ** \n",
       "subject44    1.036230   0.414100   2.502 0.015723 *  \n",
       "subject45   -0.225670   0.414100  -0.545 0.588250    \n",
       "subject46   -1.772234   0.414100  -4.280 8.66e-05 ***\n",
       "subject47   -1.008887   0.414100  -2.436 0.018518 *  \n",
       "subject48   -0.627914   0.414100  -1.516 0.135860    \n",
       "subject49   -0.103401   0.414100  -0.250 0.803864    \n",
       "subject50   -0.359054   0.414100  -0.867 0.390129    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.4141 on 49 degrees of freedom\n",
       "Multiple R-squared:  0.9315,\tAdjusted R-squared:  0.8616 \n",
       "F-statistic: 13.33 on 50 and 49 DF,  p-value: 2.636e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject <- matrix(data=c(seq(1,50),seq(1,50)), nrow=50, ncol=2)\n",
    "subject <- vec(t(subject))\n",
    "subject <- as.factor(subject)\n",
    "\n",
    "paired.mod <- lm(y.long ~ cond + subject)\n",
    "summary(paired.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4c10f-0528-48e3-ac86-141aaef3d95f",
   "metadata": {},
   "source": [
    "Now, the output here is a bit of mess due to all the subject effects. However, if you look at the coefficient and test for `CondB`, notice that $t = 2.495$ and $p = 0.016$, which is the same as the *paired* $t$-test from earlier. Furthermore, the degrees of freedom are now correct at $49$. As such, adding the subject effects to the model has allowed the *between-subjects* error to be partitioned out and thus the remaining variance calculated from the residuals is *only* the *within-subject* error. This is the error needed to correctly estimate the standard error of the paired difference and thus the model results are now correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9ee4b-b274-4207-b836-2097bec1c194",
   "metadata": {},
   "source": [
    "```{admonition} Advanced: Understanding the coefficients in the paired model\n",
    ":class: warning, dropdown\n",
    "Boo!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a091fc2-fa8d-4da2-b4af-83c5c5c7089f",
   "metadata": {},
   "source": [
    "[^foot1]: Due to the way the factors are coded in `R`, the coefficient is actually the opposite comparison here, hence why the $t$-statistic is *positive* rather than *negative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45b101-ecf5-4f63-a7e0-fab2f65f4eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}