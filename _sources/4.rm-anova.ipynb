{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde1ccab-2d89-4ccf-aca6-dbea239a0625",
   "metadata": {},
   "source": [
    "# One-way Repeated Measures ANOVA\n",
    "In the previous part of this lesson, we examined the paired $t$-test as the most basic method for dealing with repeated measurements. In doing do, we established that taking the *difference* between the pairs was enough to remove correlation and render the data independent, allowing us to specify a simple one-sample test on the mean difference. In order to understand this, we split our usual single error term into two components, one associated with each subject and one associated with any other deviations. We then saw how the term associated with each subject *cancelled* when the pairs were subtracted, implying that this component captured the correlation between the repeated measurements. Furthermore, by viewing these terms in relation to a partition of the error variance, we established that it is the *between-subjects* variance that is removed by subtraction, leaving only the *within-subject* variance. Because this is smaller than the total variance, and smaller than the between-subjects variance, this rendered the standard error of the estimated mean difference smaller, thus making the test statistic larger. This not only established *why* the paired $t$-test is different to the independent measures $t$-test, but also why the paired $t$-test is typically *more powerful* and thus desirable, from an inferential perspective. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061c103",
   "metadata": {},
   "source": [
    "## Limitations of the Model of *Paired Differences*\n",
    "Although this *paired differences* framework works well when the data consists of only *two* repeated measurements, we hit a problem if we have *more than two* repeated measurements, *more than one* repeated measures factor or even when we have a mixture of repeated measurements and independent measurements. In many of these cases, we cannot take a simple subtraction and then analyse the resultant differences. So, while the paired $t$-test is fine in simple cases, it does not generalise very easily. \n",
    "\n",
    "In order to allow the analysis of more complex experimental situations, we need to abandon the idea of making the data independent through subtraction. Instead, we need to accommodate the correlation *directly* within the model. The general theme of this section of the unit is *mixed-effects models*, which represent the most modern solution to this problem. However, in this part of the lesson we will discuss an older solution in the form of the *repeated measures ANOVA*. This is really a stepping-stone towards mixed-effects models, rather than a recommendation, as the repeated measures ANOVA is rather limited in practice. Nevertheless, this method is still used widely in psychological research and so is still worth understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffadc85",
   "metadata": {},
   "source": [
    "## The Model of *Partitioned Errors*\n",
    "As mentioned above, because *subtraction* only works in a number of limited cases, we need to abandon it as our general solution to dealing with dependent data. Instead, we need to work with data that we *know* is correlated. Unfortunately, as we have already established, the linear model framework assumes that the errors of the model are $i.i.d.$, which will not be true under repeated measurements. However, we have already seen a possible solution to this problem, as the removal of the subject terms $S_{i}$ theoretically *removes* the correlation and renders the errors independent. Thus, if we were to *include* the term $S_{i}$ in the model, the errors would meet the $i.i.d.$ criteria. Furthermore, the single error variance assumed by the linear model would be the *within-subject* variance and thus would be suitable for inference on the repeated measurements. Putting all this together gives us the model\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}    &=                      \\mu + \\alpha_{j} + S_{i} + \\eta_{ij} \\\\\n",
    "    \\eta_{ij} &\\overset{i.i.d.}{\\sim} \\mathcal{N}(0,\\sigma^{2}_{w})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "which is the basis for the repeated measures ANOVA.\n",
    "\n",
    "Now, in the specification above, we have treated $S_{i}$ like any other factor in an ANOVA model. However, this is not really correct. As discussed in the previous part of this lesson, $S_{i}$ comes from *splitting* the overall error term $\\epsilon_{ij}$. So, in theory, rather than representing population constants (like $\\mu$ and $\\alpha_{j}$), the $S_{i}$ are a *random variable*. This makes sense because the subjects represent a *random sample*, rather than a fixed quantity. If we were to run the experiment again, $\\mu$ and $\\alpha_{j}$ would be the *same*, but the $S_{i}$ would be *different*. Rather than $S_{i}$ representing the $i$th level of an $n$-dimensional experimental factor, it is the $i$th *random deviation*. From this perspective, $S_{i}$ is clearly an *additional error term*. Unfortunately, the linear model only has *one* error term. Thus, what we *want* to use is the model\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}    &=    \\mu + \\alpha_{j} + S_{i} + \\eta_{ij} \\\\\n",
    "    S_{i}     &\\sim \\mathcal{N}(0,\\sigma^{2}_{b})        \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}(0,\\sigma^{2}_{w})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "but we cannot, because this would require a method that could flexibly accommodate multiple error terms (which is exactly what *mixed-effects* model do). Instead, the repeated measures ANOVA aims to *replicate* this situation within the confines of a modelling framework that *does not allow it*. As you might imagine, this involves jumping through a number of hoops and places a number of restrictions on what is possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8847e",
   "metadata": {},
   "source": [
    "### Partitioned Errors in `R`\n",
    "Before discussing this in more detail, we will demonstrate the general idea in `R` in two ways, one using `lm()` and one using the `aov()` function. To begin with, let us specify the same model given above that contains the $S_{i}$ term. We will do this using the `mice2` data again, so we can show agreement with the paired $t$-test. \n",
    "\n",
    "First, we need to first convert this data into *long* format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c75534",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   time weight\n",
      "1   1 before  187.2\n",
      "2   1  after  429.5\n",
      "3   2 before  194.2\n",
      "4   2  after  404.4\n",
      "5   3 before  231.7\n",
      "6   3  after  405.6\n",
      "7   4 before  200.5\n",
      "8   4  after  397.2\n",
      "9   5 before  201.7\n",
      "10  5  after  377.9\n",
      "11  6 before  235.0\n",
      "12  6  after  445.8\n",
      "13  7 before  208.7\n",
      "14  7  after  408.4\n",
      "15  8 before  172.4\n",
      "16  8  after  337.0\n",
      "17  9 before  184.6\n",
      "18  9  after  414.3\n",
      "19 10 before  189.6\n",
      "20 10  after  380.3\n"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "library('reshape2')\n",
    "data('mice2')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 2\n",
    "n <- dim(mice2)[1]\n",
    "\n",
    "# reshape wide -> long\n",
    "mice2.long <- melt(mice2,                       # wide data frame\n",
    "                   id.vars='id',                # what stays fixed?\n",
    "                   variable.name=\"time\",        # name for the new predictor\n",
    "                   value.name=\"weight\")         # name for the new outcome\n",
    "\n",
    "mice2.long <- mice2.long[order(mice2.long$id),] # order by ID\n",
    "rownames(mice2.long) <- seq(1,n*t)              # fix row names\n",
    "\n",
    "print(mice2.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f792d9b",
   "metadata": {},
   "source": [
    "Next, we need to turn `id` into a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54fce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice2.long$id <- as.factor(mice2.long$id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76d9adf",
   "metadata": {},
   "source": [
    "Finally, we can specify the partitioned error model using `lm()` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6da669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = weight ~ time + id, data = mice2.long)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-21.410  -7.155   0.000   7.155  21.410 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  208.610     12.949  16.110 6.06e-08 ***\n",
       "timeafter    199.480      7.809  25.546 1.04e-09 ***\n",
       "id2           -9.050     17.460  -0.518   0.6167    \n",
       "id3           10.300     17.460   0.590   0.5698    \n",
       "id4           -9.500     17.460  -0.544   0.5996    \n",
       "id5          -18.550     17.460  -1.062   0.3157    \n",
       "id6           32.050     17.460   1.836   0.0996 .  \n",
       "id7            0.200     17.460   0.011   0.9911    \n",
       "id8          -53.650     17.460  -3.073   0.0133 *  \n",
       "id9           -8.900     17.460  -0.510   0.6225    \n",
       "id10         -23.400     17.460  -1.340   0.2130    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 17.46 on 9 degrees of freedom\n",
       "Multiple R-squared:  0.987,\tAdjusted R-squared:  0.9725 \n",
       "F-statistic: 68.22 on 10 and 9 DF,  p-value: 2.985e-07\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.mod <- lm(weight ~ time + id, data=mice2.long)\n",
    "summary(rm.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9381e",
   "metadata": {},
   "source": [
    "Ignoring the `id` effects, if we look at the test on `timeafter`, we can see that this agrees with the paired $t$-test from earlier. We can also tidy this output up a bit by calling `Anova()` on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2d62d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n",
      "Anova Table (Type II tests)\n",
      "\n",
      "Response: weight\n",
      "          Sum Sq Df F value    Pr(>F)    \n",
      "time      198961  1 652.613 1.039e-09 ***\n",
      "id          9013  9   3.285   0.04559 *  \n",
      "Residuals   2744  9                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "library('car')\n",
    "print(Anova(rm.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e8071",
   "metadata": {},
   "source": [
    "Where, again, we would ignore the test on `id` and just focus on the effect of `time`. \n",
    "\n",
    "Now, we have managed to produce correct tests for our factor of interest, so our model specification must be correct in that respect. However, the *way* we have done this needs some thought. After all, the fact that tests on `id` has been produced suggests that this model term is not being treated correctly. Do we really want a hypothesis test based on the null that all the subject means are the same? Given that this is a random sample of subjects, how meaningful would this be unless these were the only subjects in the world that we were interested in? As indicated earlier, the `id` effect is not really an effect of interest in the same way as `time`. In fact, `id` is considered part of the *error* rather than part of the *mean*. The way we have included `id` above is as part of the *mean function*, but really `id` should be part of the *variance function*. It would be like trying to specify a hypothesis test on the model residuals. We are not interested in some universal truth here because what we have are *random deviations* reflective of *error variance*. As such, in much the same way that the residuals are used to estimate the *within-subject* variance, we want the values of `id` to be used to estimate the *between-subjects* variance. Clearly, all we have done above is *remove* the variance of `id` from the residuals by moving it into the model equation. But we have done nothing to suggest that `id` should be treated differently from `time`. \n",
    "\n",
    "In order to tell `R` that `id` is an *additional error term*, we can use the `aov()` function. This is a wrapper for `lm()` designed to produce an ANOVA table where some of the model terms represent *error* rather than a traditional ANOVA effect. From an *estimation* perspective, this distinction does not make any difference because ANOVA mean squares are *already* estimates of variance. However, what *does* matter, is whether these mean squares form the *numerator* of an $F$-ratio (variance associated with *mean differences*) or the *denominator* of an $F$-ratio (variance associated with *error*). So, what we are really doing is telling `R` where to place the different mean squares in the ANOVA table. In other words, we have to tell `R` how we want the arithmetic to be organised.\n",
    "\n",
    "An example of using `aov()` for the `mice2` data is shown below. Here we use the `Error()` syntax within the model formula to indicate that `id` is an *error term*. This results in *two* ANOVA tables. One where $S_{i}$ forms the error term and one where $\\eta_{ij}$ forms the error term. Based on the model structure, `aov()` can work out that `time` should be in the table with $\\sigma^{2}_{w}$ as the error term. As there are no other terms in the model, the ANOVA table with $id$ as the error is empty, but we will see examples where this is not the case further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24416f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error: id\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\n",
      "Residuals  9   9013    1002               \n",
      "\n",
      "Error: Within\n",
      "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
      "time       1 198961  198961   652.6 1.04e-09 ***\n",
      "Residuals  9   2744     305                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "rm.aov.mod <- aov(weight ~ time + Error(id), data=mice2.long)\n",
    "print(summary(rm.aov.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e94ab",
   "metadata": {},
   "source": [
    "The main conclusion to draw at present is that the repeated measures ANOVA is based on a *partitioned error* model, where we separate the variance into $\\sigma^{2} = \\sigma^{2}_{b} + \\sigma^{2}_{w}$. However, because the normal linear model only has a *single* error term, we cannot do this automatically. Instead, we have to *remove* additional sources of variance from the errors by placing them within the *mean function*. We then have to manually construct different ANOVA tables for the different sources, using the mean square of some terms as *denominators* rather than *numerators*. This means that our *estimated model* is based only on a single error term, but the ANOVA table is based on treating some of the terms in the mean function as *additional error terms*. Hopefully it is clear that this is effectively an *ad hoc bolt-on* to a procedure that was never designed to support it[^submodel-foot]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f030e1",
   "metadata": {},
   "source": [
    "## The Implied Covariance Structure\n",
    "Another important element of the repeated measures ANOVA is the implied covariance structure. Although a variance-covariance matrix is never actually estimated or constructed as part of this procedure, it is *implied* by the model assumptions. As we will see further below, this implied structured is actually very restrictive and makes some strong claims about the nature of the repeated measurements. To see this, first consider the partitioned error model that the ANOVA table is assuming\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    y_{ij}             &\\sim \\mathcal{N}(\\mu_{j}, \\sigma^{2})             &\\quad \\text{(Population distribution)} \\\\\n",
    "    E(y_{ij})          &=    \\mu_{j} = \\mu + \\alpha_{j}                   &\\quad \\text{(Mean function)}           \\\\\n",
    "    \\text{Var}(y_{ij}) &=    \\sigma^{2} = \\sigma^{2}_{b} + \\sigma^{2}_{w} &\\quad \\text{(Variance function)}.      \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So, we can see that each observation is assumed to have the same variance, formed from $\\sigma^{2}_{b} + \\sigma^{2}_{w}$. This gives us the implied *diagonal* elements of the variance-covariance matrix. What about the *off-diagonal* elements? In a normal linear model these would be 0 to indicate no correlation. However, because we have repeated measurements, this will not be true. As established earlier, the fact that some observations share the error term $S_{i}$ creates correlation. The way this works is by examining the implied *covariance* between two measurements from the same subject\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(\\mu + \\alpha_{1} + S_{i} + \\epsilon_{i1}, \\mu + \\alpha_{2} + S_{i} + \\epsilon_{i2}) \n",
    "$$\n",
    "\n",
    "Because $\\mu$, $\\alpha_{1}$ and $\\alpha_{2}$ are *population constants*, they have 0 variance and thus do not contribute to the definition of covariance. These terms therefore drop-out, leaving\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i} + \\epsilon_{i1}, S_{i} + \\epsilon_{i2}) \n",
    "$$\n",
    "\n",
    "This can be expanded like so\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}) + \\text{Cov}(S_{i},\\epsilon_{i2}) + \\text{Cov}(\\epsilon_{i1},S_{i}) + \\text{Cov}(\\epsilon_{i1}, \\epsilon_{i2}). \n",
    "$$\n",
    "\n",
    "The subject effects and the errors are not correlated as these represent independent partitions of the overall error. As such, $\\text{Cov}(S_{i},\\epsilon_{i2}) = \\text{Cov}(\\epsilon_{i1},S_{i}) = 0$. Similarly, the final errors are uncorrelated because the correlation has been *removed* by partitioning-out the subject effects. So $\\text{Cov}(\\epsilon_{i1}, \\epsilon_{i2}) = 0$. This leaves\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}).\n",
    "$$\n",
    "\n",
    "A key result from the definition of covariance is that the [covariance of a random variable with itself is simply its variance](https://en.wikipedia.org/wiki/Covariance#Covariance_with_itself), meaning\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y_{i1},y_{i2}) = \\text{Cov}(S_{i},S_{i}) = \\text{Var}(S_{i}) = \\sigma^{2}_{b}.\n",
    "$$\n",
    "\n",
    "All of which is to say that the variance associated with the subject-specific deflections *is* the covariance induced by the repeated measurements. This means that the repeated measures ANOVA is implying the following covariance structure (as shown for two repeated measurements from two subjects)\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    y_{11} \\\\\n",
    "    y_{12} \\\\\n",
    "    y_{21} \\\\\n",
    "    y_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "\\sim\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "    \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  & 0                               & 0                               \\\\\n",
    "    \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} & 0                               & 0                               \\\\\n",
    "    0                               & 0                               & \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  \\\\\n",
    "    0                               & 0                               & \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} \\\\\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "This type of structure is known as *compound symmetry*, because all variances and covariances are the *same* across the repeated measurements. This is not really a problem when we have two repeats, because there is only one covariance term. However, consider what happens if we were to have *three* repeated measurements per-subject\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    y_{11} \\\\\n",
    "    y_{12} \\\\\n",
    "    y_{13} \\\\\n",
    "    y_{21} \\\\\n",
    "    y_{22} \\\\\n",
    "    y_{23} \\\\\n",
    "\\end{bmatrix}\n",
    "\\sim\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "    \\mu + \\alpha_{3} \\\\\n",
    "    \\mu + \\alpha_{1} \\\\\n",
    "    \\mu + \\alpha_{2} \\\\\n",
    "    \\mu + \\alpha_{3} \\\\\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "    \\sigma^{2}_{b} + \\sigma^{2}_{w}  & \\sigma^{2}_{b}                  & \\sigma^{2}_{b}                  & 0                                & 0                               & 0                               \\\\\n",
    "    \\sigma^{2}_{b}                   & \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  & 0                                & 0                               & 0                               \\\\\n",
    "    \\sigma^{2}_{b}                   & \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} & 0                                & 0                               & 0                               \\\\\n",
    "    0                                & 0                               & 0                               & \\sigma^{2}_{b} + \\sigma^{2}_{w}  & \\sigma^{2}_{b}                  & \\sigma^{2}_{b}                  \\\\\n",
    "    0                                & 0                               & 0                               & \\sigma^{2}_{b}                   & \\sigma^{2}_{b} + \\sigma^{2}_{w} & \\sigma^{2}_{b}                  \\\\\n",
    "    0                                & 0                               & 0                               & \\sigma^{2}_{b}                   & \\sigma^{2}_{b}                  & \\sigma^{2}_{b} + \\sigma^{2}_{w} \\\\\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "This looks messy, but notice that the correlation between each of the repeated measurements is *exactly* the same value. Irrespective of what the experimental conditions are, the repeated measures ANOVA implies that they are correlated in exactly the same way. This is a *big* assumption. What if two conditions are positively correlated, but the others are negatively correlated[^negcorr-foot]? What is one of the experimental conditions works by making the correlation *weaker* compared to the other conditions? Any of these more complex situations are effectively *ignore* in the repeated measures ANOVA. Indeed, look back at the correlation structure we saw earlier in the lesson for the `selfesteem` data. This is clearly not compound symmetric. Remember that the importance of covariance relates to when we want to look at the *difference* between any of these conditions. If the covariance structure is *wrong* then the assumed standard error will be *wrong*. If we are using NHST, this means the calculated test statistic will not follow the assumed null distribution and $p$-value will either be *too liberal* or *too conservative*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdde13",
   "metadata": {},
   "source": [
    "### The Sphericity Condition\n",
    "Although we have suggested that the repeated measures ANOVA assumes a *compound symmetric* covariance structure, the reality is bit more nuanced. As indicated above, the assumption of compound symmetry is tied directly to the calculation of the standard errors, which then impact the denominator of the test statistic and inform the shape of the null distribution used to derive the $p$-values. If the actual covariance structure is *not* compound symmetric, then the formula used for the standard errors will be wrong, as will the formula used for the denominator of the test statistic. This will mean that the null distribution of the statistic is not what we think it is and the $p$-values will be inaccurate. This is a core limitation of the repeated measures ANOVA which is tied directly to the fact that the covariance structure is never explicitly *estimated*, it is only *assumed*.\n",
    "\n",
    "However, this assumption can actually be *weakened* slightly. Rather than assuming compound symmetry, a related condition known as *sphericity* is all that is required for the calculated $F$-statistic to follow the assumed null distribution. In brief, this condition is that the variance of all *pairwise differences* between the repeated measurements have equal variance. For instance, in the case of 3 repeated measures, this would be\n",
    "\n",
    "$$\n",
    "\\text{Var}(y_{i1} - y _{i2}) = \\text{Var}(y_{i1} - y _{i3}) = \\text{Var}(y_{i2} - y _{i3}) = \\sigma^{2}.\n",
    "$$\n",
    "\n",
    "We can *visualise* why this is known as *sphericity*. In the plots below, we transform the 3 repeated measures from each subject into the 3 subtractions from the formula above. We then plot these against each other in a 3D scatterplot. When sphericity is met (the *left* plot), this creates a *sphere* of points, because the variance is equal in all directions. When sphericity is *not* met (the *right* plot), this creates an *ellipsoid*, because the variance is larger for some of these differences compared to others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7a7a22",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "library(rgl)\n",
    "library(htmlwidgets)\n",
    "\n",
    "set.seed(123)\n",
    "n_subj <- 800\n",
    "\n",
    "# --- Covariances in contrast space ---\n",
    "Sigma_spherical <- diag(3)\n",
    "\n",
    "A <- matrix(c(1,   0,   0,\n",
    "              0.8, 0.5, 0,\n",
    "              0.4, 0.3, 0.2),\n",
    "            nrow = 3, byrow = TRUE)\n",
    "Sigma_elliptical <- A %*% t(A)\n",
    "\n",
    "C_sph <- mvrnorm(n = n_subj, mu = c(0, 0, 0), Sigma = Sigma_spherical)\n",
    "C_ell <- mvrnorm(n = n_subj, mu = c(0, 0, 0), Sigma = Sigma_elliptical)\n",
    "\n",
    "colnames(C_sph) <- c(\"C1\", \"C2\", \"C3\")\n",
    "colnames(C_ell) <- c(\"C1\", \"C2\", \"C3\")\n",
    "\n",
    "# --- Build the rgl scene in an offscreen device ---\n",
    "open3d(useNULL = TRUE)\n",
    "bg3d(\"white\")\n",
    "\n",
    "layout3d(matrix(1:2, nrow = 1))\n",
    "\n",
    "# Left: spherical\n",
    "next3d()\n",
    "plot3d(\n",
    "  C_sph[, 1], C_sph[, 2], C_sph[, 3],\n",
    "  xlab = \"yi1 - yi2\",\n",
    "  ylab = \"yi1 - yi3\",\n",
    "  zlab = \"yi2 - yi3\",\n",
    "  col  = \"dodgerblue\",\n",
    "  size = 2,\n",
    "  alpha = 0.5,\n",
    "  box = TRUE,\n",
    "  type = \"s\"\n",
    ")\n",
    "lines3d(c(-4, 4), c(0, 0), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(-4, 4), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(0, 0), c(-4, 4), lwd = 3)\n",
    "\n",
    "aspect3d(\"iso\") \n",
    "\n",
    "# Right: elliptical\n",
    "next3d()\n",
    "plot3d(\n",
    "  C_ell[, 1], C_ell[, 2], C_ell[, 3],\n",
    "  xlab = \"yi1 - yi2\",\n",
    "  ylab = \"yi1 - yi3\",\n",
    "  zlab = \"yi2 - yi3\",\n",
    "  col  = \"firebrick\",\n",
    "  size = 2,\n",
    "  alpha = 0.5,\n",
    "  box = TRUE,\n",
    "  type = \"s\"\n",
    ")\n",
    "lines3d(c(-4, 4), c(0, 0), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(-4, 4), c(0, 0), lwd = 3)\n",
    "lines3d(c(0, 0), c(0, 0), c(-4, 4), lwd = 3)\n",
    "\n",
    "aspect3d(\"iso\") \n",
    "\n",
    "# Turn scene into widget\n",
    "w <- rglwidget()\n",
    "\n",
    "# Save as standalone HTML\n",
    "saveWidget(w, \"_static/sphericity_3d.html\", selfcontained = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0afd9d6",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">\n",
    "  <iframe\n",
    "    src=\"_static/sphericity_3d.html\"\n",
    "    class=\"sphericity-frame\"\n",
    "    width=\"800\"\n",
    "    height=\"600\"\n",
    "    style=\"border:none;\"\n",
    "  >\n",
    "  </iframe>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96675ccf",
   "metadata": {},
   "source": [
    "Now, this condition is really something of a *mathematical trick*. As pointed out by [Davis (2010)](), many authors have suggested that any realistic covariance matrix you may come across in practice that meets the criteria of *sphericity* will also be *compound symmetric*. Indeed, [Wallenstein (1982)]() went as far as to indicate that, for all practical purposes, the assumption of the repeated measures ANOVA *is* compound symmetry. However, the utility of expressing this assumption in terms of sphericity is that it allows for a *correction* to be applied. Rather than defining sphericity as above, it can be expressed in a mathematically equivalent way using a value known as $\\epsilon$. When sphericity is met $\\epsilon = 1$, and when it is not met $\\epsilon \\neq 1$. This is useful because $\\epsilon$ can be used to adjust the degrees of freedom of the null $F$-distribution to make it approximately correct. Thus, a null $F$-distribution of $F(\\epsilon \\times df_{1}, \\epsilon \\times df_{2})$ can be used, so long as we know $\\epsilon$. Remember earlier we mentioned that degrees of freedom breakdown under dependence. In the spherical or compound symmetric cases, they are still integer-valued and easily calculated. As soon as the true structure diverges from this, we get into a world of fractional values with no way to calculate them. The sphericity corrections are one way of *approximating* a more accurate null based on fractional degrees of freedom using the value $\\epsilon$. Several different methods of estimating $\\epsilon$ from the sample covariance matrix have been proposed by authors such as [Greenhouse & Geisser (1959)](https://psycnet.apa.org/record/1960-03639-001) and [Huynh & Feldt (1976)](https://psycnet.apa.org/record/1979-10174-001). These methods can therefore be used to provide an approximate correction and a more accurate calculation of the $p$-value in cases of non-sphericity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1eb7ed",
   "metadata": {},
   "source": [
    "## Repeated Measures ANOVA with Corrections in `R`\n",
    "If you have used statistical software such as SPSS in the past, the corrections for sphericity should be familiar. Within `R`, these are available through the `ezANOVA()` function which, as we will see, is generally the most straight-forward way of generating a repeated measures ANOVA with the correct error partition. In the code below, we show fitting a one-way repeated measures ANOVA to the `selfesteem` data. We first use `aov()` to show how this can be achieved in base `R` with partitioned errors. First we need to convert `selfesteem` into long format, with `id` coded as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36171ed",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "library('datarium')\n",
    "data('selfesteem')\n",
    "\n",
    "t <- 3\n",
    "n <- dim(selfesteem)[1]\n",
    "\n",
    "# reshape wide -> long\n",
    "selfesteem.long <- melt(selfesteem, id.vars='id',variable.name=\"time\", value.name=\"score\")\n",
    "\n",
    "selfesteem.long           <- selfesteem.long[order(selfesteem.long$id),] # order by ID\n",
    "rownames(selfesteem.long) <- seq(1,n*t)                                  # fix row names\n",
    "selfesteem.long$id        <- as.factor(selfesteem.long$id)               # make id a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e15c8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id time    score\n",
      "1  1   t1 4.005027\n",
      "2  1   t2 5.182286\n",
      "3  1   t3 7.107831\n",
      "4  2   t1 2.558124\n",
      "5  2   t2 6.912915\n",
      "6  2   t3 6.308434\n"
     ]
    }
   ],
   "source": [
    "print(head(selfesteem.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7208b3",
   "metadata": {},
   "source": [
    "Now we can fit the partitioned error model with `aov()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdee81e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Error: id\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)\n",
       "Residuals  9   4.57  0.5078               \n",
       "\n",
       "Error: Within\n",
       "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "time       2 102.46   51.23   55.47 2.01e-08 ***\n",
       "Residuals 18  16.62    0.92                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneway.rm.aov <- aov(score ~ time + Error(id), data=selfesteem.long)\n",
    "summary(oneway.rm.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8648e",
   "metadata": {},
   "source": [
    "So, we can see that the error has been correctly separated and we have a suitable test of `time`. However, this is only valid so far as the assumption of sphericity is met. To generate this test corrected for any violations of sphericity, the easiest approach is to use `ezANOVA()`. The code for this is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7caac0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ANOVA\n",
      "  Effect DFn DFd        F            p p<.05       ges\n",
      "2   time   2  18 55.46903 2.013829e-08     * 0.8285954\n",
      "\n",
      "$`Mauchly's Test for Sphericity`\n",
      "  Effect         W          p p<.05\n",
      "2   time 0.5508534 0.09207551      \n",
      "\n",
      "$`Sphericity Corrections`\n",
      "  Effect       GGe        p[GG] p[GG]<.05       HFe        p[HF] p[HF]<.05\n",
      "2   time 0.6900613 2.161433e-06         * 0.7743711 6.032582e-07         *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library('ez')\n",
    "\n",
    "oneway.rm.ez <- ezANOVA(data=selfesteem.long, dv=score, wid=id, within=time)\n",
    "print(oneway.rm.ez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af23a9ca",
   "metadata": {},
   "source": [
    "The returned object has 3 fields, one giving the original ANOVA tests (which match the results from `aov()`), one providing an inferential test of sphericity and one providing the sphericity corrections. Although Mauchly's test may initially seem useful, we need to remember the limitations of using inferential tests of assumptions. Furthermore, Mauchly's test is known to perform poorly in both small samples, large samples, non-normal data and data with outliers, leading [Davis (2010, pg.110)]() to conclude that \"...(Mauchly's test) is not of great practical use\". In terms of the sphericity corrections, the column `GGe` means `Greenhouse-Geiser epsilon` and `HFe` means `Huynh-Feldt epsilon`. These are the estimates of $\\epsilon$ using the methods mentioned earlier. As these are both $\\hat{\\epsilon} \\neq 1$, sphericity has been violated to some degree. The values `p[GG]` and `p[HF]` give the $p$-values for the omnibus test of `time`, after correcting the degrees of freedom using the two different estimates for $\\epsilon$. In both cases the effect of `time` remains significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee0e28",
   "metadata": {},
   "source": [
    "## Difficulties in the Use of the Repeated Measures ANOVA\n",
    "At this point, we do have a working framework for analysing repeated measurements within a traditional ANOVA framework. However, it is worth taking a step back and thinking about what was needed to reach this point. From a purely theoretical perspective, the repeated measures ANOVA requires partitioned errors within a framework that cannot accommodate more than one error term. In order to make this possible, an ANOVA table is constructed where the mean squares for some terms are treated as *denominators* rather than *numerators*. However, these are not treated as error within the model, only as part of the manual construction of tests after the model has been fit. Furthermore, in order to allow for repeated measurements within the classical ANOVA machinery, a very simple covariance structure must be assumed. For all but the most simple of situations, this structure is unlikely to hold in reality. However, rather than abandoning the framework for its lack of flexibility, the traditional approach is to provide a *correction* that allows an approximation of the null $F$-distribution if the sample covariance structure does not match the assumptions. This is effectively a sticking plaster over a procedure that is not flexible enough for general use.\n",
    "\n",
    "Beyond the theoretical limitations, we have some practical ones in terms of implementation. We can stick with `lm()` and get all the assumptions plots, follow-up tests and visualisations we are used to. However, the term $S_{i}$ will not be treated correctly as *error*. For some models this will not matter, whereas for more complex models (that we will cover in the final part of this lesson) this will make a big difference. The more correct way to do this is by using `aov()`, but not only will this get more complicated in terms of specifying error terms, we also do not get access to any plotting facilities or visualisations, despite this function wrapping `lm()`. The only way to do this would be to specify sub-models that correspond to each error term and examine them separately, but this would be error-prone and generally a bit of a pain. In addition, neither of these methods provide corrections for violations of sphericity. If we want an easier time in terms of correctly specifying error terms and correcting for violations of sphericity, we can use `ezANOVA()`. However, this only gives us an ANOVA table with no access to the underlying linear model. So, from a practical perspective, there is no great solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e8c28",
   "metadata": {},
   "source": [
    "`````{topic} What do you now know?\n",
    "In this section, we have explored the one-way repeated measures ANOVA framework. After reading this section, you should have a good sense of :\n",
    "\n",
    "- Why the subtraction method used for the paired $t$-test only works in a limited number of cases.\n",
    "- Why this limitation motivates the use of the full *partitioned error* model that underlies the logic of the paired $t$-test.\n",
    "- How splitting $\\epsilon_{ij}$ creates a model with *two* random error terms that we refer to as $S_{i}$ and $\\eta_{ij}$.\n",
    "- Why this partitioned error model cannot be used with `lm()` and why this motivates the use of `aov()` with the `Error()` syntax.\n",
    "- How the basic partitioned error model implies a *compound symmetric* covariance structure.\n",
    "- How the assumption of compound symmetry can be weakened by assuming *sphericity*, allowing the use of an *approximate correction* when sphericity does not hold.\n",
    "- How these sphericity corrections can be generated in `R` using the `ezANOVA()` function.\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6312",
   "metadata": {},
   "source": [
    "[^submodel-foot]: An alternative perspective here is that each error term represents a different *sub-model*. So, we can think of specifying *multiple* models, some of which require us to *average-over* certain factors. For instance, if we were to average-over the repeated measurements and then fit a model on the resultant outcome variable, this model would automatically have $\\sigma^{2}_{b}$ as its error term. This does make the whole procedure feel a little bit less of a hack, however, it is very impractical to do this, especially when the number of factors and interactions gets larger. You can read more about this approach in [McFarquhar (2019)](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2019.00352/full).\n",
    "\n",
    "[^noterr-foot]: Note that this is *not* the errors from the linear model, even though the Greek letter is the same.\n",
    "\n",
    "[^negcorr-foot]: In fact, it is an under-appreciated assumption in the repeated measures ANOVA that the covariance *is* positive so that the covariance term *subtracts*. If it were *negative* then the covariance should actually *add* and the variance of the difference should *increase*, but this is not what this method assumes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
