{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde1ccab-2d89-4ccf-aca6-dbea239a0625",
   "metadata": {},
   "source": [
    "# Higher-order Repeated Measures ANOVA\n",
    "In the previous part of this lesson, we examined the most simple case of the repeated measures ANOVA. Despite the simplicity of the design, we saw how this analysis had several complications around the correct partition of the error, as well as the assumptions made about the covariance structure. These alone were enough to suggest that the repeated measures ANOVA framework was problematic to apply in practice. Yet, there are even more complex situations where this framework can be applied. In this final part of the lesson, we will see how the repeated measures ANOVA is used in situations where there are additional *between-subjects* factors, as well as multiple *within-subject* factors. This is not to condone the use of the repeated measures ANOVA in these situations, rather it is to help you understand (a) how the repeated measures ANOVA generalises and (b) why an approach method such as mixed-effects will provide a better alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0025798-daa1-475d-b3f3-ed1ac8da1a0c",
   "metadata": {},
   "source": [
    "## Adding Between-subjects Factors\n",
    "The first additional complexity we may come across is when we have a *between-subjects* factor alongside the repeated measurements. For example, the `datarium` package contains the dataset `anxiety`. Here, repeated measurements of anxiety have been taken at 3 different time points. The 45 subjects are split between 3 different exercise regimes and the experimental question concerns the relationship between exercise and time on anxiety. So, `time` is the repeated measurement and `group` is the between-subjects factor. This is effectively a $3 \\times 3$ ANOVA, as illustrated in the table below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97617268",
   "metadata": {},
   "source": [
    "|             | Group: Low | Group: Moderate | Group: High | \n",
    "|-------------|------------|-----------------|-------------|\n",
    "| **Time: 1** | $\\mu_{11}$ | $\\mu_{12}$      | $\\mu_{13}$  |\n",
    "| **Time: 2** | $\\mu_{21}$ | $\\mu_{22}$      | $\\mu_{23}$  |\n",
    "| **Time: 3** | $\\mu_{31}$ | $\\mu_{32}$      | $\\mu_{33}$  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318dca3",
   "metadata": {},
   "source": [
    "As such, our interest falls on the main effect of `group`, main effect of `time` and the `group:time` interaction. Based on what we have covered do far, we can easily apply the following two-way ANOVA model with partitioned errors\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ijk}    &=    \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + S_{i} + \\eta_{ijk} \\\\\n",
    "    S_{i}      &\\sim \\mathcal{N}(0,\\sigma^{2}_{b}) \\\\ \n",
    "    \\eta_{ijk} &\\sim \\mathcal{N}(0,\\sigma^{2}_{w})\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Here we have added a term for the *between-subject* effect (denoted $\\beta_{k}$), as well as the *between* $\\times$ *within* interaction (denoted $(\\alpha\\beta)_{jk}$). So now $i$ indexes the subject ($i = 1,\\dots,45$), $j$ indexes the repeated measurements ($j = 1,\\dots,3$) and $k$ indexes the groups ($k = 1,\\dots,3$).\n",
    "\n",
    "We can see this dataset below in its original form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b17c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id group   t1   t2   t3\n",
      "1  1  grp1 14.1 14.4 14.1\n",
      "2  2  grp1 14.5 14.6 14.3\n",
      "3  3  grp1 15.7 15.2 14.9\n",
      "4  4  grp1 16.0 15.5 15.3\n",
      "5  5  grp1 16.5 15.8 15.7\n",
      "6  6  grp1 16.9 16.5 16.2\n"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "data('anxiety')\n",
    "print(head(anxiety))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3008832",
   "metadata": {},
   "source": [
    "and then reworked into long-format for univariate modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d85e554",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "library('reshape2')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 3\n",
    "n <- 45\n",
    "\n",
    "# reshape wide -> long\n",
    "anxiety.long <- melt(anxiety,                 # wide data frame\n",
    "                     id.vars=c('id','group'), # what stays fixed?\n",
    "                     variable.name='time',    # name for the new predictor\n",
    "                     value.name='anxiety')    # name for the new outcome\n",
    "\n",
    "anxiety.long           <- anxiety.long [order(anxiety.long$id),] # order by ID\n",
    "rownames(anxiety.long) <- seq(1,n*t)                             # fix row names\n",
    "anxiety.long$id        <- as.factor(anxiety.long$id)             # id as factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97baa3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id group time anxiety\n",
      "1  1  grp1   t1    14.1\n",
      "2  1  grp1   t2    14.4\n",
      "3  1  grp1   t3    14.1\n",
      "4  2  grp1   t1    14.5\n",
      "5  2  grp1   t2    14.6\n",
      "6  2  grp1   t3    14.3\n"
     ]
    }
   ],
   "source": [
    "print(head(anxiety.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476106c6",
   "metadata": {},
   "source": [
    "So far, nothing has changed from what we have seen previously. However, we now have to think more carefully about our possible error terms and which is most sensible to use as the denominator for each test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d88cc3",
   "metadata": {},
   "source": [
    "### The Between-subjects Error Term\n",
    "Recall from the previous part of this lesson that a repeated measures ANOVA is effectively a linear model with *partitioned errors*. We stated earlier that by splitting the errors into $\\epsilon_{ijk} = S_{i} + \\eta_{ijk}$ we are effectively specifying a model with *two* variance terms. So, the variance function becomes\n",
    "\n",
    "$$\n",
    "\\text{Var}(y_{ijk}) = \\sigma^{2} = \\sigma^{2}_{b} + \\sigma^{2}_{w}.\n",
    "$$\n",
    "\n",
    "The point of doing this was two-fold. Firstly, it *removes* the correlation from the model errors and thus the model now meets the $i.i.d.$ assumptions. Secondly, it removes error variance associated with the differences *between* the subjects, allowing any inferential tests to only use the variance associated with measurements *within* a subject. This is obviously the most suitable error to use for inference on the repeated measures because it captures the random fluctuations in measurements *within* an individual. \n",
    "\n",
    "Conceptually, the repeated measurements from subject $i$ can be considered multiple draws from a distribution with a variance $\\sigma^{2}_{w}$ and a mean $E(y_{ijk}) = \\mu_{jk} + S_{i}$. The distribution of each subject is therefore conceptualised as having the *same* variance but a *different* mean, unique to each subject. These means are then further conceptualised as random draws from a larger distribution of *different subjects* with a variance $\\sigma^{2}_{b}$. Thus, the variation *between* subjects is represented by this larger distribution, whereas as the variation *within* each subject is represented by the smaller individual distributions. This is illustrated in {numref}`mixed-sampling-fig` for two separate group-level distributions.\n",
    "\n",
    "```{figure} ./images/mixed-measures-sampling.png\n",
    "---\n",
    "width: 600px\n",
    "name: mixed-sampling-fig\n",
    "---\n",
    "An illustration of the sampling model that underlies a repeated measures design with 3 measurements per-subject, as taken from 2 independent groups. Two example subjects are shown for each group. The most important element here is seeing the different variance sources ($\\sigma^{2}_{b}$ and $\\sigma^{2}_{w}$) and how these correspond to inference for either the between-subjects or within-subject effects.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1360172",
   "metadata": {},
   "source": [
    "Importantly, we need to think about which measure of *uncertainty* is most suitable for inference about the different elements of this sampling model. For the repeated measurements, we can see that these all come from distributions with variance $\\sigma^{2}_{w}$. Thus, our uncertainty around our estimates of these effects is tied to how much we expect them to vary for each subject. This means that $\\sigma^{2}_{w}$ is the most suitable error term. Now, in terms of looking at the *group* effects, we can see that these come from distributions with variance $\\sigma^{2}_{b}$. These are distributions of the *subject means*, capturing how much the subjects differ from each other. This is parameterised in terms of the subject-specific errors given by $S_{i}$, which capture the magnitude of the discrepancy between each subject and the group average. Thus, the variance of the subject means is given by $\\sigma^{2}_{b}$. Any inference about subjects *as a whole* needs to take the variability of the subjects into account. Thus, for inference about the group effects, $\\sigma^{2}_{b}$ is the most suitable error term. So, taking this all together, we now have a model where *different effects* require *different error terms*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7aeb3",
   "metadata": {},
   "source": [
    "### Specifying Between-subjects Error in `R`\n",
    "As we established earlier, we can use `aov()` to express how we want the arithmetic of the ANOVA table to be organised. Again, this is a serious limitation of the repeated measures ANOVA because this requires some degree of manual intervention to state which terms we want treated as *error* and which we want treated as effects of interest. This can get complex very quickly and it is up to the analyst to indicate which terms are which[^ems-foot]. For this example, the specification is fairly simple because we just denote the subject term as error and `aov()` will automatically arrange the tests for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f31391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Error: id\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)  \n",
       "group      2  61.99  30.996   4.352 0.0192 *\n",
       "Residuals 42 299.15   7.123                 \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: Within\n",
       "           Df Sum Sq Mean Sq F value Pr(>F)    \n",
       "time        2  66.58   33.29   394.9 <2e-16 ***\n",
       "group:time  4  37.15    9.29   110.2 <2e-16 ***\n",
       "Residuals  84   7.08    0.08                   \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety.aov <- aov(anxiety ~ group*time + Error(id), data=anxiety.long)\n",
    "summary(anxiety.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460aa57",
   "metadata": {},
   "source": [
    "As we can see, the effect of `group` is now associated with `Error: id`, which represents the estimate of $\\sigma^{2}_{b}$. The effect of `time` remains associated with `Error: Within`, which represents the estimate of $\\sigma^{2}_{w}$. Notice as well that the interaction term `group:time` also uses $\\sigma^{2}_{w}$. This may seem puzzling, given that this contains a comparison *across* the groups. However, remember that when calculating the variance of the difference between two random variables, the covariance is subtracted. Because $\\sigma^{2}_{b}$ also acts as the covariance, it cancels-out when comparing the repeated measurements and thus cancels-out when calculating the interaction.\n",
    "\n",
    "We can also calculate the above using `ezANOVA()`, without having to explicitly specify the error terms, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0a2aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ANOVA\n",
      "      Effect DFn DFd          F            p p<.05       ges\n",
      "2      group   2  42   4.351811 1.916093e-02     * 0.1683558\n",
      "3       time   2  84 394.909490 1.905584e-43     * 0.1785886\n",
      "4 group:time   4  84 110.187610 1.384653e-32     * 0.1081997\n",
      "\n",
      "$`Mauchly's Test for Sphericity`\n",
      "      Effect         W          p p<.05\n",
      "3       time 0.8836439 0.07919252      \n",
      "4 group:time 0.8836439 0.07919252      \n",
      "\n",
      "$`Sphericity Corrections`\n",
      "      Effect       GGe        p[GG] p[GG]<.05       HFe        p[HF] p[HF]<.05\n",
      "3       time 0.8957715 3.484600e-39         * 0.9330916 1.037156e-40         *\n",
      "4 group:time 0.8957715 1.966104e-29         * 0.9330916 1.461019e-30         *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library('ez')\n",
    "anxiety.ez <- ezANOVA(data=anxiety.long, dv=anxiety, wid=id, within=time, between=group)\n",
    "print(anxiety.ez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40acbe7f",
   "metadata": {},
   "source": [
    "\n",
    "Although both the above approaches are reasonably simple to specify, it is worth considering the implications of getting this *wrong*. To see this, let us specify this model using `lm()` and then look at the traditional ANOVA table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a74e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analysis of Variance Table\n",
       "\n",
       "Response: anxiety\n",
       "           Df  Sum Sq Mean Sq F value    Pr(>F)    \n",
       "group       2  61.992  30.996 367.701 < 2.2e-16 ***\n",
       "time        2  66.579  33.289 394.909 < 2.2e-16 ***\n",
       "id         42 299.146   7.123  84.494 < 2.2e-16 ***\n",
       "group:time  4  37.154   9.288 110.188 < 2.2e-16 ***\n",
       "Residuals  84   7.081   0.084                      \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety.wrong.lm <- lm(anxiety ~ group*time + id, data=anxiety.long)\n",
    "anova(anxiety.wrong.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb69965",
   "metadata": {},
   "source": [
    "Without any further information, both `lm()` and `anova()` treat every term in the formula as part of the *mean function* and thus assumes we are interested in each term for the purpose of inference. As we saw earlier, we can just ignore the tests on `id`. Its inclusion has partitioned $\\sigma^{2}_{b}$ out from $\\sigma^{2}$, meaning that the `Residuals` term in the ANOVA table only represents $\\sigma^{2}_{w}$. This is fine for both the test on `time` and `group:time`, which are no different to the tests produced by `aov()`. However, the crucial difference comes from the test of `group`. Notice that the *correct* test has $F = 4.35$, whereas the test above has $F = 367.70$. This is approximately 85 times *larger*! Such a huge discrepancy comes from the fact that the *incorrect* test is using $\\sigma^{2}_{w}$ as the denominator, which is *much smaller* than $\\sigma^{2}_{b}$. This makes the test *far too liberal*. \n",
    "\n",
    "Although both versions of this test are still \"significant\", it is not hard to imagine a situation where you could get a significant effect of `group` simply by specifying the wrong error. Getting this wrong could be disastrous because we might falsely claim that the between-subjects factor has an effect when it does not. Considering that these factors may correspond to something like patients vs controls, concluding a false difference could have serious implications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98adc933",
   "metadata": {},
   "source": [
    "We could also get this \"wrong\" by not partitioning the error at all and instead working with a *pooled* error of $\\sigma^{2}_{b} + \\sigma^{2}_{w}$ for every test. An example of this is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb79a136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analysis of Variance Table\n",
       "\n",
       "Response: anxiety\n",
       "            Df  Sum Sq Mean Sq F value    Pr(>F)    \n",
       "group        2  61.992  30.996 12.7536 9.038e-06 ***\n",
       "time         2  66.579  33.289 13.6973 4.143e-06 ***\n",
       "group:time   4  37.154   9.288  3.8218  0.005753 ** \n",
       "Residuals  126 306.227   2.430                      \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety.pooled.lm <- lm(anxiety ~ group*time, data=anxiety.long)\n",
    "anova(anxiety.pooled.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6899ef6",
   "metadata": {},
   "source": [
    "Notice that, by not acknowledging or accommodating the correlation or different variance sources, many of the tests have got *substantially* weaker. So we have `time`: $F = 394.9 \\rightarrow 13.70$ and `time:group`: $F = 110.2 \\rightarrow 3.82$. So, by not doing this at all, we kill the power advantage of having a repeated measures experiment in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee845f",
   "metadata": {},
   "source": [
    "## Adding More Within-subject Factors\n",
    "If all of the above was not bad enough, things get even trickier when we add *more* within-subject factors. We will not dwell on this too much because, as should be clear by now, we do not condone using the repeated measures ANOVA at all. However, this will provide the final clearest demonstration of *why* we want a much better framework for these type of data. The complexity demonstrated below is there to help you understand why you really do *not* want to do this. This is one of clearest cases where the automation provided by software such as SPSS actively *hides* so much of the complexity that researchers do not think twice about designing studies that require these methods.\n",
    "\n",
    "As our example, the `datarium` package contains a dataset called `weightloss` that represents a fully within-subject $2 \\times 2 \\times 3$ design. There were 12 subjects whose weight was measured under combination of `diet` (`yes` or `no`) and `exercises` (`yes` or `no`). For each combination of `diet` and `exercises`, the trial lasted 9 weeks, with measurements taken at 3 time-points. As such, every subject has 12 repeated measurements, representing every combination of `diet` and `exercises` across 3 values of `time`. The original dataset is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d415ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;246m# A tibble: 6 × 6\u001b[39m\n",
      "  id    diet  exercises    t1    t2    t3\n",
      "  \u001b[3m\u001b[38;5;246m<fct>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<fct>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<fct>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[38;5;250m1\u001b[39m 1     no    no         10.4 13.2   11.6\n",
      "\u001b[38;5;250m2\u001b[39m 2     no    no         11.6 10.7   13.2\n",
      "\u001b[38;5;250m3\u001b[39m 3     no    no         11.4 11.1   11.4\n",
      "\u001b[38;5;250m4\u001b[39m 4     no    no         11.1  9.5   11.1\n",
      "\u001b[38;5;250m5\u001b[39m 5     no    no          9.5  9.73  12.3\n",
      "\u001b[38;5;250m6\u001b[39m 6     no    no          9.5 12.7   10.4\n"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "data('weightloss')\n",
    "print(head(weightloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d913e1",
   "metadata": {},
   "source": [
    "and again after conversion to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c7178a9",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id diet exercises time weight\n",
      "1  1   no        no   t1  10.43\n",
      "2  1   no       yes   t1  11.12\n",
      "3  1  yes        no   t1  10.20\n",
      "4  1  yes       yes   t1  10.43\n",
      "5  1   no        no   t2  13.21\n",
      "6  1   no       yes   t2  12.51\n"
     ]
    }
   ],
   "source": [
    "library('reshape2')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 12 # 2 * 2 * 3\n",
    "n <- 12\n",
    "\n",
    "# reshape wide -> long\n",
    "weightloss.long <- melt(weightloss,                         # wide data frame\n",
    "                        id.vars=c('id','diet','exercises'), # what stays fixed?\n",
    "                        variable.name=\"time\",               # name for the new predictor\n",
    "                        value.name=\"weight\")                # name for the new outcome\n",
    "\n",
    "weightloss.long           <- weightloss.long[order(weightloss.long$id),] # order by ID\n",
    "rownames(weightloss.long) <- seq(1,n*t)                                  # fix row names\n",
    "weightloss.long$id        <- as.factor(weightloss.long$id)               # id as factor\n",
    "\n",
    "print(head(weightloss.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c39d9c",
   "metadata": {},
   "source": [
    "### Multiple Within-subject Error Terms\n",
    "In order to facilitate understanding what we have to do when there are multiple within-subject factors, let us start by specifying the same partitioned error model we used above with `aov()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859453dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Error: id\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)\n",
       "Residuals 11   27.1   2.463               \n",
       "\n",
       "Error: Within\n",
       "                     Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "diet                  1   5.11    5.11   4.069   0.0459 *  \n",
       "exercises             1  71.16   71.16  56.647 1.03e-11 ***\n",
       "time                  2 211.39  105.69  84.134  < 2e-16 ***\n",
       "diet:exercises        1  33.40   33.40  26.586 9.96e-07 ***\n",
       "diet:time             2   2.42    1.21   0.963   0.3846    \n",
       "exercises:time        2  67.43   33.72  26.839 2.25e-10 ***\n",
       "diet:exercises:time   2  30.77   15.39  12.249 1.43e-05 ***\n",
       "Residuals           121 152.01    1.26                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightloss.aov <- aov(weight ~ diet*exercises*time + Error(id), data=weightloss.long)\n",
    "summary(weightloss.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd8f",
   "metadata": {},
   "source": [
    "In this scenario, `diet`, `exercises` and `time` are all using the *same* within-subject error term. But is this appropriate? If we focus on `diet`, $\\sigma^{2}_{w}$ will contain the variation associated with the different diet conditions within each subject, which is what we want. However, it will *also* contain variation associated with the different levels of `exercises` and the different levels of `time`. If our focus is `diet` alone, it seems inappropriate to include the uncertainty around `exercises` and `time`. Similarly, if we are interested in the `diet:time` interaction, $\\sigma^{2}_{w}$ will contain variation associated with both `diet` and `time`, as we want, but it will *also* include variation associated with `exercises`. This additional variation is of no relevance if we are only interested in the `diet:time` effect. What this means is that whenever there are *multiple* within-subject factors, we can *further partition* $\\sigma^{2}_{w}$ into more error terms that are more suitable for each of these effects. \n",
    "\n",
    "Going back to `diet` as an example, the errors we want are only those associated with the different levels of `diet` for each subject. This means we want to *average-over* all other repeated measurements associated with both `time` and `exercises`. This can be achieved by specifying an *interaction* between the subject effects and the levels of `diet`. This will create subject-specific errors (just like $S_{i}$) for each level of `diet`. The variance from these errors will then reflect within-subject variation associated with `diet`, ignoring both `time` and `exercises`. If we continue this logic for all other terms, we get an error structure where we can partition $\\sigma^{2}_{w}$ into further terms by taking all possible interactions between `subject` and the within-subject factors. Using `aov()`, this becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11cedec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Error: id\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)\n",
       "Residuals 11   27.1   2.463               \n",
       "\n",
       "Error: id:diet\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)  \n",
       "diet       1  5.111   5.111   6.021  0.032 *\n",
       "Residuals 11  9.337   0.849                 \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:exercises\n",
       "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "exercises  1  71.16   71.16   58.93 9.65e-06 ***\n",
       "Residuals 11  13.28    1.21                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:time\n",
       "          Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "time       2 211.39  105.69   110.9 3.22e-12 ***\n",
       "Residuals 22  20.96    0.95                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:exercises:time\n",
       "               Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "exercises:time  2  67.43   33.72   20.83 8.41e-06 ***\n",
       "Residuals      22  35.62    1.62                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:diet:exercises\n",
       "               Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "diet:exercises  1  33.40   33.40   75.36 2.98e-06 ***\n",
       "Residuals      11   4.88    0.44                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Error: id:diet:time\n",
       "          Df Sum Sq Mean Sq F value Pr(>F)\n",
       "diet:time  2   2.42   1.210   0.603  0.556\n",
       "Residuals 22  44.17   2.008               \n",
       "\n",
       "Error: id:diet:exercises:time\n",
       "                    Df Sum Sq Mean Sq F value   Pr(>F)    \n",
       "diet:exercises:time  2  30.77   15.39   14.25 0.000107 ***\n",
       "Residuals           22  23.76    1.08                     \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightloss.aov <- aov(weight ~ diet*exercises*time + \n",
    "                               Error(id                + \n",
    "                                     id:diet           +\n",
    "                                     id:exercises      +\n",
    "                                     id:time           +\n",
    "                                     id:exercises:time +\n",
    "                                     id:exercises:diet +\n",
    "                                     id:time:diet      +\n",
    "                                     id:time:exercises:diet), \n",
    "                        data=weightloss.long)\n",
    "summary(weightloss.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3547d3",
   "metadata": {},
   "source": [
    "which is both hideous to specify, but also to interpret given that we now have *8* ANOVA tables to deal with! It would also be very easy to get this wrong by missing a term somewhere. Luckily, there is an easier way to write this using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f0e292",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "aov(formula = weight ~ diet * exercises * time + Error(id/(diet * \n",
       "    exercises * time)), data = weightloss.long)\n",
       "\n",
       "Grand Mean: 12.68132\n",
       "\n",
       "Stratum 1: id\n",
       "\n",
       "Terms:\n",
       "                Residuals\n",
       "Sum of Squares   27.09682\n",
       "Deg. of Freedom        11\n",
       "\n",
       "Residual standard error: 1.569506\n",
       "\n",
       "Stratum 2: id:diet\n",
       "\n",
       "Terms:\n",
       "                    diet Residuals\n",
       "Sum of Squares  5.111367  9.337474\n",
       "Deg. of Freedom        1        11\n",
       "\n",
       "Residual standard error: 0.9213367\n",
       "5 out of 6 effects not estimable\n",
       "Estimated effects are balanced\n",
       "\n",
       "Stratum 3: id:exercises\n",
       "\n",
       "Terms:\n",
       "                exercises Residuals\n",
       "Sum of Squares   71.16328  13.28392\n",
       "Deg. of Freedom         1        11\n",
       "\n",
       "Residual standard error: 1.098922\n",
       "5 out of 6 effects not estimable\n",
       "Estimated effects are balanced\n",
       "\n",
       "Stratum 4: id:time\n",
       "\n",
       "Terms:\n",
       "                     time Residuals\n",
       "Sum of Squares  211.38837  20.95943\n",
       "Deg. of Freedom         2        22\n",
       "\n",
       "Residual standard error: 0.9760642\n",
       "6 out of 8 effects not estimable\n",
       "Estimated effects may be unbalanced\n",
       "\n",
       "Stratum 5: id:diet:exercises\n",
       "\n",
       "Terms:\n",
       "                diet:exercises Residuals\n",
       "Sum of Squares        33.39877   4.87534\n",
       "Deg. of Freedom              1        11\n",
       "\n",
       "Residual standard error: 0.6657423\n",
       "2 out of 3 effects not estimable\n",
       "Estimated effects are balanced\n",
       "\n",
       "Stratum 6: id:diet:time\n",
       "\n",
       "Terms:\n",
       "                diet:time Residuals\n",
       "Sum of Squares    2.41961  44.17083\n",
       "Deg. of Freedom         2        22\n",
       "\n",
       "Residual standard error: 1.416956\n",
       "2 out of 4 effects not estimable\n",
       "Estimated effects may be unbalanced\n",
       "\n",
       "Stratum 7: id:exercises:time\n",
       "\n",
       "Terms:\n",
       "                exercises:time Residuals\n",
       "Sum of Squares        67.43327  35.61749\n",
       "Deg. of Freedom              2        22\n",
       "\n",
       "Residual standard error: 1.27239\n",
       "2 out of 4 effects not estimable\n",
       "Estimated effects may be unbalanced\n",
       "\n",
       "Stratum 8: id:diet:exercises:time\n",
       "\n",
       "Terms:\n",
       "                diet:exercises:time Residuals\n",
       "Sum of Squares             30.77454  23.76233\n",
       "Deg. of Freedom                   2        22\n",
       "\n",
       "Residual standard error: 1.039281\n",
       "Estimated effects may be unbalanced"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aov(weight ~ diet*exercises*time + Error(id/(diet*exercises*time)), data=weightloss.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4033b",
   "metadata": {},
   "source": [
    "where the syntax `id/(diet*exercises*time)` can be read as a request to include the main effect of the term on the *left* of `/` alongside all possible interactions with the terms on the *right* of `/`[^nesting-foot]. Importantly, only the *within-subject* factors appear in the `Error()` syntax because our aim is to further partition $\\sigma^{2}_{w}$ and *not* $\\sigma^{2}_{b}$.\n",
    "\n",
    "In general, it is not recommended to use `aov()` like this. Not only is it *difficult* and prone to *mistakes*, but the output becomes unwieldly. A better approach, if you *must* use a repeated measures ANOVA, is the `ezANOVA()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af9955ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ANOVA\n",
      "               Effect DFn DFd          F            p p<.05        ges\n",
      "2                diet   1  11   6.021440 3.202562e-02     * 0.02774675\n",
      "3           exercises   1  11  58.928078 9.650954e-06     * 0.28434954\n",
      "4                time   2  22 110.941583 3.218470e-12     * 0.54133853\n",
      "5      diet:exercises   1  11  75.356051 2.980284e-06     * 0.15716889\n",
      "6           diet:time   2  22   0.602562 5.561945e-01       0.01332945\n",
      "7      exercises:time   2  22  20.825889 8.408790e-06     * 0.27352201\n",
      "8 diet:exercises:time   2  22  14.246076 1.074451e-04     * 0.14663048\n",
      "\n",
      "$`Mauchly's Test for Sphericity`\n",
      "               Effect         W          p p<.05\n",
      "4                time 0.9833425 0.91944157      \n",
      "6           diet:time 0.5493166 0.05001654      \n",
      "7      exercises:time 0.6835227 0.14919857      \n",
      "8 diet:exercises:time 0.9589434 0.81089547      \n",
      "\n",
      "$`Sphericity Corrections`\n",
      "               Effect       GGe        p[GG] p[GG]<.05       HFe        p[HF] p[HF]<.05\n",
      "4                time 0.9836155 4.732515e-12         * 1.1960214 3.218470e-12         *\n",
      "6           diet:time 0.6893303 5.008306e-01           0.7558161 5.144265e-01          \n",
      "7      exercises:time 0.7596029 7.470601e-05         * 0.8559657 3.105108e-05         *\n",
      "8 diet:exercises:time 0.9605626 1.395812e-04         * 1.1594775 1.074451e-04         *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library('ez')\n",
    "weightloss.ez <- ezANOVA(data=weightloss.long, dv=weight, wid=id, within=.(diet,exercises,time))\n",
    "print(weightloss.ez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23525ebc",
   "metadata": {},
   "source": [
    "The output will match the result of `aov()`, but in a much nicer format, with the additional advantage of the sphericity corrections. However, this approach does hide the fundamental difficulty with assigning tests to different error terms and thus hides much of the complexity and disadvantages of the repeated measures ANOVA framework. We also have the problem that, by going down this route, we have effectively thrown away the linear model framework we have been working so hard to build. We end up with an ANOVA table and nothing else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdc59d",
   "metadata": {},
   "source": [
    "## Why We Should *Not* Use RM ANOVA\n",
    "Everything we have discussed above has really been an exercise in telling you why you really *do not want to use a repeated measures ANOVA*. All the unnecessary fiddling with error terms and different tests requiring different errors is a complication that we could simply do without. Life is much too short to be concerning ourselves with such things, especially as a better alternative *does* exist. In the past, this was the *only* way to deal with repeated measures, but that is no longer the case. Ultimately, the concept of multiple error terms and multiple sources of error variance are perfectly sound. Indeed, we will see that this is the basis of mixed-effects models. However, getting this to work within the linear models framework, and within the traditional ANOVA framework, is fraught with difficulties. The repeated measures ANOVA is a solution to this, but is really an *ad hoc* workaround for an analysis that is ill-suited for this framework. We can use software to hide much of this complexity, but that does not mean it goes away.\n",
    "\n",
    "Even if we are ok generating the correct output using `R`, particularly with access to something like `ezANOVA()`, we are still left with a method that has a number of meaningful restrictions. Perhaps most concerning is the assumption of compound symmetry, because this will almost never be true in real-world data. Yes we can use some sort of correction for this, but this correction only applies to the inferential tests (not the model) and remains a further ad hoc adjustment to make the framework *approximately* correct. This is somewhat unsatisfying, especially as we would much prefer a method where the covariance matrix could just be *estimated* from the data and be allowed to take on any form it likes. This is particularly true when the correlation between repeated measurements is *negative*, because the repeated measures ANOVA simply *does not allow this*. Consider that $\\sigma^{2}_{b}$ is treated as the covariance and this is derived from $\\sigma^{2} = \\sigma^{2}_{b} + \\sigma^{2}_{w}$. Thus, the covariance *is* a variance component and variance can *never be negative*. This is a point that very few people understand about the repeated measures ANOVA.  \n",
    "\n",
    "Taking all this together we can conclude that the repeated measures ANOVA is both tricky to understand, tricky to use correctly and largely inflexible. It is perhaps no wonder that statisticians abandoned this method decades ago. Indeed, notice the dates around when the sphericity corrections were published: 1959 and 1976. This gives you a hint about when these approaches were last being developed and studied in mathematical statistics. And yet, this is the method that has persisted in psychology until only relatively recently. Indeed, as alluded to already, you are likely to come across people still using the repeated measures ANOVA to this day. You may even work for some of them who will *insist* that you use a repeated measures ANOVA to analyse their data. In those situations, it is useful to (a) motivate the need for something better and (b) understand how to get the ANOVA results in `R`, if absolutely necessary. So, we do not condone the use of the repeated measures ANOVA, but we understand its place in psychology and also understand that there are times where you may need to see what the repeated measures ANOVA says, even if you do not wish to use it. Over the next few weeks, we will show you how to replace this framework with something much better in the form of *mixed-effects models*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6312",
   "metadata": {},
   "source": [
    "[^submodel-foot]: An alternative perspective here is that each error term represents a different *sub-model*. So, we can think of specifying *multiple* models, some of which require us to *average-over* certain factors. For instance, if we were to average-over the repeated measurements and then fit a model on the resultant outcome variable, this model would automatically have $\\sigma^{2}_{b}$ as its error term. This does make the whole procedure feel a little bit less of a hack, however, it is very impractical to do this, especially when the number of factors and interactions gets larger. You can read more about this approach in [McFarquhar (2019)](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2019.00352/full).\n",
    "\n",
    "[^noterr-foot]: Note that this is *not* the errors from the linear model, even though the Greek letter is the same.\n",
    "\n",
    "[^ems-foot]: There is a more principled way of determining the correct error term via calculation of something called the *expected mean squares* (EMS). However, this is an old topic that is not that relevant given that we are not suggesting you actually use the repeated measures ANOVA. If you are curious, the EMS are discussed at length by [McFarquhar (2019)](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2019.00352/full) and can be calculated for you automatically by the `R` package `EMSaov`.\n",
    "\n",
    "[^nesting-foot]: This syntax is used to embody the concept of *nesting*, but that is beyond the scope of this lesson. All you really need to know is that `A/B = A + A:B`. So, specifying `S/A = A + S:A` and `S/(A*B) = S/(A + B + A:B) = S + S:A + S:B + S:AB`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5a5fa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
